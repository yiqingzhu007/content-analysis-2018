{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 - Information Extraction\n",
    "\n",
    "\n",
    "This week, we move from arbitrary textual classification to the use of computation and linguistic models to parse precise claims from documents. Rather than focusing on simply the *ideas* in a corpus, here we focus on understanding and extracting its precise *claims*. This process involves a sequential pipeline of classifying and structuring tokens from text, each of which generates potentially useful data for the content analyst. Steps in this process, which we examine in this notebook, include: 1) tagging words by their part of speech (POS) to reveal the linguistic role they play in the sentence (e.g., Verb, Noun, Adjective, etc.); 2) tagging words as named entities (NER) such as places or organizations; 3) structuring or \"parsing\" sentences into nested phrases that are local to, describe or depend on one another; and 4) extracting informational claims from those phrases, like the Subject-Verb-Object (SVO) triples we extract here. While much of this can be done directly in the python package NLTK that we introduced in week 2, here we use NLTK bindings to the Stanford NLP group's open software, written in Java. Try typing a sentence into the online version [here](http://nlp.stanford.edu:8080/corenlp/) to get a sense of its potential. It is superior in performance to NLTK's implementations, but takes time to run, and so for these exercises we will parse and extract information for a very small text corpus. Of course, for final projects that draw on these tools, we encourage you to install the software on your own machines or shared servers at the university (RCC, SSRC) in order to perform these operations on much more text. \n",
    "\n",
    "For this notebook we will be using the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For NLP\n",
    "import nltk\n",
    "\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to run this _once_ to download everything, you will also need [Java 1.8+](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html) if you are using Windows or MacOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting downloads, this will take 5-10 minutes\n",
      "../stanford-NLP/core already exists, skipping download\n",
      "Downloading parser from https://nlp.stanford.edu/software/stanford-parser-full-2017-06-09.zip\n",
      "Downloaded parser, extracting to ../stanford-NLP/parser\n",
      "../stanford-NLP/ner already exists, skipping download\n",
      "../stanford-NLP/postagger already exists, skipping download\n",
      "Done setting up the Stanford NLP collection\n"
     ]
    }
   ],
   "source": [
    "lucem_illud.setupStanfordNLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have stanford-NLP setup before importing, so we are doing the import here. IF you have stanford-NLP working, you can import at the beginning like you would with any other library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiqingzhu/anaconda/lib/python3.5/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "/Users/yiqingzhu/anaconda/lib/python3.5/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import lucem_illud.stanford as stanford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Information Extraction is a module packaged within the Stanford Core NLP package, but it is not yet supported by `nltk`. As a result, we have defining our own `lucem_illud` function that runs the Stanford Core NLP java code right here. For other projects, it is often useful to use Java or other programs (in C, C++) within a python workflow, and this is an example. `stanford.openIE()` takes in a string or list of strings and then produces as output all the subject, verb, object (SVO) triples Stanford Corenlp can find, as a DataFrame. You can do this through links to the Stanford Core NLP project that we provide here, or play with their interface directly (in the penultimate cell of this notebook), which produces data in \"pretty graphics\" like this example parsing of the first sentence in the \"Shooting of Trayvon Martin\" Wikipedia article:\n",
    "\n",
    "![Output 1](../data/stanford_core1.png)\n",
    "![Output 2](../data/stanford_core2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will illustrate these tools on some *very* short examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw the elephant in my pajamas.\n",
      "The quick brown fox jumped over the lazy dog.\n",
      "While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.\n",
      "Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.\n",
      "Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo\n"
     ]
    }
   ],
   "source": [
    "text = ['I saw the elephant in my pajamas.', 'The quick brown fox jumped over the lazy dog.', 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.', 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.', 'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']\n",
    "tokenized_text = [nltk.word_tokenize(t) for t in text]\n",
    "print('\\n'.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech (POS) tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In POS tagging, we classify each word by its semantic role in a sentence. The Stanford POS tagger uses the [Penn Treebank tag set]('http://repository.upenn.edu/cgi/viewcontent.cgi?article=1603&context=cis_reports') to POS tag words from input sentences. As discussed in the second assignment, this is a relatively precise tagset, which allows more informative tags, and also more opportunities to err :-).\n",
    "\n",
    "|#. |Tag |Description |\n",
    "|---|----|------------|\n",
    "|1.\t|CC\t|Coordinating conjunction\n",
    "|2.\t|CD\t|Cardinal number\n",
    "|3.\t|DT\t|Determiner\n",
    "|4.\t|EX\t|Existential there\n",
    "|5.\t|FW\t|Foreign word\n",
    "|6.\t|IN\t|Preposition or subordinating conjunction\n",
    "|7.\t|JJ\t|Adjective\n",
    "|8.\t|JJR|\tAdjective, comparative\n",
    "|9.\t|JJS|\tAdjective, superlative\n",
    "|10.|\tLS\t|List item marker\n",
    "|11.|\tMD\t|Modal\n",
    "|12.|\tNN\t|Noun, singular or mass\n",
    "|13.|\tNNS\t|Noun, plural\n",
    "|14.|\tNNP\t|Proper noun, singular\n",
    "|15.|\tNNPS|\tProper noun, plural\n",
    "|16.|\tPDT\t|Predeterminer\n",
    "|17.|\tPOS\t|Possessive ending\n",
    "|18.|\tPRP\t|Personal pronoun\n",
    "|19.|\tPRP\\$|\tPossessive pronoun\n",
    "|20.|\tRB\t|Adverb\n",
    "|21.|\tRBR\t|Adverb, comparative\n",
    "|22.|\tRBS\t|Adverb, superlative\n",
    "|23.|\tRP\t|Particle\n",
    "|24.|\tSYM\t|Symbol\n",
    "|25.|\tTO\t|to\n",
    "|26.|\tUH\t|Interjection\n",
    "|27.|\tVB\t|Verb, base form\n",
    "|28.|\tVBD\t|Verb, past tense\n",
    "|29.|\tVBG\t|Verb, gerund or present participle\n",
    "|30.|\tVBN\t|Verb, past participle\n",
    "|31.|\tVBP\t|Verb, non-3rd person singular present\n",
    "|32.|\tVBZ\t|Verb, 3rd person singular present\n",
    "|33.|\tWDT\t|Wh-determiner\n",
    "|34.|\tWP\t|Wh-pronoun\n",
    "|35.|\tWP$\t|Possessive wh-pronoun\n",
    "|36.|\tWRB\t|Wh-adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'PRP'), ('saw', 'VBD'), ('the', 'DT'), ('elephant', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('pajamas', 'NNS'), ('.', '.')], [('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')], [('While', 'IN'), ('in', 'IN'), ('France', 'NNP'), (',', ','), ('Christine', 'NNP'), ('Lagarde', 'NNP'), ('discussed', 'VBD'), ('short-term', 'JJ'), ('stimulus', 'NN'), ('efforts', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('recent', 'JJ'), ('interview', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Wall', 'NNP'), ('Street', 'NNP'), ('Journal', 'NNP'), ('.', '.')], [('Trayvon', 'NNP'), ('Benjamin', 'NNP'), ('Martin', 'NNP'), ('was', 'VBD'), ('an', 'DT'), ('African', 'NNP'), ('American', 'NNP'), ('from', 'IN'), ('Miami', 'NNP'), ('Gardens', 'NNP'), (',', ','), ('Florida', 'NNP'), (',', ','), ('who', 'WP'), (',', ','), ('at', 'IN'), ('17', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('was', 'VBD'), ('fatally', 'RB'), ('shot', 'VBN'), ('by', 'IN'), ('George', 'NNP'), ('Zimmerman', 'NNP'), (',', ','), ('a', 'DT'), ('neighborhood', 'NN'), ('watch', 'NN'), ('volunteer', 'NN'), (',', ','), ('in', 'IN'), ('Sanford', 'NNP'), (',', ','), ('Florida', 'NNP'), ('.', '.')], [('Buffalo', 'NNP'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "pos_sents = stanford.postTagger.tag_sents(tokenized_text)\n",
    "print(pos_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks quite good. Now we will try POS tagging with a somewhat larger corpus. We consider a few of the top posts from the reddit data we used last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditDF = pandas.read_csv('../data/reddit.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the 10 highest scoring posts and tokenizing the sentences. Once again, notice that we aren't going to do any kind of stemming this week (although *semantic* normalization may be performed where we translate synonyms into the same focal word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>over_18</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>goldie-gold</td>\n",
       "      <td>False</td>\n",
       "      <td>12650</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>This just happened...  So, I had a laptop syst...</td>\n",
       "      <td>Engineer is doing drugs!! No. No they aren't.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[This, just, happened, ...], [So, ,, I, had, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TheDroolinFool</td>\n",
       "      <td>False</td>\n",
       "      <td>13152</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>Another tale from the out of hours IT desk... ...</td>\n",
       "      <td>\"I need you to fix Google Bing immediately!\"</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[Another, tale, from, the, out, of, hours, IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clickity_clickity</td>\n",
       "      <td>False</td>\n",
       "      <td>13404</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>[Part 1](http://www.reddit.com/r/talesfromtech...</td>\n",
       "      <td>Jack, the Worst End User, Part 4</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[[, Part, 1, ], (, http, :, //www.reddit.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SECGaz</td>\n",
       "      <td>False</td>\n",
       "      <td>13724</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>&gt; $Me  - Hello, IT.   &gt; $Usr - Hi, I am still ...</td>\n",
       "      <td>Hi, I am still off sick but I am not.</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[&gt;, $, Me, -, Hello, ,, IT, .], [&gt;, $, Usr, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guitarsdontdance</td>\n",
       "      <td>False</td>\n",
       "      <td>14089</td>\n",
       "      <td>Tales From Tech Support</td>\n",
       "      <td>So my story starts on what was a normal day ta...</td>\n",
       "      <td>\"Don't bother sending a tech, I'll be dead by ...</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>[[So, my, story, starts, on, what, was, a, nor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author  over_18  score                subreddit  \\\n",
       "4        goldie-gold    False  12650  Tales From Tech Support   \n",
       "3     TheDroolinFool    False  13152  Tales From Tech Support   \n",
       "2  Clickity_clickity    False  13404  Tales From Tech Support   \n",
       "1             SECGaz    False  13724  Tales From Tech Support   \n",
       "0   guitarsdontdance    False  14089  Tales From Tech Support   \n",
       "\n",
       "                                                text  \\\n",
       "4  This just happened...  So, I had a laptop syst...   \n",
       "3  Another tale from the out of hours IT desk... ...   \n",
       "2  [Part 1](http://www.reddit.com/r/talesfromtech...   \n",
       "1  > $Me  - Hello, IT.   > $Usr - Hi, I am still ...   \n",
       "0  So my story starts on what was a normal day ta...   \n",
       "\n",
       "                                               title  \\\n",
       "4      Engineer is doing drugs!! No. No they aren't.   \n",
       "3       \"I need you to fix Google Bing immediately!\"   \n",
       "2                   Jack, the Worst End User, Part 4   \n",
       "1              Hi, I am still off sick but I am not.   \n",
       "0  \"Don't bother sending a tech, I'll be dead by ...   \n",
       "\n",
       "                                                 url  \\\n",
       "4  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "3  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "2  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "1  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "0  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "\n",
       "                                           sentences  \n",
       "4  [[This, just, happened, ...], [So, ,, I, had, ...  \n",
       "3  [[Another, tale, from, the, out, of, hours, IT...  \n",
       "2  [[[, Part, 1, ], (, http, :, //www.reddit.com/...  \n",
       "1  [[>, $, Me, -, Hello, ,, IT, .], [>, $, Usr, -...  \n",
       "0  [[So, my, story, starts, on, what, was, a, nor...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores = redditDF.sort_values('score')[-10:]\n",
    "redditTopScores['sentences'] = redditTopScores['text'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "redditTopScores.index = range(len(redditTopScores) - 1, -1, -1) #Reindex to make things nice in the future\n",
    "redditTopScores[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['POS_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, JJ), (year, NN), (,, ,), (Help, NN), ...\n",
       "8    [[(First, JJ), (post, NN), (in, IN), (quite, R...\n",
       "7    [[([, NNP), (Original, NNP), (Post, NNP), (], ...\n",
       "6    [[(I, PRP), (witnessed, VBD), (this, DT), (ast...\n",
       "5    [[(I, PRP), (work, VBP), (Helpdesk, NNP), (for...\n",
       "4    [[(This, DT), (just, RB), (happened, VBN), (.....\n",
       "3    [[(Another, DT), (tale, NN), (from, IN), (the,...\n",
       "2    [[([, NNP), (Part, NNP), (1, CD), (], FW), ((,...\n",
       "1    [[(>, JJR), ($, $), (Me, PRP), (-, :), (Hello,...\n",
       "0    [[(So, RB), (my, PRP$), (story, NN), (starts, ...\n",
       "Name: POS_sents, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['POS_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And count the number of `NN` (nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('password', 21),\n",
       " ('(', 19),\n",
       " (')', 14),\n",
       " ('time', 14),\n",
       " ('lot', 12),\n",
       " ('computer', 12),\n",
       " ('life', 11),\n",
       " ('email', 11),\n",
       " ('**Genius**', 10),\n",
       " ('**Me**', 9),\n",
       " ('message', 9),\n",
       " ('system', 9),\n",
       " ('day', 9),\n",
       " ('story', 8),\n",
       " ('office', 8),\n",
       " ('part', 8),\n",
       " ('laptop', 8),\n",
       " ('today', 8),\n",
       " ('call', 8),\n",
       " ('user', 7)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'NN'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the number of top verbs (`VB`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 18),\n",
       " ('have', 17),\n",
       " ('get', 14),\n",
       " ('do', 11),\n",
       " ('change', 9),\n",
       " ('make', 8),\n",
       " ('know', 7),\n",
       " ('say', 7),\n",
       " ('send', 6),\n",
       " ('tell', 6),\n",
       " ('help', 6),\n",
       " ('look', 6),\n",
       " ('go', 5),\n",
       " ('take', 4),\n",
       " ('call', 4),\n",
       " ('feel', 4),\n",
       " ('thank', 4),\n",
       " ('open', 4),\n",
       " ('use', 4),\n",
       " ('receive', 4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countTarget = 'VB'\n",
    "targetCounts = {}\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != countTarget:\n",
    "                continue\n",
    "            elif ent in targetCounts:\n",
    "                targetCounts[ent] += 1\n",
    "            else:\n",
    "                targetCounts[ent] = 1\n",
    "sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedTargets[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the adjectives that modify the word, \"computer\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unrestricted', 'own'}\n"
     ]
    }
   ],
   "source": [
    "NTarget = 'JJ'\n",
    "Word = 'computer'\n",
    "NResults = set()\n",
    "for entry in redditTopScores['POS_sents']:\n",
    "    for sentence in entry:\n",
    "        for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "            if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                NResults.add(ent1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "print(NResults)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating POS tagger\n",
    "\n",
    "We can check the POS tagger by running it on a manually tagged corpus and identifying a reasonable error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank = nltk.corpus.treebank\n",
    "treeBank.tagged_sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeBank.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stanfordTags = stanford.postTagger.tag_sents(treeBank.sents()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Dutch  \tStanford: JJ\tTreebank: NNP\n",
      "Word: publishing  \tStanford: NN\tTreebank: VBG\n",
      "Word: used  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: later  \tStanford: RB\tTreebank: JJ\n",
      "Word: New  \tStanford: NNP\tTreebank: JJ\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: more  \tStanford: JJR\tTreebank: RBR\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: ago  \tStanford: RB\tTreebank: IN\n",
      "Word: replaced  \tStanford: VBD\tTreebank: VBN\n",
      "Word: more  \tStanford: JJR\tTreebank: JJ\n",
      "Word: expected  \tStanford: VBD\tTreebank: VBN\n",
      "Word: study  \tStanford: VBD\tTreebank: VBP\n",
      "Word: studied  \tStanford: VBD\tTreebank: VBN\n",
      "Word: industrialized  \tStanford: JJ\tTreebank: VBN\n",
      "Word: Lorillard  \tStanford: NNP\tTreebank: NN\n",
      "Word: found  \tStanford: VBD\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: rejected  \tStanford: VBD\tTreebank: VBN\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "Word: poured  \tStanford: VBN\tTreebank: VBD\n",
      "Word: in  \tStanford: IN\tTreebank: RP\n",
      "Word: that  \tStanford: IN\tTreebank: WDT\n",
      "The Precision is 96.547%\n"
     ]
    }
   ],
   "source": [
    "NumDiffs = 0\n",
    "for sentIndex in range(len(stanfordTags)):\n",
    "    for wordIndex in range(len(stanfordTags[sentIndex])):\n",
    "        if stanfordTags[sentIndex][wordIndex][1] != treeBank.tagged_sents()[sentIndex][wordIndex][1]:\n",
    "            if treeBank.tagged_sents()[sentIndex][wordIndex][1] != '-NONE-':\n",
    "                print(\"Word: {}  \\tStanford: {}\\tTreebank: {}\".format(stanfordTags[sentIndex][wordIndex][0], stanfordTags[sentIndex][wordIndex][1], treeBank.tagged_sents()[sentIndex][wordIndex][1]))\n",
    "                NumDiffs += 1\n",
    "total = sum([len(s) for s in stanfordTags])\n",
    "print(\"The Precision is {:.3f}%\".format((total-NumDiffs)/total * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the stanford POS tagger is quite good. Nevertheless, for a 20 word sentence, we only have a 66% chance ($1-.96^{20}$) of tagging (and later parsing) it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform POS tagging on a meaningful (but modest) subset of a corpus associated with your final project. Examine the list of words associated with at least three different parts of speech. Consider conditional frequencies (e.g., adjectives associated with nouns of interest or adverbs with verbs of interest). What do these distributions suggest about your corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I collected the plot summaries of sci-fi movies in the year 2008 and 2009 available on IMDb and try to perform the POS tagging on a subset of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3280625</td>\n",
       "      <td>'O puorco</td>\n",
       "      <td>2009</td>\n",
       "      <td>The sacrifice of pig in some ancient ethnic gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3281971</td>\n",
       "      <td>00:05'01</td>\n",
       "      <td>2008</td>\n",
       "      <td>A scenic work about nature, human nature, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3288302</td>\n",
       "      <td>20 Years After</td>\n",
       "      <td>2008</td>\n",
       "      <td>Everything that could go wrong did go wrong: W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3289227</td>\n",
       "      <td>2012</td>\n",
       "      <td>2009</td>\n",
       "      <td>Geophysicist Adrian Helmsley officially visits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3289786</td>\n",
       "      <td>2081</td>\n",
       "      <td>2009</td>\n",
       "      <td>A short film adaptation of Kurt Vonnegut's Har...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id           title  year  \\\n",
       "0   3280625       'O puorco  2009   \n",
       "1   3281971        00:05'01  2008   \n",
       "2   3288302  20 Years After  2008   \n",
       "3   3289227            2012  2009   \n",
       "4   3289786            2081  2009   \n",
       "\n",
       "                                                plot  \n",
       "0  The sacrifice of pig in some ancient ethnic gr...  \n",
       "1  A scenic work about nature, human nature, and ...  \n",
       "2  Everything that could go wrong did go wrong: W...  \n",
       "3  Geophysicist Adrian Helmsley officially visits...  \n",
       "4  A short film adaptation of Kurt Vonnegut's Har...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots_ori = pandas.read_csv('scifi_uncoded.csv')\n",
    "plots = plots_ori[:50]\n",
    "plots[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiqingzhu/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>plot</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3280625</td>\n",
       "      <td>'O puorco</td>\n",
       "      <td>2009</td>\n",
       "      <td>The sacrifice of pig in some ancient ethnic gr...</td>\n",
       "      <td>[[The, sacrifice, of, pig, in, some, ancient, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3281971</td>\n",
       "      <td>00:05'01</td>\n",
       "      <td>2008</td>\n",
       "      <td>A scenic work about nature, human nature, and ...</td>\n",
       "      <td>[[A, scenic, work, about, nature, ,, human, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3288302</td>\n",
       "      <td>20 Years After</td>\n",
       "      <td>2008</td>\n",
       "      <td>Everything that could go wrong did go wrong: W...</td>\n",
       "      <td>[[Everything, that, could, go, wrong, did, go,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3289227</td>\n",
       "      <td>2012</td>\n",
       "      <td>2009</td>\n",
       "      <td>Geophysicist Adrian Helmsley officially visits...</td>\n",
       "      <td>[[Geophysicist, Adrian, Helmsley, officially, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3289786</td>\n",
       "      <td>2081</td>\n",
       "      <td>2009</td>\n",
       "      <td>A short film adaptation of Kurt Vonnegut's Har...</td>\n",
       "      <td>[[A, short, film, adaptation, of, Kurt, Vonneg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id           title  year  \\\n",
       "0   3280625       'O puorco  2009   \n",
       "1   3281971        00:05'01  2008   \n",
       "2   3288302  20 Years After  2008   \n",
       "3   3289227            2012  2009   \n",
       "4   3289786            2081  2009   \n",
       "\n",
       "                                                plot  \\\n",
       "0  The sacrifice of pig in some ancient ethnic gr...   \n",
       "1  A scenic work about nature, human nature, and ...   \n",
       "2  Everything that could go wrong did go wrong: W...   \n",
       "3  Geophysicist Adrian Helmsley officially visits...   \n",
       "4  A short film adaptation of Kurt Vonnegut's Har...   \n",
       "\n",
       "                                           sentences  \n",
       "0  [[The, sacrifice, of, pig, in, some, ancient, ...  \n",
       "1  [[A, scenic, work, about, nature, ,, human, na...  \n",
       "2  [[Everything, that, could, go, wrong, did, go,...  \n",
       "3  [[Geophysicist, Adrian, Helmsley, officially, ...  \n",
       "4  [[A, short, film, adaptation, of, Kurt, Vonneg...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots['sentences'] = plots['plot'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "plots[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiqingzhu/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>plot</th>\n",
       "      <th>sentences</th>\n",
       "      <th>POS_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3280625</td>\n",
       "      <td>'O puorco</td>\n",
       "      <td>2009</td>\n",
       "      <td>The sacrifice of pig in some ancient ethnic gr...</td>\n",
       "      <td>[[The, sacrifice, of, pig, in, some, ancient, ...</td>\n",
       "      <td>[[(The, DT), (sacrifice, NN), (of, IN), (pig, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3281971</td>\n",
       "      <td>00:05'01</td>\n",
       "      <td>2008</td>\n",
       "      <td>A scenic work about nature, human nature, and ...</td>\n",
       "      <td>[[A, scenic, work, about, nature, ,, human, na...</td>\n",
       "      <td>[[(A, DT), (scenic, JJ), (work, NN), (about, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3288302</td>\n",
       "      <td>20 Years After</td>\n",
       "      <td>2008</td>\n",
       "      <td>Everything that could go wrong did go wrong: W...</td>\n",
       "      <td>[[Everything, that, could, go, wrong, did, go,...</td>\n",
       "      <td>[[(Everything, NN), (that, WDT), (could, MD), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3289227</td>\n",
       "      <td>2012</td>\n",
       "      <td>2009</td>\n",
       "      <td>Geophysicist Adrian Helmsley officially visits...</td>\n",
       "      <td>[[Geophysicist, Adrian, Helmsley, officially, ...</td>\n",
       "      <td>[[(Geophysicist, NNP), (Adrian, NNP), (Helmsle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3289786</td>\n",
       "      <td>2081</td>\n",
       "      <td>2009</td>\n",
       "      <td>A short film adaptation of Kurt Vonnegut's Har...</td>\n",
       "      <td>[[A, short, film, adaptation, of, Kurt, Vonneg...</td>\n",
       "      <td>[[(A, DT), (short, JJ), (film, NN), (adaptatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id           title  year  \\\n",
       "0   3280625       'O puorco  2009   \n",
       "1   3281971        00:05'01  2008   \n",
       "2   3288302  20 Years After  2008   \n",
       "3   3289227            2012  2009   \n",
       "4   3289786            2081  2009   \n",
       "\n",
       "                                                plot  \\\n",
       "0  The sacrifice of pig in some ancient ethnic gr...   \n",
       "1  A scenic work about nature, human nature, and ...   \n",
       "2  Everything that could go wrong did go wrong: W...   \n",
       "3  Geophysicist Adrian Helmsley officially visits...   \n",
       "4  A short film adaptation of Kurt Vonnegut's Har...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [[The, sacrifice, of, pig, in, some, ancient, ...   \n",
       "1  [[A, scenic, work, about, nature, ,, human, na...   \n",
       "2  [[Everything, that, could, go, wrong, did, go,...   \n",
       "3  [[Geophysicist, Adrian, Helmsley, officially, ...   \n",
       "4  [[A, short, film, adaptation, of, Kurt, Vonneg...   \n",
       "\n",
       "                                           POS_sents  \n",
       "0  [[(The, DT), (sacrifice, NN), (of, IN), (pig, ...  \n",
       "1  [[(A, DT), (scenic, JJ), (work, NN), (about, I...  \n",
       "2  [[(Everything, NN), (that, WDT), (could, MD), ...  \n",
       "3  [[(Geophysicist, NNP), (Adrian, NNP), (Helmsle...  \n",
       "4  [[(A, DT), (short, JJ), (film, NN), (adaptatio...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots['POS_sents'] = plots['sentences'].apply(lambda x: stanford.postTagger.tag_sents(x))\n",
    "plots[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A function to list POS and sort them by count\n",
    "def list_pos(df, countTarget):\n",
    "    targetCounts = {}\n",
    "    for entry in df['POS_sents']:\n",
    "        for sentence in entry:\n",
    "            for ent, kind in sentence:\n",
    "                if kind != countTarget:\n",
    "                    continue\n",
    "                elif ent in targetCounts:\n",
    "                    targetCounts[ent] += 1\n",
    "                else:\n",
    "                    targetCounts[ent] = 1\n",
    "    sortedTargets = sorted(targetCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "    return sortedTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('life', 18),\n",
       " ('man', 15),\n",
       " ('world', 15),\n",
       " ('time', 10),\n",
       " ('woman', 9),\n",
       " ('way', 7),\n",
       " ('story', 6),\n",
       " ('government', 6),\n",
       " ('father', 6),\n",
       " ('future', 6),\n",
       " ('love', 6),\n",
       " ('journey', 6),\n",
       " ('film', 6),\n",
       " ('night', 5),\n",
       " ('day', 5),\n",
       " ('businessman', 5),\n",
       " ('mission', 5),\n",
       " ('battle', 5),\n",
       " ('place', 4),\n",
       " ('machine', 4)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of nouns\n",
    "list_pos(plots, 'NN')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 15),\n",
       " ('find', 9),\n",
       " ('save', 6),\n",
       " ('take', 4),\n",
       " ('leave', 4),\n",
       " ('go', 4),\n",
       " ('have', 3),\n",
       " ('stop', 3),\n",
       " ('survive', 3),\n",
       " ('discover', 3),\n",
       " ('heal', 2),\n",
       " ('convince', 2),\n",
       " ('destroy', 2),\n",
       " ('die', 2),\n",
       " ('come', 2),\n",
       " ('understand', 2),\n",
       " ('do', 2),\n",
       " ('end', 2),\n",
       " ('bring', 2),\n",
       " ('question', 2)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of verbs\n",
    "list_pos(plots, 'VB')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('human', 9),\n",
       " ('own', 8),\n",
       " ('young', 7),\n",
       " ('new', 7),\n",
       " ('native', 6),\n",
       " ('other', 5),\n",
       " ('local', 4),\n",
       " ('first', 4),\n",
       " ('powerful', 4),\n",
       " ('old', 4),\n",
       " ('mysterious', 4),\n",
       " ('last', 4),\n",
       " ('same', 3),\n",
       " ('wealthy', 3),\n",
       " ('only', 3),\n",
       " ('ordinary', 3),\n",
       " ('alien', 3),\n",
       " ('single', 3),\n",
       " ('short', 3),\n",
       " ('futuristic', 3)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of adjectives\n",
    "list_pos(plots, 'JJ')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('only', 10),\n",
       " ('not', 7),\n",
       " ('soon', 6),\n",
       " ('also', 5),\n",
       " (\"n't\", 5),\n",
       " ('just', 5),\n",
       " ('Now', 5),\n",
       " ('once', 4),\n",
       " ('somewhere', 4),\n",
       " ('alone', 3),\n",
       " ('Meanwhile', 3),\n",
       " ('now', 3),\n",
       " ('back', 3),\n",
       " ('again', 3),\n",
       " ('quickly', 3),\n",
       " ('Not', 2),\n",
       " ('about', 2),\n",
       " ('long', 2),\n",
       " ('too', 2),\n",
       " ('immediately', 2)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of adverbs\n",
    "list_pos(plots, 'RB')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to find POS associated with words of interest\n",
    "def find_surrounding_pos(df, Word, NTarget):\n",
    "    NResults = set()\n",
    "    for entry in df['POS_sents']:\n",
    "        for sentence in entry:\n",
    "            for (ent1, kind1),(ent2,kind2) in zip(sentence[:-1], sentence[1:]):\n",
    "                if (kind1,ent2.lower())==(NTarget,Word):\n",
    "                    NResults.add(ent1)\n",
    "                else:\n",
    "                    continue\n",
    "    return NResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'native', 'old', 'young'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_surrounding_pos(plots, 'woman', 'JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elderly', 'grieving', 'ordinary', 'same'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_surrounding_pos(plots, 'man', 'JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distant', 'entire', 'neo-realistic'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_surrounding_pos(plots, 'world', 'JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entire', 'horrible', 'human', 'innocent', 'mundane', 'own'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_surrounding_pos(plots, 'life',  'JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first', 'same'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_surrounding_pos(plots, 'time',  'JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apocalyptic', 'dystopian', 'not-so-distant', 'unknown'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_surrounding_pos(plots, 'future',  'JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brutal'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_surrounding_pos(plots, 'government',  'JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'they'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_surrounding_pos(plots, 'find',  'PRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'they'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_surrounding_pos(plots, 'discover',  'PRP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sci-fi films are usually about the future, world, space, technology, life and surviving. \n",
    "\n",
    "It is interesting to observe that in our sample plots, the \"government\" is also appearing often, and as a \"brutal\" one. As we can recall, in most films, the government does play a negative role, and the officers from the government are usually stupid, while the main character would be depicted as someone opposite or at least irrelevant to the government.  It seems that in our sample plots, the government is even described worse than the average.\n",
    "\n",
    "“Future\" in our sample plots is \"apocalyptic\" and \"unknown\", and “life” is “horrible”, “mundane”, and “innocent”, and the actions appearing often are “find”, “save”, ”leave”, “survive”, which aligns with the nature of sci-fi film stories that some people fight for something catastrophic in a future setting for the survival of human beings.\n",
    "\n",
    "I didn’t find much meaningful conditional frequencies due to the limited data size. It would be more interesting to further investigate it if I can include more plot summaries and compare them in pre-great-recession, during-great-recession and post-great-recession period, to see if the films in different periods of great recession are catering to different needs of people, if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named-Entity Recognition\n",
    "\n",
    "Named Entity Recognition (NER) is also a classification task, which identifies named objects. Included with Stanford NER are a 4 class model trained on the CoNLL 2003 eng.train, a 7 class model trained on the MUC 6 and MUC 7 training data sets, and a 3 class model trained on both data sets plus some additional data (including ACE 2002 and limited data in-house) on the intersection of those class sets. \n",
    "\n",
    "**3 class**:\tLocation, Person, Organization\n",
    "\n",
    "**4 class**:\tLocation, Person, Organization, Misc\n",
    "\n",
    "**7 class**:\tLocation, Person, Organization, Money, Percent, Date, Time\n",
    "\n",
    "These models each use distributional similarity features, which provide some performance gain at the cost of increasing their size and runtime. Also available are the same models missing those features.\n",
    "\n",
    "(We note that the training data for the 3 class model does not include any material from the CoNLL eng.testa or eng.testb data sets, nor any of the MUC 6 or 7 test or devtest datasets, nor Alan Ritter's Twitter NER data, so all of these would be valid tests of its performance.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we tag our first set of exemplary sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'O'), ('saw', 'O'), ('the', 'O'), ('elephant', 'O'), ('in', 'O'), ('my', 'O'), ('pajamas', 'O'), ('.', 'O')], [('The', 'O'), ('quick', 'O'), ('brown', 'O'), ('fox', 'O'), ('jumped', 'O'), ('over', 'O'), ('the', 'O'), ('lazy', 'O'), ('dog', 'O'), ('.', 'O')], [('While', 'O'), ('in', 'O'), ('France', 'LOCATION'), (',', 'O'), ('Christine', 'PERSON'), ('Lagarde', 'PERSON'), ('discussed', 'O'), ('short-term', 'O'), ('stimulus', 'O'), ('efforts', 'O'), ('in', 'O'), ('a', 'O'), ('recent', 'O'), ('interview', 'O'), ('with', 'O'), ('the', 'O'), ('Wall', 'ORGANIZATION'), ('Street', 'ORGANIZATION'), ('Journal', 'ORGANIZATION'), ('.', 'O')], [('Trayvon', 'PERSON'), ('Benjamin', 'PERSON'), ('Martin', 'PERSON'), ('was', 'O'), ('an', 'O'), ('African', 'O'), ('American', 'O'), ('from', 'O'), ('Miami', 'LOCATION'), ('Gardens', 'LOCATION'), (',', 'O'), ('Florida', 'LOCATION'), (',', 'O'), ('who', 'O'), (',', 'O'), ('at', 'O'), ('17', 'O'), ('years', 'O'), ('old', 'O'), (',', 'O'), ('was', 'O'), ('fatally', 'O'), ('shot', 'O'), ('by', 'O'), ('George', 'PERSON'), ('Zimmerman', 'PERSON'), (',', 'O'), ('a', 'O'), ('neighborhood', 'O'), ('watch', 'O'), ('volunteer', 'O'), (',', 'O'), ('in', 'O'), ('Sanford', 'LOCATION'), (',', 'O'), ('Florida', 'LOCATION'), ('.', 'O')], [('Buffalo', 'LOCATION'), ('buffalo', 'O'), ('Buffalo', 'ORGANIZATION'), ('buffalo', 'O'), ('buffalo', 'O'), ('buffalo', 'O'), ('Buffalo', 'ORGANIZATION'), ('buffalo', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "classified_sents = stanford.nerTagger.tag_sents(tokenized_text)\n",
    "print(classified_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run NER over our entire corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditTopScores['classified_sents'] = redditTopScores['sentences'].apply(lambda x: stanford.nerTagger.tag_sents(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    [[(Last, O), (year, O), (,, O), (Help, O), (De...\n",
       "8    [[(First, O), (post, O), (in, O), (quite, O), ...\n",
       "7    [[([, O), (Original, O), (Post, O), (], O), ((...\n",
       "6    [[(I, O), (witnessed, O), (this, O), (astoundi...\n",
       "5    [[(I, O), (work, O), (Helpdesk, ORGANIZATION),...\n",
       "4    [[(This, O), (just, O), (happened, O), (..., O...\n",
       "3    [[(Another, O), (tale, O), (from, O), (the, O)...\n",
       "2    [[([, O), (Part, O), (1, O), (], O), ((, O), (...\n",
       "1    [[(>, O), ($, O), (Me, O), (-, O), (Hello, O),...\n",
       "0    [[(So, O), (my, O), (story, O), (starts, O), (...\n",
       "Name: classified_sents, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redditTopScores['classified_sents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most common entities (which are, of course, boring):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 401),\n",
       " ('I', 245),\n",
       " ('the', 226),\n",
       " (',', 205),\n",
       " ('to', 197),\n",
       " ('a', 143),\n",
       " ('and', 135),\n",
       " ('>', 106),\n",
       " ('you', 102),\n",
       " ('of', 97)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entityCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if ent in entityCounts:\n",
    "                entityCounts[ent] += 1\n",
    "            else:\n",
    "                entityCounts[ent] = 1\n",
    "sortedEntities = sorted(entityCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedEntities[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or those occurring only twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['small',\n",
       " 'others',\n",
       " 'soon',\n",
       " 'fix',\n",
       " 'lunch',\n",
       " 'absolutely',\n",
       " 'LOWERCASE',\n",
       " 'brought',\n",
       " 'Fail',\n",
       " 'Everyone']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in sortedEntities if x[1] == 2][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also list the most common \"non-objects\". (We note that we're not graphing these because there are so few here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jack', 17),\n",
       " ('Google', 6),\n",
       " ('Smith', 5),\n",
       " ('Steve', 2),\n",
       " ('GOOGLE', 1),\n",
       " ('Clickity', 1),\n",
       " ('Buzzfeed', 1),\n",
       " ('UK', 1),\n",
       " ('CMD', 1),\n",
       " ('Reddit', 1)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonObjCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind == 'O':\n",
    "                continue\n",
    "            elif ent in nonObjCounts:\n",
    "                nonObjCounts[ent] += 1\n",
    "            else:\n",
    "                nonObjCounts[ent] = 1\n",
    "sortedNonObj = sorted(nonObjCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedNonObj[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the Organizations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Google', 6), ('CMD', 1), ('Citrix', 1), ('GOOGLE', 1), ('Helpdesk', 1)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrgCounts = {}\n",
    "for entry in redditTopScores['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            if kind != 'ORGANIZATION':\n",
    "                continue\n",
    "            elif ent in OrgCounts:\n",
    "                OrgCounts[ent] += 1\n",
    "            else:\n",
    "                OrgCounts[ent] = 1\n",
    "sortedOrgs = sorted(OrgCounts.items(), key = lambda x: x[1], reverse = True)\n",
    "sortedOrgs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These, of course, have much smaller counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform NER on a (modest) subset of your corpus of interest. List all of the different kinds of entities tagged. What does their distribution suggest about the focus of your corpus? For a subset of your corpus, tally at least one type of named entity and calculate the Precision, Recall and F-score for the NER classification just performed (using your own hand-codings as \"ground truth\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiqingzhu/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [[(The, O), (sacrifice, O), (of, O), (pig, O),...\n",
       "1    [[(A, O), (scenic, O), (work, O), (about, O), ...\n",
       "2    [[(Everything, O), (that, O), (could, O), (go,...\n",
       "3    [[(Geophysicist, O), (Adrian, PERSON), (Helmsl...\n",
       "4    [[(A, O), (short, O), (film, O), (adaptation, ...\n",
       "5    [[(Not, O), (much, O), (left, O), (since, O), ...\n",
       "6    [[(The, O), (film, O), (27, O), (Down, O), (is...\n",
       "7    [[(Los, LOCATION), (Angeles, LOCATION), (,, O)...\n",
       "8    [[(In, O), (a, O), (world, O), (destroyed, O),...\n",
       "9    [[(It, O), (is, O), (the, O), (year, O), (3032...\n",
       "Name: classified_sents, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots['classified_sents'] = plots['sentences'].apply(lambda x: stanford.nerTagger.tag_sents(x))\n",
    "plots['classified_sents'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOCATION', 'O', 'ORGANIZATION', 'PERSON'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all tags\n",
    "kinds = set()\n",
    "for entry in plots['classified_sents']:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            kinds.add(kind)\n",
    "kinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to find entities with different tags\n",
    "def find_entities(df, tag):\n",
    "    Counts = {}\n",
    "    for entry in df['classified_sents']:\n",
    "        for sentence in entry:\n",
    "            for ent, kind in sentence:\n",
    "                if kind != tag:\n",
    "                    continue\n",
    "                elif ent in Counts:\n",
    "                    Counts[ent] += 1\n",
    "                else:\n",
    "                    Counts[ent] = 1\n",
    "    sortedCounts = sorted(Counts.items(), key = lambda x: x[1], reverse = True)\n",
    "    return sortedCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 283),\n",
       " (',', 224),\n",
       " ('.', 207),\n",
       " ('a', 149),\n",
       " ('to', 138),\n",
       " ('and', 137),\n",
       " ('of', 125),\n",
       " ('is', 76),\n",
       " ('in', 75),\n",
       " ('his', 49)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_entities(plots, 'O')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Earth', 8),\n",
       " ('City', 3),\n",
       " ('Angeles', 2),\n",
       " ('California', 2),\n",
       " ('Los', 2),\n",
       " ('States', 2),\n",
       " ('New', 2),\n",
       " ('Metro', 2),\n",
       " ('United', 2),\n",
       " ('Arizona', 2),\n",
       " ('Alliance', 1),\n",
       " ('Ghota', 1),\n",
       " ('India', 1),\n",
       " ('World', 1),\n",
       " ('Mojave', 1),\n",
       " ('Istanbul', 1),\n",
       " ('US', 1),\n",
       " ('Landing', 1),\n",
       " ('Canada', 1),\n",
       " ('Honolulu', 1),\n",
       " ('Chicago', 1),\n",
       " ('Johannesburg', 1),\n",
       " ('Desert', 1),\n",
       " ('Buck', 1),\n",
       " ('Lake', 1),\n",
       " ('Hawaii', 1),\n",
       " ('Scarlet', 1),\n",
       " ('Boston', 1),\n",
       " ('Italy', 1),\n",
       " ('Maine', 1),\n",
       " ('Michigan', 1),\n",
       " ('Creek', 1),\n",
       " ('York', 1)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_entities(plots, 'LOCATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Colonials', 2),\n",
       " ('Laurel', 2),\n",
       " ('Earth', 1),\n",
       " ('Police', 1),\n",
       " ('Enlightenment', 1),\n",
       " ('Station', 1),\n",
       " ('Beauty', 1),\n",
       " ('Southern', 1),\n",
       " ('Justice', 1),\n",
       " ('Miller', 1),\n",
       " ('Richard', 1),\n",
       " ('Space', 1),\n",
       " ('Corridor', 1),\n",
       " ('Church', 1),\n",
       " ('Systems', 1),\n",
       " ('Elysian', 1),\n",
       " ('Boston', 1),\n",
       " ('University', 1),\n",
       " ('Program', 1),\n",
       " ('United', 1)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_entities(plots, 'ORGANIZATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ariel', 10),\n",
       " ('Allison', 7),\n",
       " ('Liz', 5),\n",
       " ('Oliver', 5),\n",
       " ('Tammy', 4),\n",
       " ('Sarah', 4),\n",
       " ('Khalia', 4),\n",
       " ('Jake', 4),\n",
       " ('Remy', 3),\n",
       " ('Archie', 3),\n",
       " ('Cameron', 3),\n",
       " ('Nicholas', 3),\n",
       " ('Justin', 3),\n",
       " ('Madison', 3),\n",
       " ('Strider', 3),\n",
       " ('Thomason', 3),\n",
       " ('Michael', 3),\n",
       " ('Lewis', 3),\n",
       " ('Jennifer', 2),\n",
       " ('Kalia', 2),\n",
       " ('Andy', 2),\n",
       " ('Stuart', 2),\n",
       " ('Nick', 2),\n",
       " ('Marcus', 2),\n",
       " ('Tom', 2),\n",
       " ('Benny', 2),\n",
       " ('John', 2),\n",
       " ('Pearson', 2),\n",
       " ('Jonathan', 2),\n",
       " ('Toby', 2),\n",
       " ('Pandora', 2),\n",
       " ('Crenshaw', 2),\n",
       " ('Julius', 2),\n",
       " ('Neal', 2),\n",
       " ('Linda', 2),\n",
       " ('Pentupp', 2),\n",
       " ('Brandon', 2),\n",
       " ('Burke', 2),\n",
       " ('Lana', 2),\n",
       " ('Johnson', 2),\n",
       " ('Joe', 2),\n",
       " ('Michelle', 2),\n",
       " ('Vonnegut', 1),\n",
       " ('Sully', 1),\n",
       " ('Ted', 1),\n",
       " ('Natasha', 1),\n",
       " ('Maya', 1),\n",
       " ('Armie', 1),\n",
       " ('Cosmo', 1),\n",
       " ('Dillman', 1),\n",
       " ('Harrison', 1),\n",
       " ('Gabriel', 1),\n",
       " ('Apollo', 1),\n",
       " ('Holt', 1),\n",
       " ('Clarkson', 1),\n",
       " ('Hammer', 1),\n",
       " ('Julie', 1),\n",
       " ('Rose', 1),\n",
       " ('Hagerty', 1),\n",
       " ('Bergeron', 1),\n",
       " ('Bob', 1),\n",
       " ('Mackey', 1),\n",
       " ('Commodore', 1),\n",
       " ('Dawson', 1),\n",
       " ('HipSon', 1),\n",
       " ('Future', 1),\n",
       " ('Baldwon', 1),\n",
       " ('Magnus', 1),\n",
       " ('Angel', 1),\n",
       " ('Romanis', 1),\n",
       " ('Margaret', 1),\n",
       " ('Kapstan', 1),\n",
       " ('Aparna', 1),\n",
       " ('Brownsteen', 1),\n",
       " ('Depew', 1),\n",
       " ('Astro', 1),\n",
       " ('James', 1),\n",
       " ('Patricia', 1),\n",
       " ('Greg', 1),\n",
       " ('Penny', 1),\n",
       " ('Melon', 1),\n",
       " ('Lucreti', 1),\n",
       " ('Helmsley', 1),\n",
       " ('Nathan', 1),\n",
       " ('Rez', 1),\n",
       " ('Ghota', 1),\n",
       " ('Neytiri', 1),\n",
       " ('Akec', 1),\n",
       " ('Satnam', 1),\n",
       " ('Cackadoody', 1),\n",
       " ('Whackerman', 1),\n",
       " ('Vern', 1),\n",
       " ('Sally', 1),\n",
       " ('Slater', 1),\n",
       " ('Lev', 1),\n",
       " ('Skye', 1),\n",
       " ('Dawn', 1),\n",
       " ('Quaritch', 1),\n",
       " ('Diana', 1),\n",
       " ('Ricky', 1),\n",
       " ('Adrian', 1),\n",
       " ('Kurt', 1),\n",
       " ('Jay', 1),\n",
       " ('Sylvan', 1),\n",
       " ('Tsurutani', 1),\n",
       " ('Abner', 1),\n",
       " ('Marine', 1),\n",
       " ('Dick', 1),\n",
       " ('Winnifred', 1),\n",
       " ('Selfridge', 1),\n",
       " ('Parker', 1),\n",
       " ('Commissar', 1),\n",
       " ('Lara', 1),\n",
       " ('Hiccup', 1),\n",
       " ('Jim', 1),\n",
       " ('Praetors', 1),\n",
       " ('Patriot', 1),\n",
       " ('Tommy', 1),\n",
       " ('Jordan', 1),\n",
       " ('Kaufman', 1),\n",
       " ('Azura', 1),\n",
       " ('McBride', 1),\n",
       " ('Boy', 1),\n",
       " ('Wilbur', 1)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_entities(plots, 'PERSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that most of our movies are set in American cities but there are still \"India\", \"Istanbul\", \"Itaty\" appearing in Location entities. \"Earth\" and \"world\" appear multiple times, and despite the big cities, \"Desert\" and deserts or islands such as \"Mojave\" and \"Honolulu\" appear, which makes sense as the sci-fi movies are usually about space exploration and spaceships are usually launched in remote and humanless areas. The most frequent organization entity \"Colonials\" indicates some stories with aliens or robots. The most frequent names seems to be female names, though due to the limited data, I'm hesitated to draw any conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sacrifice</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pig</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>some</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ancient</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ethnic</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>group</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ent kind\n",
       "0        The    O\n",
       "1  sacrifice    O\n",
       "2         of    O\n",
       "3        pig    O\n",
       "4         in    O\n",
       "5       some    O\n",
       "6    ancient    O\n",
       "7     ethnic    O\n",
       "8      group    O\n",
       "9       from    O"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset the first five plots and store the automated tag of entities into a dataframe\n",
    "auto_codings = pandas.DataFrame()\n",
    "for entry in plots['classified_sents'][:5]:\n",
    "    for sentence in entry:\n",
    "        for ent, kind in sentence:\n",
    "            auto_codings = auto_codings.append([(ent, kind)], ignore_index = True)\n",
    "auto_codings = auto_codings.rename(columns={0: \"ent\", 1: \"kind\"})\n",
    "auto_codings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the auto codings\n",
    "auto_codings.to_csv('auto_codings.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent</th>\n",
       "      <th>kind</th>\n",
       "      <th>hand_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sacrifice</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pig</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>some</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ancient</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ethnic</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>group</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ent kind hand_code\n",
       "0        The    O         O\n",
       "1  sacrifice    O         O\n",
       "2         of    O         O\n",
       "3        pig    O         O\n",
       "4         in    O         O\n",
       "5       some    O         O\n",
       "6    ancient    O         O\n",
       "7     ethnic    O         O\n",
       "8      group    O         O\n",
       "9       from    O         O"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the hand codings\n",
    "hand_codings = pandas.read_csv('hand_codings.csv')\n",
    "hand_codings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCATION:\n",
      "Precision: 0.875\n",
      "Recall: 0.875\n",
      "F-1 measure: 0.7368421052631579\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print('LOCATION:')\n",
    "print('Precision:', sklearn.metrics.precision_score(hand_codings['hand_code'], hand_codings['kind'], labels = ['LOCATION'], average = 'micro')) #precision\n",
    "print('Recall:', sklearn.metrics.recall_score(hand_codings['kind'], hand_codings['hand_code'], labels = ['LOCATION'], average = 'micro')) #recall\n",
    "print('F-1 measure:', sklearn.metrics.f1_score(hand_codings['kind'], hand_codings['hand_code'], labels = ['LOCATION'], average = 'micro')) #F-1 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORGANIZATION:\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F-1 measure: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('ORGANIZATION:')\n",
    "print('Precision:', sklearn.metrics.precision_score(hand_codings['hand_code'], hand_codings['kind'], labels = ['ORGANIZATION'], average = 'micro')) #precision\n",
    "print('Recall:', sklearn.metrics.recall_score(hand_codings['kind'], hand_codings['hand_code'], labels = ['ORGANIZATION'], average = 'micro')) #recall\n",
    "print('F-1 measure:', sklearn.metrics.f1_score(hand_codings['kind'], hand_codings['hand_code'], labels = ['ORGANIZATION'], average = 'micro')) #F-1 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON:\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F-1 measure: 0.9473684210526316\n"
     ]
    }
   ],
   "source": [
    "print('PERSON:')\n",
    "print('Precision:', sklearn.metrics.precision_score(hand_codings['hand_code'], hand_codings['kind'], labels = ['PERSON'], average = 'micro')) #precision\n",
    "print('Recall:', sklearn.metrics.recall_score(hand_codings['kind'], hand_codings['hand_code'], labels = ['PERSON'], average = 'micro')) #recall\n",
    "print('F-1 measure:', sklearn.metrics.f1_score(hand_codings['kind'], hand_codings['hand_code'], labels = ['PERSON'], average = 'micro')) #F-1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "\n",
    "Here we will introduce the Stanford Parser by feeding it tokenized text from our initial example sentences. The parser is a dependency parser, but this initial program outputs a simple, self-explanatory phrase-structure representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('ROOT', [Tree('S', [Tree('NP', [Tree('NNP', ['Trayvon']), Tree('NNP', ['Benjamin']), Tree('NNP', ['Martin'])]), Tree('VP', [Tree('VBD', ['was']), Tree('NP', [Tree('NP', [Tree('DT', ['an']), Tree('NNP', ['African']), Tree('NNP', ['American'])]), Tree('PP', [Tree('IN', ['from']), Tree('NP', [Tree('NP', [Tree('NNP', ['Miami']), Tree('NNPS', ['Gardens'])]), Tree(',', [',']), Tree('NP', [Tree('NNP', ['Florida'])]), Tree(',', [',']), Tree('SBAR', [Tree('WHNP', [Tree('WP', ['who'])]), Tree('S', [Tree(',', [',']), Tree('PP', [Tree('IN', ['at']), Tree('ADJP', [Tree('NP', [Tree('CD', ['17']), Tree('NNS', ['years'])]), Tree('JJ', ['old'])])]), Tree(',', [',']), Tree('VP', [Tree('VBD', ['was']), Tree('ADVP', [Tree('RB', ['fatally'])]), Tree('VP', [Tree('VBN', ['shot']), Tree('PP', [Tree('IN', ['by']), Tree('NP', [Tree('NP', [Tree('NNP', ['George']), Tree('NNP', ['Zimmerman'])]), Tree(',', [',']), Tree('NP', [Tree('DT', ['a']), Tree('NN', ['neighborhood']), Tree('NN', ['watch']), Tree('NN', ['volunteer'])]), Tree(',', [','])])]), Tree('PP', [Tree('IN', ['in']), Tree('NP', [Tree('NNP', ['Sanford']), Tree(',', [',']), Tree('NNP', ['Florida'])])])])])])])])])])]), Tree('.', ['.'])])])]\n"
     ]
    }
   ],
   "source": [
    "parses = list(stanford.parser.parse_sents(tokenized_text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "fourthSentParseTree = list(parses[3]) #iterators so be careful about re-running code, without re-running this block\n",
    "print(fourthSentParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees are a common data structure and there are a large number of things to do with them. What we are interested in is the relationship between different types of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def treeRelation(parsetree, relationType, *targets):\n",
    "    if isinstance(parsetree, list):\n",
    "        parsetree = parsetree[0]\n",
    "    if set(targets) & set(parsetree.leaves()) != set(targets):\n",
    "        return []\n",
    "    else:\n",
    "        retList = []\n",
    "        for subT in parsetree.subtrees():\n",
    "            if subT.label() == relationType:\n",
    "                if set(targets) & set(subT.leaves()) == set(targets):\n",
    "                    retList.append([(subT.label(), ' '.join(subT.leaves()))])\n",
    "    return retList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def treeSubRelation(parsetree, relationTypeScope, relationTypeTarget, *targets):\n",
    "    if isinstance(parsetree, list):\n",
    "        parsetree = parsetree[0]\n",
    "    if set(targets) & set(parsetree.leaves()) != set(targets):\n",
    "        return []\n",
    "    else:\n",
    "        retSet = set()\n",
    "        for subT in parsetree.subtrees():\n",
    "            if set(targets) & set(subT.leaves()) == set(targets):\n",
    "                if subT.label() == relationTypeScope:\n",
    "                    for subsub in subT.subtrees():\n",
    "                        if subsub.label()==relationTypeTarget:\n",
    "                            retSet.add(' '.join(subsub.leaves()))\n",
    "    return retSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('NP',\n",
       "   'an African American from Miami Gardens , Florida , who , at 17 years old , was fatally shot by George Zimmerman , a neighborhood watch volunteer , in Sanford , Florida')],\n",
       " [('NP',\n",
       "   'Miami Gardens , Florida , who , at 17 years old , was fatally shot by George Zimmerman , a neighborhood watch volunteer , in Sanford , Florida')]]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeRelation(fourthSentParseTree, 'NP', 'Florida', 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Florida occurs twice in two different nested noun phrases in the sentence. \n",
    "\n",
    "We can also find all of the verbs within the noun phrase defined by one or more target words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shot'}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeSubRelation(fourthSentParseTree, 'NP', 'VBN', 'Florida', 'who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or if we want to to look at the whole tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                   ROOT                                                                                                                       \n",
      "                                                                                                                    |                                                                                                                          \n",
      "                                                                                                                    S                                                                                                                         \n",
      "            ________________________________________________________________________________________________________|_______________________________________________________________________________________________________________________   \n",
      "           |                       VP                                                                                                                                                                                                       | \n",
      "           |              _________|______________                                                                                                                                                                                          |  \n",
      "           |             |                        NP                                                                                                                                                                                        | \n",
      "           |             |          ______________|________________                                                                                                                                                                         |  \n",
      "           |             |         |                               PP                                                                                                                                                                       | \n",
      "           |             |         |               ________________|___________                                                                                                                                                             |  \n",
      "           |             |         |              |                            NP                                                                                                                                                           | \n",
      "           |             |         |              |           _________________|____________________________________                                                                                                                        |  \n",
      "           |             |         |              |          |           |     |     |                             SBAR                                                                                                                     | \n",
      "           |             |         |              |          |           |     |     |    __________________________|______________________________                                                                                         |  \n",
      "           |             |         |              |          |           |     |     |   |                                                         S                                                                                        | \n",
      "           |             |         |              |          |           |     |     |   |     ____________________________________________________|_______________________                                                                 |  \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |                                                 VP                                                               | \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |    _____________________________________________|_______                                                         |  \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |   |     |                                               VP                                                       | \n",
      "           |             |         |              |          |           |     |     |   |    |           |              |   |     |      _________________________________________|________________________________________                |  \n",
      "           |             |         |              |          |           |     |     |   |    |           PP             |   |     |     |                      PP                                                          |               | \n",
      "           |             |         |              |          |           |     |     |   |    |    _______|____          |   |     |     |     _________________|__________                                                 |               |  \n",
      "           |             |         |              |          |           |     |     |   |    |   |           ADJP       |   |     |     |    |                            NP                                               PP              | \n",
      "           |             |         |              |          |           |     |     |   |    |   |        ____|____     |   |     |     |    |           _________________|________________________________     ___________|___            |  \n",
      "           NP            |         NP             |          NP          |     NP    |  WHNP  |   |       NP        |    |   |    ADVP   |    |          NP            |           NP                       |   |               NP          | \n",
      "    _______|_______      |    _____|_______       |      ____|_____      |     |     |   |    |   |    ___|____     |    |   |     |     |    |     _____|______       |    _______|_________________       |   |      _________|_____      |  \n",
      "  NNP     NNP     NNP   VBD  DT   NNP     NNP     IN   NNP        NNPS   ,    NNP    ,   WP   ,   IN  CD      NNS   JJ   ,  VBD    RB   VBN   IN  NNP          NNP     ,   DT      NN        NN      NN     ,   IN   NNP        ,    NNP    . \n",
      "   |       |       |     |   |     |       |      |     |          |     |     |     |   |    |   |   |        |    |    |   |     |     |    |    |            |      |   |       |         |       |      |   |     |         |     |     |  \n",
      "Trayvon Benjamin Martin was  an African American from Miami     Gardens  ,  Florida  ,  who   ,   at  17     years old   ,  was fatally shot  by George     Zimmerman  ,   a  neighborhood watch volunteer  ,   in Sanford      ,  Florida  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fourthSentParseTree[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or another sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ROOT                           \n",
      "                      |                              \n",
      "                      S                             \n",
      "       _______________|___________________________   \n",
      "      |                          VP               | \n",
      "      |                __________|___             |  \n",
      "      |               |              PP           | \n",
      "      |               |      ________|___         |  \n",
      "      NP              |     |            NP       | \n",
      "  ____|__________     |     |     _______|____    |  \n",
      " DT   JJ    JJ   NN  VBD    IN   DT      JJ   NN  . \n",
      " |    |     |    |    |     |    |       |    |   |  \n",
      "The quick brown fox jumped over the     lazy dog  . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "list(parses[1])[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency parsing and graph representations\n",
    "\n",
    "Dependency parsing was developed to robustly capture linguistic dependencies from text. The complex tags associated with these parses are detailed [here](http://universaldependencies.org/u/overview/syntax.html). When parsing with the dependency parser, we will work directly from the untokenized text. Note that no *processing* takes place before parsing sentences--we do not remove so-called stop words or anything that plays a syntactic role in the sentence, although anaphora resolution and related normalization may be performed before or after parsing to enhance the value of information extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x113b162f0>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'root': [5]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'The'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'quick'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'brown'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'amod': [2, 3],\n",
      "                                      'det': [1]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 5,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'fox'},\n",
      "             5: {'address': 5,\n",
      "                 'ctag': 'VBD',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'nmod': [9],\n",
      "                                      'nsubj': [4]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 0,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'root',\n",
      "                 'tag': 'VBD',\n",
      "                 'word': 'jumped'},\n",
      "             6: {'address': 6,\n",
      "                 'ctag': 'IN',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'case',\n",
      "                 'tag': 'IN',\n",
      "                 'word': 'over'},\n",
      "             7: {'address': 7,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             8: {'address': 8,\n",
      "                 'ctag': 'JJ',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 9,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'amod',\n",
      "                 'tag': 'JJ',\n",
      "                 'word': 'lazy'},\n",
      "             9: {'address': 9,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'amod': [8],\n",
      "                                      'case': [6],\n",
      "                                      'det': [7]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 5,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nmod',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'dog'}})\n"
     ]
    }
   ],
   "source": [
    "depParses = list(stanford.depParser.raw_parse_sents(text)) #Converting the iterator to a list so we can call by index. They are still \n",
    "secondSentDepParseTree = list(depParses[1])[0] #iterators so be careful about re-running code, without re-running this block\n",
    "print(secondSentDepParseTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a graph and we can convert it to a dot file and use that to visulize it. Try traversing the tree and extracting elements that are nearby one another. We note that unless you have the graphviz successfully installed on your computer (which is not necessary to complete this homework), the following graphviz call will trigger an error. If you are interested in installing graphviz and working on a Mac, consider installing through [homebrew](https://brew.sh), a package manager (i.e., with the command \"brew install graphviz\", once brew is installed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"467pt\" height=\"302pt\"\n",
       " viewBox=\"0.00 0.00 467.37 302.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 298)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-298 463.3657,-298 463.3657,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"193.7949\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"193.7949\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (jumped)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M193.7949,-257.7616C193.7949,-246.3597 193.7949,-231.4342 193.7949,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"197.295,-218.2121 193.7949,-208.2121 190.295,-218.2121 197.295,-218.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"205.0708\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"152.7949\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (fox)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M184.9506,-171.6975C182.2192,-166.0286 179.2067,-159.7594 176.457,-154 172.9867,-146.731 169.2503,-138.8578 165.7948,-131.5568\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"168.7462,-129.6107 161.3081,-122.0658 162.4177,-132.6024 168.7462,-129.6107\"/>\n",
       "<text text-anchor=\"middle\" x=\"191.9639\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"316.7949\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (dog)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M219.5798,-171.9716C237.9481,-159.1286 262.8214,-141.7376 282.8098,-127.7619\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"284.8541,-130.6033 291.044,-122.0047 280.843,-124.8665 284.8541,-130.6033\"/>\n",
       "<text text-anchor=\"middle\" x=\"278.7397\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"28.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (The)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"108.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (quick)</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"195.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (brown)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M126.8005,-85.9716C108.2827,-73.1286 83.2073,-55.7376 63.0563,-41.7619\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"64.967,-38.8277 54.7552,-36.0047 60.9777,-44.5797 64.967,-38.8277\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.3467\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M143.4637,-85.7616C137.4551,-74.0176 129.534,-58.5355 122.7802,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"125.7834,-43.5204 118.1127,-36.2121 119.5517,-46.7088 125.7834,-43.5204\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.3467\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M161.9141,-85.7616C167.7861,-74.0176 175.5272,-58.5355 182.1275,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.3472,-46.7216 186.6889,-36.2121 179.0862,-43.5911 185.3472,-46.7216\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.3467\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"279.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (over)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;6 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>9&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M308.9482,-85.7616C303.9446,-74.1316 297.3638,-58.8357 291.721,-45.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.7976,-44.0148 287.6304,-36.2121 288.3674,-46.7813 294.7976,-44.0148\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.8398\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"354.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (the)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M324.8537,-85.7616C329.9926,-74.1316 336.7512,-58.8357 342.5466,-45.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"345.9074,-46.7736 346.7477,-36.2121 339.5046,-43.9444 345.9074,-46.7736\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.3467\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"429.7949\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (lazy)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;8 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>9&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M340.4834,-85.9716C357.2078,-73.2433 379.8019,-56.0478 398.0799,-42.1371\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"400.2997,-44.8461 406.1376,-36.0047 396.0604,-39.2758 400.2997,-44.8461\"/>\n",
       "<text text-anchor=\"middle\" x=\"396.3467\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1139ad5f8>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    secondSentGraph = graphviz.Source(secondSentDepParseTree.to_dot())\n",
    "except:\n",
    "    secondSentGraph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "secondSentGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or another sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"997pt\" height=\"560pt\"\n",
       " viewBox=\"0.00 0.00 996.96 560.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 556)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-556 992.9575,-556 992.9575,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"235.3833\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"235.3833\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (American)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;7 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M235.3833,-515.7616C235.3833,-504.3597 235.3833,-489.4342 235.3833,-476.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"238.8834,-476.2121 235.3833,-466.2121 231.8834,-476.2121 238.8834,-476.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"246.6592\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"77.3833\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (Martin)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>7&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M195.5259,-429.8504C183.9641,-424.3453 171.399,-418.1273 160.0454,-412 144.9107,-403.8322 128.6384,-394.1858 114.5678,-385.5556\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"116.0198,-382.3384 105.6735,-380.0569 112.3388,-388.2925 116.0198,-382.3384\"/>\n",
       "<text text-anchor=\"middle\" x=\"175.5522\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"161.3833\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (was)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;4 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>7&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M219.6898,-429.7616C209.1921,-417.5615 195.2231,-401.3273 183.5899,-387.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.2297,-385.5094 177.0542,-380.2121 180.9236,-390.0751 186.2297,-385.5094\"/>\n",
       "<text text-anchor=\"middle\" x=\"213.4902\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cop</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"235.3833\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (an)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;5 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M235.3833,-429.7616C235.3833,-418.3597 235.3833,-403.4342 235.3833,-390.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"238.8834,-390.2121 235.3833,-380.2121 231.8834,-390.2121 238.8834,-390.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"243.9351\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"319.3833\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (African)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M253.1975,-429.7616C265.2253,-417.4475 281.2673,-401.0235 294.5454,-387.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"297.1111,-389.8115 301.5947,-380.2121 292.1035,-384.9203 297.1111,-389.8115\"/>\n",
       "<text text-anchor=\"middle\" x=\"312.9351\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"421.3833\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (Gardens)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;10 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>7&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M281.035,-436.267C301.523,-430.2297 325.6866,-422.0184 346.3833,-412 361.1468,-404.8536 376.3934,-395.1776 389.2526,-386.2414\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"391.6132,-388.8578 397.7385,-380.213 387.5592,-383.1511 391.6132,-388.8578\"/>\n",
       "<text text-anchor=\"middle\" x=\"386.3281\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"41.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (Trayvon)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"146.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (Benjamin)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>3&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M69.7486,-343.7616C64.8803,-332.1316 58.4773,-316.8357 52.987,-303.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"56.097,-302.085 49.007,-294.2121 49.6399,-304.788 56.097,-302.085\"/>\n",
       "<text text-anchor=\"middle\" x=\"91.9351\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M105.7905,-343.9005C112.4839,-338.7035 119.1771,-332.628 124.3833,-326 129.5733,-319.3927 133.8059,-311.3704 137.1222,-303.7037\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"140.4118,-304.9025 140.8359,-294.3161 133.9027,-302.3275 140.4118,-304.9025\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.9351\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"274.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (from)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;8 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M376.5212,-344.6694C364.1537,-339.2688 350.9417,-332.9006 339.2935,-326 326.8103,-318.6047 313.97,-309.165 303.0389,-300.4839\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"305.0617,-297.6182 295.0895,-294.0398 300.6536,-303.0559 305.0617,-297.6182\"/>\n",
       "<text text-anchor=\"middle\" x=\"351.4282\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"360.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (Miami)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;9 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>10&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M391.2568,-343.6347C384.9071,-338.5898 378.7774,-332.6501 374.2798,-326 369.9075,-319.5352 366.903,-311.7204 364.8413,-304.2096\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"368.2186,-303.2775 362.5744,-294.3112 361.3952,-304.8402 368.2186,-303.2775\"/>\n",
       "<text text-anchor=\"middle\" x=\"403.9351\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"456.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12 (Florida)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;12 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>10&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M428.8059,-343.7616C433.539,-332.1316 439.7641,-316.8357 445.1019,-303.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"448.4436,-304.7938 448.9714,-294.2121 441.96,-302.1551 448.4436,-304.7938\"/>\n",
       "<text text-anchor=\"middle\" x=\"457.7144\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">appos</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"549.3833\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">23 (shot)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;23 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>10&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M450.562,-343.9652C459.5457,-338.3073 469.4264,-331.9769 478.3833,-326 490.7955,-317.7174 504.223,-308.3654 516.0254,-300.0089\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"518.1726,-302.7768 524.2944,-294.1295 514.1163,-297.0718 518.1726,-302.7768\"/>\n",
       "<text text-anchor=\"middle\" x=\"520.9214\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"341.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">14 (who)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;14 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>23&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M516.1602,-260.9769C513.2216,-259.8878 510.2679,-258.8756 507.3833,-258 465.6572,-245.3346 451.0323,-257.1374 410.9351,-240 396.1578,-233.6843 381.463,-223.7913 369.4142,-214.4665\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"371.5209,-211.6696 361.5269,-208.1526 367.1463,-217.1344 371.5209,-211.6696\"/>\n",
       "<text text-anchor=\"middle\" x=\"438.6074\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubjpass</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"423.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19 (old)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;19 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>23&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M516.1838,-257.9822C506.6151,-252.48 496.2767,-246.2305 487.0659,-240 475.5821,-232.2319 463.494,-223.0275 452.972,-214.6466\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"454.892,-211.6986 444.9108,-208.1451 450.4974,-217.1473 454.892,-211.6986\"/>\n",
       "<text text-anchor=\"middle\" x=\"502.542\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advcl</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"504.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">21 (was)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;21 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>23&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M538.2032,-257.8722C534.8316,-252.2105 531.1955,-245.9014 528.0591,-240 524.2785,-232.8864 520.4337,-225.0669 516.9726,-217.7676\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"519.9328,-215.8341 512.5329,-208.2517 513.5892,-218.7937 519.9328,-215.8341\"/>\n",
       "<text text-anchor=\"middle\" x=\"550.5454\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">auxpass</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>22</title>\n",
       "<text text-anchor=\"middle\" x=\"594.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">22 (fatally)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;22 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>23&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M561.88,-257.643C565.455,-252.0813 569.2329,-245.8848 572.3833,-240 576.1375,-232.9872 579.7933,-225.2024 583.0121,-217.9043\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"586.3752,-218.9423 587.0989,-208.3722 579.9415,-216.1839 586.3752,-218.9423\"/>\n",
       "<text text-anchor=\"middle\" x=\"601.9351\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"707.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">26 (Zimmerman)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;26 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>23&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M582.5441,-262.0972C596.8621,-255.7864 613.6686,-247.961 628.3833,-240 643.1389,-232.0169 658.8574,-222.3295 672.3559,-213.6153\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"674.4115,-216.4533 680.8734,-208.0572 670.586,-210.5911 674.4115,-216.4533\"/>\n",
       "<text text-anchor=\"middle\" x=\"667.3281\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"856.3833\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">36 (Florida)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;36 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>23&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M582.6464,-267.6451C610.6488,-260.5344 651.722,-249.924 687.3833,-240 726.7862,-229.0348 771.1175,-215.8883 804.4873,-205.8282\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"805.9136,-209.0536 814.474,-202.811 803.889,-202.3527 805.9136,-209.0536\"/>\n",
       "<text text-anchor=\"middle\" x=\"750.3281\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"391.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">16 (at)</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"472.3833\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">17 (17)</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"472.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18 (years)</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;17 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>18&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M472.3833,-85.7616C472.3833,-74.3597 472.3833,-59.4342 472.3833,-46.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"475.8834,-46.2121 472.3833,-36.2121 468.8834,-46.2121 475.8834,-46.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"497.2729\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nummod</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;16 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>19&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M416.5969,-171.7616C412.2695,-160.1316 406.578,-144.8357 401.6977,-131.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"404.9276,-130.3637 398.1599,-122.2121 398.367,-132.8049 404.9276,-130.3637\"/>\n",
       "<text text-anchor=\"middle\" x=\"421.4282\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;18 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>19&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M433.7749,-171.7616C440.5313,-159.9036 449.459,-144.2345 457.0275,-130.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"460.0971,-132.6334 462.0066,-122.2121 454.0151,-129.1681 460.0971,-132.6334\"/>\n",
       "<text text-anchor=\"middle\" x=\"488.7178\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod:npmod</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"567.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">24 (by)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;24 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>26&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M668.1869,-171.9496C657.328,-166.5419 645.6763,-160.3501 635.2935,-154 622.6297,-146.2549 609.3446,-136.8017 597.9168,-128.2084\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"600.0333,-125.4208 589.9593,-122.1398 595.7884,-130.9869 600.0333,-125.4208\"/>\n",
       "<text text-anchor=\"middle\" x=\"647.4282\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"655.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">25 (George)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;25 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>26&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M684.2392,-171.951C678.6851,-166.6739 673.2261,-160.5473 669.2798,-154 665.2509,-147.3157 662.3575,-139.4301 660.2923,-131.9215\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"663.6687,-130.9902 657.9608,-122.0643 656.8567,-132.6015 663.6687,-130.9902\"/>\n",
       "<text text-anchor=\"middle\" x=\"698.9351\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"763.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">31 (volunteer)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;31 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>26&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M719.2595,-171.7616C726.981,-159.9036 737.1841,-144.2345 745.8338,-130.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"749.0005,-132.502 751.5243,-122.2121 743.1345,-128.6822 749.0005,-132.502\"/>\n",
       "<text text-anchor=\"middle\" x=\"755.7144\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">appos</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"856.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">33 (in)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;33 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>36&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M856.3833,-171.7616C856.3833,-160.3597 856.3833,-145.4342 856.3833,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"859.8834,-132.2121 856.3833,-122.2121 852.8834,-132.2121 859.8834,-132.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"868.4282\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"945.3833\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">34 (Sanford)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;34 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>36&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M875.2579,-171.7616C888.0016,-159.4475 904.9985,-143.0235 919.067,-129.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"921.7767,-131.6779 926.5359,-122.2121 916.9125,-126.644 921.7767,-131.6779\"/>\n",
       "<text text-anchor=\"middle\" x=\"934.9351\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"658.3833\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">28 (a)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;28 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>31&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M741.3719,-85.9716C725.9715,-73.358 705.2148,-56.3573 688.313,-42.5139\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"690.3198,-39.6334 680.3658,-36.0047 685.8843,-45.0488 690.3198,-39.6334\"/>\n",
       "<text text-anchor=\"middle\" x=\"725.9351\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"763.3833\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">29 (neighborhood)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M763.3833,-85.7616C763.3833,-74.3597 763.3833,-59.4342 763.3833,-46.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"766.8834,-46.2121 763.3833,-36.2121 759.8834,-46.2121 766.8834,-46.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"792.9351\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"879.3833\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">30 (watch)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M798.3154,-85.9914C807.713,-80.629 817.6789,-74.4499 826.3833,-68 836.2881,-60.6606 846.3323,-51.6634 854.9744,-43.3341\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"857.5027,-45.7565 862.1694,-36.2448 852.5896,-40.7703 857.5027,-45.7565\"/>\n",
       "<text text-anchor=\"middle\" x=\"873.9351\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1139be4e0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    graph = graphviz.Source(list(depParses[3])[0].to_dot())\n",
    "except IndexError:\n",
    "    print(\"You likely have to rerun the depParses\")\n",
    "    raise\n",
    "except:\n",
    "    graph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do a dependency parse on the reddit sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topPostDepParse = list(stanford.depParser.parse_sents(redditTopScores['sentences'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a few seconds, but now lets look at the parse tree from one of the processed sentences.\n",
    "\n",
    "The sentence is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So anyway , I get a call from an older gentleman who 's quite bitter and mean right off the bat ( does n't like that I asked for his address / telephone number to verify the account , hates that he has to speak with a machine before reaching an agent , etc . ) .\n"
     ]
    }
   ],
   "source": [
    "targetSentence = 7\n",
    "print(' '.join(redditTopScores['sentences'][0][targetSentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which leads to a very rich dependancy tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"1014pt\" height=\"818pt\"\n",
       " viewBox=\"0.00 0.00 1014.21 818.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 814)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-814 1010.207,-814 1010.207,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"207.2432\" y=\"-787.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"207.2432\" y=\"-701.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (get)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;5 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M207.2432,-773.7616C207.2432,-762.3597 207.2432,-747.4342 207.2432,-734.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"210.7433,-734.2121 207.2432,-724.2121 203.7433,-734.2121 210.7433,-734.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"218.519\" y=\"-744.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"37.2432\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (So)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M180.0991,-700.0143C157.3043,-694.3052 124.3518,-684.4249 98.1396,-670 85.8462,-663.2347 73.6272,-653.8632 63.3969,-645.0603\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.4559,-642.2079 55.6552,-638.1831 60.8069,-647.4412 65.4559,-642.2079\"/>\n",
       "<text text-anchor=\"middle\" x=\"120.7949\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"122.2432\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (anyway)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M180.0131,-688.3776C172.5318,-682.9299 164.6844,-676.6103 158.1396,-670 151.1828,-662.9735 144.5653,-654.4941 138.9508,-646.5301\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"141.7966,-644.4907 133.2834,-638.1838 136.0055,-648.423 141.7966,-644.4907\"/>\n",
       "<text text-anchor=\"middle\" x=\"180.7949\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"207.2432\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (I)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M207.2432,-687.7616C207.2432,-676.3597 207.2432,-661.4342 207.2432,-648.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"210.7433,-648.2121 207.2432,-638.2121 203.7433,-648.2121 210.7433,-648.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"222.4121\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 34 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>34</title>\n",
       "<text text-anchor=\"middle\" x=\"295.2432\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">34 (number)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;34 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5&#45;&gt;34</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M225.9057,-687.7616C238.5062,-675.4475 255.3121,-659.0235 269.2225,-645.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"271.9019,-647.7046 276.6075,-638.2121 267.0094,-642.6983 271.9019,-647.7046\"/>\n",
       "<text text-anchor=\"middle\" x=\"267.3501\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dep</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"450.2432\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (call)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M234.646,-696.3019C278.1919,-680.8906 363.2883,-650.7742 412.5475,-633.3409\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"413.9335,-636.5631 422.1928,-629.9273 411.598,-629.9642 413.9335,-636.5631\"/>\n",
       "<text text-anchor=\"middle\" x=\"356.688\" y=\"-658.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"133.2432\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">25 (like)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;25 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>34&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M261.2827,-601.9716C235.9692,-588.5336 201.276,-570.1162 174.3874,-555.842\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"175.704,-552.5783 165.2303,-550.9808 172.4217,-558.7612 175.704,-552.5783\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.3501\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dep</text>\n",
       "</g>\n",
       "<!-- 33 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>33</title>\n",
       "<text text-anchor=\"middle\" x=\"252.2432\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">33 (telephone)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;33 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>34&#45;&gt;33</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M277.2835,-601.7041C272.7881,-596.3406 268.3405,-590.2327 265.1396,-584 261.688,-577.279 259.1113,-569.564 257.2075,-562.238\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"260.5743,-561.2589 254.9431,-552.2844 253.7487,-562.8117 260.5743,-561.2589\"/>\n",
       "<text text-anchor=\"middle\" x=\"294.7949\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound</text>\n",
       "</g>\n",
       "<!-- 36 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>36</title>\n",
       "<text text-anchor=\"middle\" x=\"357.2432\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">36 (verify)</text>\n",
       "</g>\n",
       "<!-- 34&#45;&gt;36 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>34&#45;&gt;36</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M310.3378,-601.948C314.9187,-596.2894 319.8887,-589.9629 324.2432,-584 329.6217,-576.6347 335.1875,-568.4487 340.181,-560.8685\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"343.2143,-562.6242 345.7348,-552.3336 337.3471,-558.8064 343.2143,-562.6242\"/>\n",
       "<text text-anchor=\"middle\" x=\"342.4019\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"450.2432\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (a)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M450.2432,-601.7616C450.2432,-590.3597 450.2432,-575.4342 450.2432,-562.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"453.7433,-562.2121 450.2432,-552.2121 446.7433,-562.2121 453.7433,-562.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"458.7949\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"550.2432\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">11 (gentleman)</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;11 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>7&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M471.4506,-601.7616C485.9019,-589.3335 505.221,-572.719 521.1125,-559.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"523.7666,-561.3862 529.0663,-552.2121 519.2023,-556.0789 523.7666,-561.3862\"/>\n",
       "<text text-anchor=\"middle\" x=\"522.188\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"473.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (from)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;8 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>11&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M533.9134,-515.7616C522.9901,-503.5615 508.4548,-487.3273 496.35,-473.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"498.8274,-471.3276 489.5493,-466.2121 493.6123,-475.9969 498.8274,-471.3276\"/>\n",
       "<text text-anchor=\"middle\" x=\"529.2881\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"550.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (an)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;9 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>11&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M550.2432,-515.7616C550.2432,-504.3597 550.2432,-489.4342 550.2432,-476.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"553.7433,-476.2121 550.2432,-466.2121 546.7433,-476.2121 553.7433,-476.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"558.7949\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"631.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (older)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M567.4212,-515.7616C578.912,-503.5615 594.2023,-487.3273 606.936,-473.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"609.7814,-475.8913 614.0899,-466.2121 604.6858,-471.0919 609.7814,-475.8913\"/>\n",
       "<text text-anchor=\"middle\" x=\"611.7949\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"721.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">15 (bitter)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;15 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>11&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M593.0332,-515.8322C605.4626,-510.3267 618.987,-504.113 631.2432,-498 647.9569,-489.6637 666.0209,-479.8025 681.5483,-471.05\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"683.3984,-474.0245 690.3681,-466.0448 679.9435,-467.9365 683.3984,-474.0245\"/>\n",
       "<text text-anchor=\"middle\" x=\"679.7813\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"563.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12 (who)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;12 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>15&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M684.884,-432.4737C671.4995,-426.4508 656.3352,-419.2608 642.9053,-412 628.0589,-403.9733 612.215,-394.2776 598.5992,-385.5689\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"600.305,-382.504 590.0064,-380.0161 596.5057,-388.3833 600.305,-382.504\"/>\n",
       "<text text-anchor=\"middle\" x=\"658.4121\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"641.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">13 (&#39;s)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;13 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>15&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M704.2772,-429.7616C692.9283,-417.5615 677.8267,-401.3273 665.2502,-387.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"667.5584,-385.1501 658.1847,-380.2121 662.4331,-389.9179 667.5584,-385.1501\"/>\n",
       "<text text-anchor=\"middle\" x=\"696.3501\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cop</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"721.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">14 (quite)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;14 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>15&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M721.2432,-429.7616C721.2432,-418.3597 721.2432,-403.4342 721.2432,-390.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"724.7433,-390.2121 721.2432,-380.2121 717.7433,-390.2121 724.7433,-390.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"743.7949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"806.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">16 (and)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M748.9176,-429.9916C756.2288,-424.6292 763.8548,-418.45 770.2432,-412 777.2081,-404.9678 783.8413,-396.4869 789.4727,-388.5232\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"792.4204,-390.4128 795.1585,-380.1779 786.6355,-386.4715 792.4204,-390.4128\"/>\n",
       "<text text-anchor=\"middle\" x=\"788.457\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cc</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"892.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">17 (mean)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>15&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M757.4665,-431.5318C770.4032,-425.5274 785.0405,-418.5922 798.2432,-412 815.3854,-403.4407 834.0569,-393.6154 850.2088,-384.9525\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"852.2519,-387.8276 859.397,-380.0047 848.9329,-381.6644 852.2519,-387.8276\"/>\n",
       "<text text-anchor=\"middle\" x=\"837.2949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conj</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"854.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18 (right)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M873.8839,-343.8974C869.3869,-338.5346 865.0384,-332.3788 862.1396,-326 859.0753,-319.2569 857.1728,-311.5343 855.9993,-304.2081\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"859.4705,-303.7587 854.7805,-294.2585 852.5224,-304.6099 859.4705,-303.7587\"/>\n",
       "<text text-anchor=\"middle\" x=\"884.7949\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advmod</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"937.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">21 (bat)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;21 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>17&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M901.7865,-343.7616C907.9316,-332.0176 916.0327,-316.5355 922.94,-303.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"926.1784,-304.6951 927.7136,-294.2121 919.9762,-301.4497 926.1784,-304.6951\"/>\n",
       "<text text-anchor=\"middle\" x=\"934.188\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"899.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19 (off)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;19 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>21&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M929.1843,-257.7616C924.0455,-246.1316 917.2869,-230.8357 911.4915,-217.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"914.5335,-215.9444 907.2904,-208.2121 908.1307,-218.7736 914.5335,-215.9444\"/>\n",
       "<text text-anchor=\"middle\" x=\"933.2881\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"976.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">20 (the)</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;20 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>21&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M945.5141,-257.7616C950.8398,-246.0176 957.8608,-230.5355 963.8471,-217.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"967.0416,-218.7649 967.9842,-208.2121 960.6665,-215.8739 967.0416,-218.7649\"/>\n",
       "<text text-anchor=\"middle\" x=\"966.7949\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"34.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">23 (does)</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"114.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">24 (n&#39;t)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;23 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>25&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M112.2478,-515.7616C97.941,-503.3335 78.8151,-486.719 63.0825,-473.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.0529,-470.1279 55.2083,-466.2121 60.4623,-475.4124 65.0529,-470.1279\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.3501\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">aux</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;24 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>25&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M129.2138,-515.7616C126.6695,-504.2456 123.3312,-489.1353 120.4527,-476.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"123.8417,-475.2216 118.2668,-466.2121 117.0065,-476.7317 123.8417,-475.2216\"/>\n",
       "<text text-anchor=\"middle\" x=\"135.3501\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">neg</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"197.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">28 (asked)</text>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;28 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>25&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M146.8159,-515.7616C155.7253,-503.7896 167.5257,-487.9328 177.4712,-474.5685\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"180.5277,-476.324 183.69,-466.2121 174.912,-472.1449 180.5277,-476.324\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.9019\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ccomp</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"54.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">26 (that)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;26 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>28&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M160.7847,-429.8674C150.2297,-424.3627 138.7795,-418.1406 128.4775,-412 114.9215,-403.9198 100.4376,-394.3813 87.8957,-385.8132\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.7783,-382.86 79.5583,-380.0664 85.8056,-388.6235 89.7783,-382.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"143.626\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>27</title>\n",
       "<text text-anchor=\"middle\" x=\"131.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">27 (I)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;27 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>28&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M183.2463,-429.7616C173.9709,-417.6756 161.6572,-401.6304 151.3405,-388.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"154.0847,-386.0143 145.2199,-380.2121 148.5315,-390.2761 154.0847,-386.0143\"/>\n",
       "<text text-anchor=\"middle\" x=\"183.4121\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 31 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>31</title>\n",
       "<text text-anchor=\"middle\" x=\"218.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">31 (address)</text>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;31 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>28&#45;&gt;31</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M201.6967,-429.7616C204.5088,-418.2456 208.1985,-403.1353 211.38,-390.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"214.8239,-390.757 213.796,-380.2121 208.0237,-389.0964 214.8239,-390.757\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.188\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"148.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">29 (for)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;29 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>31&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M203.398,-343.7616C193.5605,-331.6756 180.5005,-315.6304 169.5585,-302.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"172.0942,-299.7583 163.067,-294.2121 166.6652,-304.1772 172.0942,-299.7583\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.2881\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"225.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">30 (his)</text>\n",
       "</g>\n",
       "<!-- 31&#45;&gt;30 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>31&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M219.7277,-343.7616C220.6557,-332.3597 221.8706,-317.4342 222.9239,-304.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"226.4379,-304.4631 223.7608,-294.2121 219.461,-303.8952 226.4379,-304.4631\"/>\n",
       "<text text-anchor=\"middle\" x=\"252.5811\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 35 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>35</title>\n",
       "<text text-anchor=\"middle\" x=\"292.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">35 (to)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;35 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>36&#45;&gt;35</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M343.4583,-515.7616C334.4097,-503.7896 322.4249,-487.9328 312.324,-474.5685\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.83,-472.0794 306.0081,-466.2121 309.2456,-476.3002 314.83,-472.0794\"/>\n",
       "<text text-anchor=\"middle\" x=\"343.626\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 38 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>38</title>\n",
       "<text text-anchor=\"middle\" x=\"380.2432\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">38 (account)</text>\n",
       "</g>\n",
       "<!-- 36&#45;&gt;38 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>36&#45;&gt;38</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M362.1209,-515.7616C365.2007,-504.2456 369.2419,-489.1353 372.7263,-476.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"376.17,-476.7769 375.3725,-466.2121 369.4076,-474.9683 376.17,-476.7769\"/>\n",
       "<text text-anchor=\"middle\" x=\"382.688\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 37 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>37</title>\n",
       "<text text-anchor=\"middle\" x=\"308.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">37 (the)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;37 -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>38&#45;&gt;37</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M364.9738,-429.7616C354.8553,-417.6756 341.4221,-401.6304 330.1675,-388.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"332.5936,-385.6329 323.4905,-380.2121 327.2262,-390.1265 332.5936,-385.6329\"/>\n",
       "<text text-anchor=\"middle\" x=\"357.7949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 40 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>40</title>\n",
       "<text text-anchor=\"middle\" x=\"392.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">40 (hates)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;40 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>38&#45;&gt;40</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M382.7881,-429.7616C384.379,-418.3597 386.4617,-403.4342 388.2673,-390.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"391.7863,-390.5999 389.7019,-380.2121 384.8535,-389.6324 391.7863,-390.5999\"/>\n",
       "<text text-anchor=\"middle\" x=\"399.2949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conj</text>\n",
       "</g>\n",
       "<!-- 54 -->\n",
       "<g id=\"node38\" class=\"node\">\n",
       "<title>54</title>\n",
       "<text text-anchor=\"middle\" x=\"475.2432\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">54 (etc)</text>\n",
       "</g>\n",
       "<!-- 38&#45;&gt;54 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>38&#45;&gt;54</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M400.3902,-429.7616C414.119,-417.3335 432.4721,-400.719 447.569,-387.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"450.0605,-389.518 455.1251,-380.2121 445.3627,-384.3286 450.0605,-389.518\"/>\n",
       "<text text-anchor=\"middle\" x=\"446.2949\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conj</text>\n",
       "</g>\n",
       "<!-- 50 -->\n",
       "<g id=\"node39\" class=\"node\">\n",
       "<title>50</title>\n",
       "<text text-anchor=\"middle\" x=\"332.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">50 (reaching)</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;50 -->\n",
       "<g id=\"edge38\" class=\"edge\">\n",
       "<title>40&#45;&gt;50</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M379.5187,-343.7616C371.1661,-331.7896 360.1033,-315.9328 350.7793,-302.5685\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"353.5416,-300.4107 344.9493,-294.2121 347.8007,-304.416 353.5416,-300.4107\"/>\n",
       "<text text-anchor=\"middle\" x=\"381.4019\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">advcl</text>\n",
       "</g>\n",
       "<!-- 43 -->\n",
       "<g id=\"node40\" class=\"node\">\n",
       "<title>43</title>\n",
       "<text text-anchor=\"middle\" x=\"461.2432\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">43 (has)</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;43 -->\n",
       "<g id=\"edge39\" class=\"edge\">\n",
       "<title>40&#45;&gt;43</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M406.8763,-343.7616C416.5732,-331.6756 429.4467,-315.6304 440.2324,-302.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"443.103,-304.2023 446.6311,-294.2121 437.6431,-299.8216 443.103,-304.2023\"/>\n",
       "<text text-anchor=\"middle\" x=\"449.9019\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ccomp</text>\n",
       "</g>\n",
       "<!-- 49 -->\n",
       "<g id=\"node48\" class=\"node\">\n",
       "<title>49</title>\n",
       "<text text-anchor=\"middle\" x=\"238.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">49 (before)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;49 -->\n",
       "<g id=\"edge47\" class=\"edge\">\n",
       "<title>50&#45;&gt;49</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M312.3082,-257.7616C298.724,-245.3335 280.564,-228.719 265.626,-215.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"267.89,-212.3799 258.1494,-208.2121 263.1649,-217.5446 267.89,-212.3799\"/>\n",
       "<text text-anchor=\"middle\" x=\"305.626\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 52 -->\n",
       "<g id=\"node49\" class=\"node\">\n",
       "<title>52</title>\n",
       "<text text-anchor=\"middle\" x=\"332.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">52 (agent)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;52 -->\n",
       "<g id=\"edge48\" class=\"edge\">\n",
       "<title>50&#45;&gt;52</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M332.2432,-257.7616C332.2432,-246.3597 332.2432,-231.4342 332.2432,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"335.7433,-218.2121 332.2432,-208.2121 328.7433,-218.2121 335.7433,-218.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"344.688\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 41 -->\n",
       "<g id=\"node41\" class=\"node\">\n",
       "<title>41</title>\n",
       "<text text-anchor=\"middle\" x=\"418.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">41 (that)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;41 -->\n",
       "<g id=\"edge41\" class=\"edge\">\n",
       "<title>43&#45;&gt;41</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M452.124,-257.7616C446.252,-246.0176 438.5109,-230.5355 431.9106,-217.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"434.9519,-215.5911 427.3492,-208.2121 428.6909,-218.7216 434.9519,-215.5911\"/>\n",
       "<text text-anchor=\"middle\" x=\"457.626\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 42 -->\n",
       "<g id=\"node42\" class=\"node\">\n",
       "<title>42</title>\n",
       "<text text-anchor=\"middle\" x=\"496.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">42 (he)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;42 -->\n",
       "<g id=\"edge42\" class=\"edge\">\n",
       "<title>43&#45;&gt;42</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M468.6658,-257.7616C473.3989,-246.1316 479.624,-230.8357 484.9618,-217.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"488.3035,-218.7938 488.8313,-208.2121 481.8198,-216.1551 488.3035,-218.7938\"/>\n",
       "<text text-anchor=\"middle\" x=\"496.4121\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 45 -->\n",
       "<g id=\"node43\" class=\"node\">\n",
       "<title>45</title>\n",
       "<text text-anchor=\"middle\" x=\"579.2432\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">45 (speak)</text>\n",
       "</g>\n",
       "<!-- 43&#45;&gt;45 -->\n",
       "<g id=\"edge40\" class=\"edge\">\n",
       "<title>43&#45;&gt;45</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M489.2659,-257.8955C497.7059,-252.2887 506.9317,-246.0042 515.2432,-240 526.4263,-231.9213 538.41,-222.7141 548.9487,-214.4211\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"551.3826,-216.9582 557.0479,-208.0053 547.036,-211.4712 551.3826,-216.9582\"/>\n",
       "<text text-anchor=\"middle\" x=\"552.2949\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">xcomp</text>\n",
       "</g>\n",
       "<!-- 44 -->\n",
       "<g id=\"node44\" class=\"node\">\n",
       "<title>44</title>\n",
       "<text text-anchor=\"middle\" x=\"543.2432\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">44 (to)</text>\n",
       "</g>\n",
       "<!-- 45&#45;&gt;44 -->\n",
       "<g id=\"edge44\" class=\"edge\">\n",
       "<title>45&#45;&gt;44</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M571.1225,-171.7289C568.6357,-166.0614 565.9142,-159.785 563.4775,-154 560.4286,-146.7615 557.2055,-138.8989 554.2496,-131.5982\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"557.4079,-130.0712 550.4259,-122.1023 550.9145,-132.6859 557.4079,-130.0712\"/>\n",
       "<text text-anchor=\"middle\" x=\"578.626\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 48 -->\n",
       "<g id=\"node45\" class=\"node\">\n",
       "<title>48</title>\n",
       "<text text-anchor=\"middle\" x=\"633.2432\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">48 (machine)</text>\n",
       "</g>\n",
       "<!-- 45&#45;&gt;48 -->\n",
       "<g id=\"edge43\" class=\"edge\">\n",
       "<title>45&#45;&gt;48</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M590.6952,-171.7616C598.1409,-159.9036 607.9796,-144.2345 616.3204,-130.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"619.4541,-132.5422 621.8077,-122.2121 613.5258,-128.8198 619.4541,-132.5422\"/>\n",
       "<text text-anchor=\"middle\" x=\"626.188\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 46 -->\n",
       "<g id=\"node46\" class=\"node\">\n",
       "<title>46</title>\n",
       "<text text-anchor=\"middle\" x=\"594.2432\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">46 (with)</text>\n",
       "</g>\n",
       "<!-- 48&#45;&gt;46 -->\n",
       "<g id=\"edge45\" class=\"edge\">\n",
       "<title>48&#45;&gt;46</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M624.9723,-85.7616C619.6465,-74.0176 612.6255,-58.5355 606.6392,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"609.8198,-43.8739 602.5021,-36.2121 603.4447,-46.7649 609.8198,-43.8739\"/>\n",
       "<text text-anchor=\"middle\" x=\"628.2881\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 47 -->\n",
       "<g id=\"node47\" class=\"node\">\n",
       "<title>47</title>\n",
       "<text text-anchor=\"middle\" x=\"673.2432\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">47 (a)</text>\n",
       "</g>\n",
       "<!-- 48&#45;&gt;47 -->\n",
       "<g id=\"edge46\" class=\"edge\">\n",
       "<title>48&#45;&gt;47</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M641.7261,-85.7616C647.1885,-74.0176 654.3895,-58.5355 660.5293,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"663.7286,-46.7554 664.7724,-36.2121 657.3815,-43.8032 663.7286,-46.7554\"/>\n",
       "<text text-anchor=\"middle\" x=\"664.7949\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 51 -->\n",
       "<g id=\"node50\" class=\"node\">\n",
       "<title>51</title>\n",
       "<text text-anchor=\"middle\" x=\"332.2432\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">51 (an)</text>\n",
       "</g>\n",
       "<!-- 52&#45;&gt;51 -->\n",
       "<g id=\"edge49\" class=\"edge\">\n",
       "<title>52&#45;&gt;51</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M332.2432,-171.7616C332.2432,-160.3597 332.2432,-145.4342 332.2432,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"335.7433,-132.2121 332.2432,-122.2121 328.7433,-132.2121 335.7433,-132.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"340.7949\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x113b57550>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    graph = graphviz.Source(list(topPostDepParse[targetSentence])[0].to_dot())\n",
    "except IndexError:\n",
    "    print(\"You likely have to rerun the depParses\")\n",
    "    raise\n",
    "except:\n",
    "    graph = None\n",
    "    print(\"There was a problem with graphviz, likely your missing the program, https://www.graphviz.org/download/\")\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, parse a (modest) subset of your corpus of interest. How deep are the phrase structure and dependency parse trees nested? How does parse depth relate to perceived sentence complexity? What are five things you can extract from these parses for subsequent analysis? (e.g., nouns collocated in a noun phrase; adjectives that modify a noun; etc.) Capture these sets of things for a focal set of words (e.g., \"Bush\", \"Obama\", \"Trump\"). What do they reveal about the roles that these entities are perceived to play in the social world inscribed by your texts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse the first plot summary in our sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PlotParse = list(stanford.depParser.parse_sents(plots['sentences'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's take a look at the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sacrifice of pig in some ancient ethnic group from the south of Italy , to represent the brutality of human beings rooted in every aspect of our contemporary society .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(plots['sentences'][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's parse it and look at the dependency tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"798pt\" height=\"646pt\"\n",
       " viewBox=\"0.00 0.00 798.28 646.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 642)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-642 794.2847,-642 794.2847,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"352\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"352\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">23 (rooted)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;23 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M352,-601.7616C352,-590.3597 352,-575.4342 352,-562.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"355.5001,-562.2121 352,-552.2121 348.5001,-562.2121 355.5001,-562.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.2759\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"304\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (sacrifice)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;2 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>23&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M341.8204,-515.7616C335.202,-503.9036 326.4565,-488.2345 319.0424,-474.951\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"322.0948,-473.2383 314.1649,-466.2121 315.9824,-476.6499 322.0948,-473.2383\"/>\n",
       "<text text-anchor=\"middle\" x=\"346.1689\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>26</title>\n",
       "<text text-anchor=\"middle\" x=\"434\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">26 (aspect)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;26 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>23&#45;&gt;26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M369.3901,-515.7616C381.0227,-503.5615 396.5018,-487.3273 409.3927,-473.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"412.2673,-475.8648 416.635,-466.2121 407.2011,-471.0342 412.2673,-475.8648\"/>\n",
       "<text text-anchor=\"middle\" x=\"413.9448\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (The)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M288.3065,-429.7616C277.8088,-417.5615 263.8398,-401.3273 252.2066,-387.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"254.8464,-385.5094 245.6709,-380.2121 249.5403,-390.0751 254.8464,-385.5094\"/>\n",
       "<text text-anchor=\"middle\" x=\"280.5518\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"304\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (pig)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M304,-429.7616C304,-418.3597 304,-403.4342 304,-390.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"307.5001,-390.2121 304,-380.2121 300.5001,-390.2121 307.5001,-390.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.9448\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"206\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (of)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M283.2167,-343.7616C269.0544,-331.3335 250.1217,-314.719 234.5481,-301.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"236.5782,-298.1773 226.7533,-294.2121 231.961,-303.4387 236.5782,-298.1773\"/>\n",
       "<text text-anchor=\"middle\" x=\"273.0449\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"285\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (group)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;9 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M299.9706,-343.7616C297.4264,-332.2456 294.088,-317.1353 291.2095,-304.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"294.5985,-303.2216 289.0236,-294.2121 287.7634,-304.7317 294.5985,-303.2216\"/>\n",
       "<text text-anchor=\"middle\" x=\"311.9448\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"453\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">17 (represent)</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;17 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M331.3289,-346.2263C354.1754,-333.0397 387.0761,-314.05 412.9059,-299.1415\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"414.8081,-302.0849 421.7193,-294.0546 411.3088,-296.0223 414.8081,-302.0849\"/>\n",
       "<text text-anchor=\"middle\" x=\"396.1587\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (in)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;5 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M250.4739,-260.8905C247.6306,-259.8475 244.7812,-258.8678 242,-258 205.1,-246.4862 194.1804,-250.2523 156.9102,-240 117.2182,-229.0816 105.2446,-225.4845 63.6787,-208.0788\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"64.9138,-204.8013 54.3392,-204.1474 62.198,-211.253 64.9138,-204.8013\"/>\n",
       "<text text-anchor=\"middle\" x=\"169.0449\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"105\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (some)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;6 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M250.7197,-259.6216C221.3238,-245.5769 178.8531,-225.2854 147.3396,-210.2289\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"148.4698,-206.89 137.9379,-205.737 145.452,-213.2061 148.4698,-206.89\"/>\n",
       "<text text-anchor=\"middle\" x=\"214.5518\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"194\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (ancient)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M265.7012,-257.7616C252.6712,-245.4475 235.2924,-229.0235 220.9077,-215.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"222.9429,-212.5369 213.2709,-208.2121 218.1349,-217.6245 222.9429,-212.5369\"/>\n",
       "<text text-anchor=\"middle\" x=\"260.5518\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"285\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (ethnic)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>9&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M285,-257.7616C285,-246.3597 285,-231.4342 285,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"288.5001,-218.2121 285,-208.2121 281.5001,-218.2121 288.5001,-218.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"300.5518\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12 (south)</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;12 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>9&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M304.0867,-257.7616C316.9735,-245.4475 334.1614,-229.0235 348.388,-215.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"351.1289,-217.6512 355.9408,-208.2121 346.2929,-212.5902 351.1289,-217.6512\"/>\n",
       "<text text-anchor=\"middle\" x=\"351.9448\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"457\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">16 (to)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>17&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M453.8483,-257.7616C454.3786,-246.3597 455.0728,-231.4342 455.6747,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"459.1844,-218.3639 456.1529,-208.2121 452.192,-218.0387 459.1844,-218.3639\"/>\n",
       "<text text-anchor=\"middle\" x=\"470.3828\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mark</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"547\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19 (brutality)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;19 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>17&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M472.935,-257.7616C486.5192,-245.3335 504.6792,-228.719 519.6172,-215.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"522.0782,-217.5446 527.0938,-208.2121 517.3531,-212.3799 522.0782,-217.5446\"/>\n",
       "<text text-anchor=\"middle\" x=\"518.4448\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"292\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (from)</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;10 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M357.3978,-171.7616C345.5133,-159.4475 329.6623,-143.0235 316.5422,-129.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"319.0397,-126.977 309.5768,-122.2121 314.0029,-131.8382 319.0397,-126.977\"/>\n",
       "<text text-anchor=\"middle\" x=\"351.0449\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"375\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">11 (the)</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;11 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M375,-171.7616C375,-160.3597 375,-145.4342 375,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"378.5001,-132.2121 375,-122.2121 371.5001,-132.2121 378.5001,-132.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"383.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"457\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">14 (Italy)</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M392.3901,-171.7616C404.0227,-159.5615 419.5018,-143.3273 432.3927,-129.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"435.2673,-131.8648 439.635,-122.2121 430.2011,-127.0342 435.2673,-131.8648\"/>\n",
       "<text text-anchor=\"middle\" x=\"436.9448\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"457\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">13 (of)</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;13 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>14&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M457,-85.7616C457,-74.3597 457,-59.4342 457,-46.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"460.5001,-46.2121 457,-36.2121 453.5001,-46.2121 460.5001,-46.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"469.0449\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>18</title>\n",
       "<text text-anchor=\"middle\" x=\"543\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18 (the)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;18 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>19&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M546.1517,-171.7616C545.6214,-160.3597 544.9272,-145.4342 544.3253,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"547.808,-132.0387 543.8471,-122.2121 540.8156,-132.3639 547.808,-132.0387\"/>\n",
       "<text text-anchor=\"middle\" x=\"554.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>22</title>\n",
       "<text text-anchor=\"middle\" x=\"631\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">22 (beings)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;22 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>19&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M564.8142,-171.7616C576.842,-159.4475 592.884,-143.0235 606.1621,-129.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"608.7278,-131.8115 613.2114,-122.2121 603.7202,-126.9203 608.7278,-131.8115\"/>\n",
       "<text text-anchor=\"middle\" x=\"610.9448\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"588\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">20 (of)</text>\n",
       "</g>\n",
       "<!-- 22&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>22&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M621.8808,-85.7616C616.0088,-74.0176 608.2677,-58.5355 601.6674,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"604.7087,-43.5911 597.106,-36.2121 598.4477,-46.7216 604.7087,-43.5911\"/>\n",
       "<text text-anchor=\"middle\" x=\"625.0449\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"674\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">21 (human)</text>\n",
       "</g>\n",
       "<!-- 22&#45;&gt;21 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>22&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M640.1192,-85.7616C645.9912,-74.0176 653.7323,-58.5355 660.3326,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"663.5523,-46.7216 664.894,-36.2121 657.2913,-43.5911 663.5523,-46.7216\"/>\n",
       "<text text-anchor=\"middle\" x=\"670.5518\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>24</title>\n",
       "<text text-anchor=\"middle\" x=\"414\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">24 (in)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;24 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>26&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M429.7585,-429.7616C427.0804,-418.2456 423.5664,-403.1353 420.5364,-390.1064\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"423.9096,-389.1594 418.2354,-380.2121 417.0916,-390.745 423.9096,-389.1594\"/>\n",
       "<text text-anchor=\"middle\" x=\"438.0449\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>25</title>\n",
       "<text text-anchor=\"middle\" x=\"496\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">25 (every)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;25 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>26&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M447.1486,-429.7616C455.7796,-417.7896 467.2112,-401.9328 476.8459,-388.5685\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"479.8614,-390.3707 482.8703,-380.2121 474.1832,-386.2771 479.8614,-390.3707\"/>\n",
       "<text text-anchor=\"middle\" x=\"477.5518\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>30</title>\n",
       "<text text-anchor=\"middle\" x=\"618\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">30 (society)</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;30 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>26&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M472.5724,-429.9716C501.0317,-416.67 539.9293,-398.4896 570.3355,-384.278\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"571.901,-387.4097 579.4784,-380.0047 568.937,-381.0682 571.901,-387.4097\"/>\n",
       "<text text-anchor=\"middle\" x=\"553.9448\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>27</title>\n",
       "<text text-anchor=\"middle\" x=\"545\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">27 (of)</text>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;27 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>30&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M602.5186,-343.7616C592.2595,-331.6756 578.6398,-315.6304 567.2288,-302.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"569.5988,-299.5709 560.4591,-294.2121 564.2622,-304.1009 569.5988,-299.5709\"/>\n",
       "<text text-anchor=\"middle\" x=\"598.0449\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>28</title>\n",
       "<text text-anchor=\"middle\" x=\"621\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">28 (our)</text>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;28 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>30&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M618.6362,-343.7616C619.034,-332.3597 619.5546,-317.4342 620.006,-304.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"623.5138,-304.3281 620.3647,-294.2121 616.5181,-304.084 623.5138,-304.3281\"/>\n",
       "<text text-anchor=\"middle\" x=\"650.3379\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>29</title>\n",
       "<text text-anchor=\"middle\" x=\"730\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">29 (contemporary)</text>\n",
       "</g>\n",
       "<!-- 30&#45;&gt;29 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>30&#45;&gt;29</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M656.977,-343.9807C666.5477,-338.7822 676.4828,-332.6858 685,-326 693.9107,-319.0053 702.5294,-310.1327 709.7981,-301.8097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"712.5476,-303.9783 716.3188,-294.0774 707.1964,-299.4656 712.5476,-303.9783\"/>\n",
       "<text text-anchor=\"middle\" x=\"715.5518\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1139beba8>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphviz.Source(list(PlotParse[0])[0].to_dot())\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 8-layer tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's try the some other sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We see one of the primitive and archaic human behaviour that has driven his struggle for life , the killing of other species .\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"765pt\" height=\"646pt\"\n",
       " viewBox=\"0.00 0.00 764.69 646.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 642)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-642 760.6914,-642 760.6914,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-615.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"141\" y=\"-529.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (see)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M141,-601.7616C141,-590.3597 141,-575.4342 141,-562.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"144.5001,-562.2121 141,-552.2121 137.5001,-562.2121 144.5001,-562.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"152.2759\" y=\"-572.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"115\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (We)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M132.5023,-515.9432C130.0587,-510.2843 127.5475,-503.959 125.6621,-498 123.4675,-491.0636 121.5851,-483.443 120.0401,-476.2876\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"123.428,-475.3817 118.0207,-466.2706 116.566,-476.7651 123.428,-475.3817\"/>\n",
       "<text text-anchor=\"middle\" x=\"141.1689\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-443.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (one)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M150.9675,-515.7616C157.3857,-504.0176 165.8469,-488.5355 173.0612,-475.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"176.3224,-476.6657 178.0469,-466.2121 170.1799,-473.3087 176.3224,-476.6657\"/>\n",
       "<text text-anchor=\"middle\" x=\"180.4448\" y=\"-486.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (behaviour)</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;10 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M188,-429.7616C188,-418.3597 188,-403.4342 188,-390.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.5001,-390.2121 188,-380.2121 184.5001,-390.2121 191.5001,-390.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"203.9448\" y=\"-400.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (of)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;4 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>10&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M147.215,-343.8842C135.3842,-338.3798 122.5272,-332.1537 110.9102,-326 94.9016,-317.52 77.6418,-307.4106 62.9628,-298.5082\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"64.5485,-295.3755 54.1908,-293.1466 60.8979,-301.3482 64.5485,-295.3755\"/>\n",
       "<text text-anchor=\"middle\" x=\"123.0449\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (the)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;5 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M169.1254,-343.7616C156.3817,-331.4475 139.3848,-315.0235 125.3163,-301.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.4708,-298.644 117.8474,-294.2121 122.6066,-303.6779 127.4708,-298.644\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.5518\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (primitive)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;6 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>10&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M188,-343.7616C188,-332.3597 188,-317.4342 188,-304.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.5001,-304.2121 188,-294.2121 184.5001,-304.2121 191.5001,-304.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"203.5518\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"287\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (human)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>10&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M208.9954,-343.7616C223.3021,-331.3335 242.4281,-314.719 258.1606,-301.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"260.7809,-303.4124 266.0349,-294.2121 256.1902,-298.1279 260.7809,-303.4124\"/>\n",
       "<text text-anchor=\"middle\" x=\"259.5518\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"399\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">13 (driven)</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;13 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>10&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M234.3587,-343.8474C248.6921,-338.1846 264.5179,-331.8812 279,-326 302.5889,-316.4206 328.6897,-305.5749 350.5083,-296.4389\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"352.0222,-299.5994 359.8912,-292.505 349.3156,-293.1438 352.0222,-299.5994\"/>\n",
       "<text text-anchor=\"middle\" x=\"335.5381\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">acl:relcl</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"104\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (and)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M170.1858,-257.7616C158.158,-245.4475 142.116,-229.0235 128.8379,-215.4293\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"131.2798,-212.9203 121.7886,-208.2121 126.2722,-217.8115 131.2798,-212.9203\"/>\n",
       "<text text-anchor=\"middle\" x=\"158.2139\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cc</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"188\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (archaic)</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M188,-257.7616C188,-246.3597 188,-231.4342 188,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.5001,-218.2121 188,-208.2121 184.5001,-218.2121 191.5001,-218.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.0518\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conj</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">11 (that)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;11 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M368.3321,-257.9107C359.2935,-252.3565 349.4687,-246.097 340.6621,-240 329.2463,-232.0966 317.111,-222.9306 306.4739,-214.6218\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"308.3265,-211.6254 298.3066,-208.1825 303.9925,-217.1224 308.3265,-211.6254\"/>\n",
       "<text text-anchor=\"middle\" x=\"356.1689\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"356\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12 (has)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>13&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M389.8808,-257.7616C384.0088,-246.0176 376.2677,-230.5355 369.6674,-217.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"372.7087,-215.5911 365.106,-208.2121 366.4477,-218.7216 372.7087,-215.5911\"/>\n",
       "<text text-anchor=\"middle\" x=\"391.1069\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">aux</text>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>17</title>\n",
       "<text text-anchor=\"middle\" x=\"435\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">17 (life)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;17 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>13&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M406.6347,-257.7616C411.503,-246.1316 417.906,-230.8357 423.3963,-217.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"426.7434,-218.788 427.3763,-208.2121 420.2863,-216.085 426.7434,-218.788\"/>\n",
       "<text text-anchor=\"middle\" x=\"435.9448\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">15 (struggle)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M428.1546,-257.9289C437.1373,-252.2695 447.0235,-245.9474 456,-240 468.5567,-231.6805 482.1665,-222.32 494.1381,-213.9672\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"496.3437,-216.6955 502.5272,-208.0923 492.3283,-210.9617 496.3437,-216.6955\"/>\n",
       "<text text-anchor=\"middle\" x=\"488.4448\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>19</title>\n",
       "<text text-anchor=\"middle\" x=\"620\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19 (the)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;19 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>13&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M438.5024,-263.3255C458.5436,-256.7081 483.1973,-248.2804 505,-240 536.5853,-228.0043 546.0268,-223.5018 580.4841,-208.1918\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"582.0894,-211.3087 589.8121,-204.0554 579.2518,-204.9096 582.0894,-211.3087\"/>\n",
       "<text text-anchor=\"middle\" x=\"552.4448\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dobj</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>16</title>\n",
       "<text text-anchor=\"middle\" x=\"435\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">16 (for)</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;16 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M435,-171.7616C435,-160.3597 435,-145.4342 435,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"438.5001,-132.2121 435,-122.2121 431.5001,-132.2121 438.5001,-132.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"447.0449\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>14</title>\n",
       "<text text-anchor=\"middle\" x=\"528\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">14 (his)</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;14 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>15&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M528,-171.7616C528,-160.3597 528,-145.4342 528,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"531.5001,-132.2121 528,-122.2121 524.5001,-132.2121 531.5001,-132.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"558.3379\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod:poss</text>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>23</title>\n",
       "<text text-anchor=\"middle\" x=\"618\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">23 (species)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;23 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>19&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M619.5759,-171.7616C619.3107,-160.3597 618.9636,-145.4342 618.6627,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"622.1552,-132.128 618.4235,-122.2121 615.1571,-132.2908 622.1552,-132.128\"/>\n",
       "<text text-anchor=\"middle\" x=\"635.9448\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<text text-anchor=\"middle\" x=\"717\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">20 (killing)</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>19&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M640.5712,-171.7616C654.589,-159.3335 673.3285,-142.719 688.7432,-129.0524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"691.2978,-131.4651 696.4584,-122.2121 686.6539,-126.2273 691.2978,-131.4651\"/>\n",
       "<text text-anchor=\"middle\" x=\"690.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>21</title>\n",
       "<text text-anchor=\"middle\" x=\"578\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">21 (of)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;21 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>23&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M609.517,-85.7616C604.0547,-74.0176 596.8537,-58.5355 590.7139,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"593.8616,-43.8032 586.4707,-36.2121 587.5146,-46.7554 593.8616,-43.8032\"/>\n",
       "<text text-anchor=\"middle\" x=\"613.0449\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>22</title>\n",
       "<text text-anchor=\"middle\" x=\"659\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">22 (other)</text>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;22 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>23&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M626.695,-85.7616C632.2939,-74.0176 639.6749,-58.5355 645.9683,-45.3349\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"649.1734,-46.745 650.3175,-36.2121 642.8547,-43.7326 649.1734,-46.745\"/>\n",
       "<text text-anchor=\"middle\" x=\"656.5518\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x113ba1828>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(' '.join(plots['sentences'][0][1]))\n",
    "graphviz.Source(list(PlotParse[1])[0].to_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also a 8-layer tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everyone at the same time are the executor and the victim of themselves .\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"545pt\" height=\"388pt\"\n",
       " viewBox=\"0.00 0.00 544.52 388.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 384)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-384 540.5156,-384 540.5156,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-357.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>8</title>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-271.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8 (executor)</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M261,-343.7616C261,-332.3597 261,-317.4342 261,-304.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"264.5001,-304.2121 261,-294.2121 257.5001,-304.2121 264.5001,-304.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"272.2759\" y=\"-314.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">root</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (Everyone)</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;1 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>8&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M222.5533,-257.9897C210.939,-252.3861 198.2083,-246.0798 186.6621,-240 170.7427,-231.6175 153.4897,-221.9148 138.5345,-213.2998\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"139.9598,-210.0807 129.5522,-208.0979 136.4517,-216.1382 139.9598,-210.0807\"/>\n",
       "<text text-anchor=\"middle\" x=\"202.1689\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nsubj</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<text text-anchor=\"middle\" x=\"189\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (are)</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;6 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M245.7307,-257.7616C235.6121,-245.6756 222.179,-229.6304 210.9243,-216.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"213.3504,-213.6329 204.2473,-208.2121 207.9831,-218.1265 213.3504,-213.6329\"/>\n",
       "<text text-anchor=\"middle\" x=\"240.1069\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cop</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>7</title>\n",
       "<text text-anchor=\"middle\" x=\"261\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7 (the)</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;7 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>8&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M261,-257.7616C261,-246.3597 261,-231.4342 261,-218.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"264.5001,-218.2121 261,-208.2121 257.5001,-218.2121 264.5001,-218.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"269.5518\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<text text-anchor=\"middle\" x=\"334\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9 (and)</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M276.4814,-257.7616C286.7405,-245.6756 300.3602,-229.6304 311.7712,-216.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.7378,-218.1009 318.5409,-208.2121 309.4012,-213.5709 314.7378,-218.1009\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.2139\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">cc</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>11</title>\n",
       "<text text-anchor=\"middle\" x=\"419\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">11 (victim)</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;11 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>8&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M294.122,-257.9716C318.2438,-244.842 351.0987,-226.959 377.0542,-212.8313\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"378.8117,-215.8596 385.9216,-208.0047 375.4651,-209.7113 378.8117,-215.8596\"/>\n",
       "<text text-anchor=\"middle\" x=\"362.0518\" y=\"-228.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">conj</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5</title>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (time)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M99,-171.7616C99,-160.3597 99,-145.4342 99,-132.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.5001,-132.2121 99,-122.2121 95.5001,-132.2121 102.5001,-132.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"114.9448\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2</title>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (at)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M83.7307,-85.7616C73.6121,-73.6756 60.179,-57.6304 48.9243,-44.1874\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"51.3504,-41.6329 42.2473,-36.2121 45.9831,-46.1265 51.3504,-41.6329\"/>\n",
       "<text text-anchor=\"middle\" x=\"80.0449\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>3</title>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (the)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M99,-85.7616C99,-74.3597 99,-59.4342 99,-46.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.5001,-46.2121 99,-36.2121 95.5001,-46.2121 102.5001,-46.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.5518\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>4</title>\n",
       "<text text-anchor=\"middle\" x=\"176\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (same)</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M115.3297,-85.7616C126.253,-73.5615 140.7883,-57.3273 152.8932,-43.8076\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"155.6309,-45.9969 159.6938,-36.2121 150.4157,-41.3276 155.6309,-45.9969\"/>\n",
       "<text text-anchor=\"middle\" x=\"158.5518\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>10</title>\n",
       "<text text-anchor=\"middle\" x=\"384\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10 (the)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;10 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>11&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M411.5774,-171.7616C406.8443,-160.1316 400.6192,-144.8357 395.2814,-131.72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"398.4233,-130.1551 391.4119,-122.2121 391.9397,-132.7938 398.4233,-130.1551\"/>\n",
       "<text text-anchor=\"middle\" x=\"412.5518\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">det</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>13</title>\n",
       "<text text-anchor=\"middle\" x=\"484\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">13 (themselves)</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;13 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>11&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M432.7848,-171.7616C441.8335,-159.7896 453.8182,-143.9328 463.9191,-130.5685\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"466.9976,-132.3002 470.235,-122.2121 461.4132,-128.0794 466.9976,-132.3002\"/>\n",
       "<text text-anchor=\"middle\" x=\"471.9448\" y=\"-142.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>12</title>\n",
       "<text text-anchor=\"middle\" x=\"484\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12 (of)</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;12 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>13&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M484,-85.7616C484,-74.3597 484,-59.4342 484,-46.494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"487.5001,-46.2121 484,-36.2121 480.5001,-46.2121 487.5001,-46.2121\"/>\n",
       "<text text-anchor=\"middle\" x=\"496.0449\" y=\"-56.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">case</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x113ba2390>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(' '.join(plots['sentences'][0][2]))\n",
    "graphviz.Source(list(PlotParse[2])[0].to_dot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 5-layer tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the parse depth positively relates to perceived sentence complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these parses, I can extract nouns collocated in a noun phrase, adjectives that modify a noun, verbs related to a noun, nouns related to an adjective, and adverbs that modify a verb. \n",
    "Let's try to parse the whole dataset and capture these sets of things for some words to see what we can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PlotsTrees = []\n",
    "for i in range(len(plots['sentences'])):\n",
    "    PlotsParses = list(stanford.parser.parse_sents(plots['sentences'][i])) #Converting the iterator to a list so we can call by index. They are still \n",
    "    for j in range(len(PlotsParses)):\n",
    "        PlotSentParseTree = list(PlotsParses[j]) #iterators so be careful about re-running code, without re-running this block\n",
    "        PlotsTrees += PlotSentParseTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A function to find part of speech related to the targets\n",
    "def find_relation(parsetree, relationType, *targets):\n",
    "    x = 0\n",
    "    for i in range(len(parsetree)):\n",
    "        r = treeRelation(parsetree[i], relationType, *targets)\n",
    "        if r != []:\n",
    "            x += 1\n",
    "            print(i, r)\n",
    "    if x == 0:\n",
    "        print('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to find part of speech subrelated to the targets\n",
    "def find_subrelation(parsetree, relationTypeScope, relationTypeTarget, *targets):\n",
    "    x = 0\n",
    "    for i in range(len(parsetree)):\n",
    "        r = treeSubRelation(parsetree[i], relationTypeScope, relationTypeTarget, *targets)\n",
    "        if r != [] and r != set():\n",
    "            x += 1\n",
    "            print(i, r)\n",
    "    if x == 0:\n",
    "        print('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 [[('NP', \"the world 's deepest copper mine , where he finds evidence that the Earth 's crust is heating up faster than expected\")], [('NP', \"the world 's deepest copper mine\")], [('NP', \"the world 's\")]]\n",
      "23 [[('NP', 'the world')]]\n",
      "35 [[('NP', 'a world destroyed in a war between man and machine')], [('NP', 'a world')]]\n",
      "36 [[('NP', 'The world he has awakened in')], [('NP', 'The world')]]\n",
      "37 [[('NP', '2 who tells him something of what happened to the world')], [('NP', 'something of what happened to the world')], [('NP', 'the world')]]\n",
      "85 [[('NP', 'a fun ride sure to leave you feeling out of this world')], [('NP', 'this world')]]\n",
      "102 [[('NP', 'the human fuel to multiply and conquer the world')], [('NP', 'the world')]]\n",
      "136 [[('NP', 'the world learning about her own humanity and love')], [('NP', 'the world')]]\n",
      "151 [[('NP', 'a mission on the distant world of Pandora')], [('NP', 'the distant world of Pandora')], [('NP', 'the distant world')]]\n",
      "178 [[('NP', \"A pompous , young inventor who calls himself 'Bobinicci ' is dead-set on proving that he is the smartest man in the world .\")], [('NP', \"young inventor who calls himself 'Bobinicci ' is dead-set on proving that he is the smartest man in the world\")], [('NP', \"'Bobinicci ' is dead-set on proving that he is the smartest man in the world\")], [('NP', 'the smartest man in the world')], [('NP', 'the world')]]\n",
      "181 [[('NP', 'a tribe who tribe now occupies one of the largest remaining liquid oil fields in the world - forcing them into conflict with a powerful Chinese corporation')], [('NP', 'one of the largest remaining liquid oil fields in the world')], [('NP', 'the largest remaining liquid oil fields in the world')], [('NP', 'the world')]]\n",
      "188 [[('NP', 'a neo-realistic world , where no one can be trusted')], [('NP', 'a neo-realistic world')]]\n",
      "189 [[('NP', 'this world')]]\n",
      "195 [[('NP', 'a way to break into the toughest super-prison ever created-or watch him be executed before the entire world')], [('NP', 'the entire world')]]\n",
      "198 [[('NP', \"the world 's leaders\")], [('NP', \"the world 's\")]]\n"
     ]
    }
   ],
   "source": [
    "# nouns collocated in a noun phrase\n",
    "find_relation(PlotsTrees, 'NP', 'world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 {'Earth', 'mine', 'world', 'copper', 'crust', 'evidence'}\n",
      "23 {'world'}\n",
      "35 {'war', 'world', 'man', 'machine'}\n",
      "36 {'world'}\n",
      "37 {'something', 'world'}\n",
      "85 {'ride', 'world', 'fun'}\n",
      "102 {'world', 'fuel'}\n",
      "136 {'humanity', 'world', 'love'}\n",
      "151 {'world', 'mission'}\n",
      "178 {'world', 'man', 'inventor'}\n",
      "181 {'conflict', 'oil', 'world', 'corporation', 'tribe'}\n",
      "188 {'one', 'world'}\n",
      "189 {'world'}\n",
      "195 {'world', 'way', 'created-or', 'super-prison'}\n",
      "198 {'world'}\n"
     ]
    }
   ],
   "source": [
    "find_subrelation(PlotsTrees, 'NP', 'NN', 'world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 [[('ADJP', \"Unable to fulfill the grieving man 's expectations , our hero embarks on a journey in search of acceptance , experiencing betrayal and a netherworld of robot gladiators\")]]\n",
      "157 [[('ADJP', 'too much for any man')]]\n",
      "178 [[('ADJP', 'dead-set on proving that he is the smartest man in the world')]]\n"
     ]
    }
   ],
   "source": [
    "# adjective phrases that modify a noun\n",
    "find_relation(PlotsTrees, 'ADJP', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139 {'Unable'}\n",
      "157 {'much'}\n",
      "178 {'dead-set'}\n"
     ]
    }
   ],
   "source": [
    "find_subrelation(PlotsTrees, 'ADJP', 'JJ', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "find_relation(PlotsTrees, 'ADJP', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 [[('VP', 'broadcasts dim and distant messages of hope mixed with the music he scavenges from the dead')]]\n",
      "16 [[('VP', \"is led to the world 's deepest copper mine , where he finds evidence that the Earth 's crust is heating up faster than expected\")], [('VP', \"led to the world 's deepest copper mine , where he finds evidence that the Earth 's crust is heating up faster than expected\")]]\n",
      "18 [[('VP', 'is instead stunned when he learns that the powers-that-be have no intention of publicizing this catastrophe')]]\n",
      "36 [[('VP', 'learns that he is not alone and that there are others like him , also with a single digit written on their back')]]\n",
      "43 [[('VP', 'prepares the colony for a guest speaker that he has acquired from the past')]]\n",
      "46 [[('VP', 'drawn in he')], [('VP', \"becomes , especially when he discovers that she 's being hunted by an old foe\")]]\n",
      "71 [[('VP', \"lives a horrible life of self-destruction as he is advised by a newly-released device meant to `` better '' it 's user , a Personal Assistant Computer PAC that begins using it 's own methods of user improvement as Nick 's lifestyle hurts others as well as himself\")]]\n",
      "84 [[('VP', 'is about a young guy who thinks he was abducted by aliens because he wakes up with an oddly shaped scar and no memory of how it happened')], [('VP', 'thinks he was abducted by aliens because he wakes up with an oddly shaped scar and no memory of how it happened')], [('VP', 'was abducted by aliens because he wakes up with an oddly shaped scar and no memory of how it happened')], [('VP', 'abducted by aliens because he wakes up with an oddly shaped scar and no memory of how it happened')]]\n",
      "100 [[('VP', 'is the only one who knows how to stop the hideous extra-terrestrial , but to do so he has to take over the body of Dr. Lewis and enlist the aid of Tammy , the only human in town willing to believe and trust in his mission')], [('VP', 'knows how to stop the hideous extra-terrestrial , but to do so he has to take over the body of Dr. Lewis and enlist the aid of Tammy , the only human in town willing to believe and trust in his mission')], [('VP', 'to stop the hideous extra-terrestrial , but to do so he has to take over the body of Dr. Lewis and enlist the aid of Tammy , the only human in town willing to believe and trust in his mission')], [('VP', 'to do so he has to take over the body of Dr. Lewis and enlist the aid of Tammy , the only human in town willing to believe and trust in his mission')], [('VP', 'do so he has to take over the body of Dr. Lewis and enlist the aid of Tammy , the only human in town willing to believe and trust in his mission')]]\n",
      "108 [[('VP', 'is haunted by his past where is believes he was abducted by aliens in the 50s , so keeps to himself')], [('VP', 'haunted by his past where is believes he was abducted by aliens in the 50s , so keeps to himself')], [('VP', 'is believes he was abducted by aliens in the 50s , so keeps to himself')], [('VP', 'believes he was abducted by aliens in the 50s , so keeps to himself')]]\n",
      "111 [[('VP', 'jumps at the chance and is excited by what he discovers')], [('VP', 'is excited by what he discovers')]]\n",
      "123 [[('VP', 'doing what he feels')]]\n",
      "138 [[('VP', 'is about a young robot with incredible powers created by a brilliant scientist in the image of the son he has lost')], [('VP', 'created by a brilliant scientist in the image of the son he has lost')]]\n",
      "161 [[('VP', 'discovers that he has been double crossed')], [('VP', 'is an experiment to test the suit , which he can not take off')], [('VP', 'to test the suit , which he can not take off')], [('VP', 'test the suit , which he can not take off')]]\n",
      "163 [[('VP', \"discovers he is no longer attracted to the `` enlightened '' women he creates\")], [('VP', \"is no longer attracted to the `` enlightened '' women he creates\")], [('VP', \"attracted to the `` enlightened '' women he creates\")]]\n",
      "178 [[('VP', \"calls himself 'Bobinicci ' is dead-set on proving that he is the smartest man in the world\")], [('VP', 'is dead-set on proving that he is the smartest man in the world')], [('VP', 'proving that he is the smartest man in the world')]]\n",
      "179 [[('VP', 'is well on his way to accomplishing that goal ... until he tries it on his dog')], [('VP', 'to accomplishing that goal ... until he tries it on his dog')], [('VP', 'accomplishing that goal ... until he tries it on his dog')]]\n",
      "180 [[('VP', \"is a relentless battle against dog , machine , and the dark side of his ego unable to come to grips with the fact that he is indeed just 'Bob\")], [('VP', \"to come to grips with the fact that he is indeed just 'Bob\")], [('VP', \"come to grips with the fact that he is indeed just 'Bob\")]]\n",
      "185 [[('VP', 'cubicle where he sits at a desk driving a remote control truck across a hostile planet filled with dangerous creatures')]]\n",
      "186 [[('VP', \"is a young woman he talks to only via a monitor , even though she 's much closer than he thinks\")], [('VP', \"talks to only via a monitor , even though she 's much closer than he thinks\")], [('VP', \"'s much closer than he thinks\")]]\n",
      "189 [[('VP', \"feels like he does n't belong in this world , though he 's not sure why\")], [('VP', \"does n't belong in this world , though he 's not sure why\")], [('VP', \"belong in this world , though he 's not sure why\")]]\n"
     ]
    }
   ],
   "source": [
    "# verbs related to a noun\n",
    "find_relation(PlotsTrees, 'VP', 'he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 {'scavenges', 'broadcasts'}\n",
      "16 {'finds', 'is'}\n",
      "18 {'learns', 'is'}\n",
      "36 {'learns', 'is'}\n",
      "43 {'prepares', 'has'}\n",
      "46 {'becomes', \"'s\", 'discovers'}\n",
      "71 {\"'s\", 'hurts', 'lives', 'begins', 'is'}\n",
      "84 {'thinks', 'is', 'wakes'}\n",
      "100 {'has', 'is', 'knows'}\n",
      "108 {'keeps', 'believes', 'is'}\n",
      "111 {'jumps', 'is', 'discovers'}\n",
      "123 {'feels'}\n",
      "138 {'has', 'is'}\n",
      "161 {'has', 'is', 'discovers'}\n",
      "163 {'creates', 'is', 'discovers'}\n",
      "178 {'is', 'calls'}\n",
      "179 {'tries', 'is'}\n",
      "180 {'is'}\n",
      "185 {'sits'}\n",
      "186 {\"'s\", 'talks', 'thinks', 'is'}\n",
      "189 {'feels', 'does', \"'s\"}\n"
     ]
    }
   ],
   "source": [
    "find_subrelation(PlotsTrees, 'VP', 'VBZ', 'he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 [[('VP', \"is being chased by forces she does n't quite understand\")], [('VP', \"being chased by forces she does n't quite understand\")], [('VP', \"chased by forces she does n't quite understand\")]]\n",
      "46 [[('VP', \"becomes , especially when he discovers that she 's being hunted by an old foe\")], [('VP', \"discovers that she 's being hunted by an old foe\")]]\n",
      "47 [[('VP', 'agrees to help Laurel , who is more than she seems to be')], [('VP', 'to help Laurel , who is more than she seems to be')], [('VP', 'help Laurel , who is more than she seems to be')], [('VP', 'is more than she seems to be')]]\n",
      "51 [[('VP', 'is immediately attacked by a pack of hungry mutant wolves , which , she easily dispatches with her ancient Old West-style revolvers')], [('VP', 'attacked by a pack of hungry mutant wolves , which , she easily dispatches with her ancient Old West-style revolvers')]]\n",
      "94 [[('VP', 'looks out her window and is excited to see a shooting star , which she takes as a good sign for her dreams')], [('VP', 'is excited to see a shooting star , which she takes as a good sign for her dreams')], [('VP', 'to see a shooting star , which she takes as a good sign for her dreams')], [('VP', 'see a shooting star , which she takes as a good sign for her dreams')]]\n",
      "132 [[('VP', \"realizes she 's becoming influenced by the woman 's memories , but still has to find a way to accomplish her intended mission\")], [('VP', \"realizes she 's becoming influenced by the woman 's memories\")]]\n",
      "140 [[('VP', 'is traumatized by the loss of her deranged father when she was nine years old and the suicide of her beloved brother Brandon one year ago')]]\n",
      "184 [[('VP', 'rebels against her father by sneaking out for a night surf with a guy she just met')], [('VP', 'sneaking out for a night surf with a guy she just met')], [('VP', \"discovers that she should have heeded her father 's advice and stayed away from the beach after dark\")], [('VP', \"discovers that she should have heeded her father 's advice\")]]\n",
      "186 [[('VP', \"is a young woman he talks to only via a monitor , even though she 's much closer than he thinks\")], [('VP', \"talks to only via a monitor , even though she 's much closer than he thinks\")]]\n",
      "187 [[('VP', 'downloads more than she bargains for')]]\n"
     ]
    }
   ],
   "source": [
    "find_relation(PlotsTrees, 'VP', 'she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 {'does', 'is'}\n",
      "46 {'becomes', \"'s\", 'discovers'}\n",
      "47 {'seems', 'agrees', 'is'}\n",
      "51 {'dispatches', 'is'}\n",
      "94 {'looks', 'takes', 'is'}\n",
      "132 {'has', \"'s\", 'realizes'}\n",
      "140 {'is'}\n",
      "184 {'discovers'}\n",
      "186 {\"'s\", 'talks', 'thinks', 'is'}\n"
     ]
    }
   ],
   "source": [
    "find_subrelation(PlotsTrees, 'VP', 'VBZ', 'she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 [[('NP', 'The strong wear weights , the beautiful wear masks and the intelligent wear')], [('NP', 'the beautiful wear masks')]]\n",
      "93 [[('NP', 'a special night for noted astronomer Ted Lewis , who is preparing a special dinner for his beautiful , adoring wife Lana to celebrate their wedding anniversary')], [('NP', 'noted astronomer Ted Lewis , who is preparing a special dinner for his beautiful , adoring wife Lana to celebrate their wedding anniversary')], [('NP', 'his beautiful , adoring wife Lana to celebrate their wedding anniversary')]]\n",
      "154 [[('NP', 'the beautiful alien Neytiri')]]\n"
     ]
    }
   ],
   "source": [
    "# nouns related to an adjective\n",
    "find_relation(PlotsTrees, 'NP', 'beautiful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 {'wear'}\n",
      "93 {'Lana', 'wife', 'dinner', 'anniversary', 'night', 'wedding', 'astronomer'}\n"
     ]
    }
   ],
   "source": [
    "find_subrelation(PlotsTrees, 'NP', 'NN', 'beautiful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 [[('VP', 'becomes conscious of his divine obligation : to save humanity before it plunges into extinction')], [('VP', 'to save humanity before it plunges into extinction')], [('VP', 'save humanity before it plunges into extinction')]]\n",
      "106 [[('VP', 'need to a find a way to force the adults to leave the house and discover the vulnerability of the invaders to plot a defense plan to save our planet')], [('VP', 'to a find a way to force the adults to leave the house and discover the vulnerability of the invaders to plot a defense plan to save our planet')], [('VP', 'a find a way to force the adults to leave the house and discover the vulnerability of the invaders to plot a defense plan to save our planet')], [('VP', 'to force the adults to leave the house and discover the vulnerability of the invaders to plot a defense plan to save our planet')], [('VP', 'force the adults to leave the house and discover the vulnerability of the invaders to plot a defense plan to save our planet')], [('VP', 'to leave the house and discover the vulnerability of the invaders to plot a defense plan to save our planet')], [('VP', 'leave the house and discover the vulnerability of the invaders to plot a defense plan to save our planet')], [('VP', 'discover the vulnerability of the invaders to plot a defense plan to save our planet')], [('VP', 'to plot a defense plan to save our planet')], [('VP', 'plot a defense plan to save our planet')], [('VP', 'to save our planet')], [('VP', 'save our planet')]]\n",
      "123 [[('VP', 'is right , in order to save a life')], [('VP', 'to save a life')], [('VP', 'save a life')]]\n",
      "139 [[('VP', 'returns to save Metro City and reconcile with the father who had rejected him')], [('VP', 'to save Metro City and reconcile with the father who had rejected him')], [('VP', 'save Metro City and reconcile with the father who had rejected him')], [('VP', 'save Metro City')]]\n",
      "171 [[('VP', 'to save her')], [('VP', 'save her')]]\n",
      "174 [[('VP', \"has a trick up his sleeve for escaping Hiccup 's grasp but will it be in time to save the random dimensions from nihilism\")], [('VP', \"escaping Hiccup 's grasp but will it be in time to save the random dimensions from nihilism\")], [('VP', 'grasp but will it be in time to save the random dimensions from nihilism')], [('VP', 'be in time to save the random dimensions from nihilism')], [('VP', 'to save the random dimensions from nihilism')], [('VP', 'save the random dimensions from nihilism')]]\n"
     ]
    }
   ],
   "source": [
    "# adverbs that modify a verb\n",
    "find_relation(PlotsTrees, 'VP', 'save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "find_subrelation(PlotsTrees, 'VP', 'RB', 'save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset I used for this assignment is really small so I would not draw any conclusion here. However, from the above exploration, we can still notice some interesting phenomena that worth to be investigated further. For example, the \"world\" depicted in this dataset is somehow about \"love\" and \"fun\". Even in the sci-fi films, \"love\" is main topic, so we can see that it is true that \"love\" is the hardcore of different kinds of literatures and arts. There are more adjectives and verbs to describe man than woman, which may indicate that male characters are taking up larger potion in sci-fi films than woman. The verbs that \"he\" uses are more meaningful and active than those \"she\" uses. For instance, \"he\" \"scavenges\", \"broadcasts\", \"learns\", \"prepares\", \"created\", while \"she\" \"thinks\", \"feels\", \"seems\", and \"talks\". It might also imply that male characters are more active and important ones in sci-fi movies than female characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information extraction\n",
    "\n",
    "Information extraction approaches typically (as here, with Stanford's Open IE engine) ride atop the dependency parse of a sentence. They are a pre-coded example of the type analyzed in the prior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [0.9 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 14.977 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [16.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0097 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/r0/knnmzsq17t32vsdpgs17k_9m0000gn/T/tmp3u2l0gqb\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ieDF = stanford.openIE(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`openIE()` prints everything stanford core produces and we can see from looking at it that initializing the dependency parser takes most of the time, so calling the function will always take at least 12 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>elephant</td>\n",
       "      <td>is in</td>\n",
       "      <td>my pajamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>saw</td>\n",
       "      <td>elephant in my pajamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>saw</td>\n",
       "      <td>elephant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in interview with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in recent interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed stimulus efforts in</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in recent intervie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in recent interview with Wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in recent interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>short-term stimulus efforts</td>\n",
       "      <td>is in</td>\n",
       "      <td>recent interview with Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in interview with Wall Street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>recent interview</td>\n",
       "      <td>is with</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was African American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    certainty                      subject                           verb  \\\n",
       "0         1.0                     elephant                          is in   \n",
       "1         1.0                            I                            saw   \n",
       "2         1.0                            I                            saw   \n",
       "3         1.0              quick brown fox                    jumped over   \n",
       "4         1.0              quick brown fox                    jumped over   \n",
       "5         1.0                    quick fox                    jumped over   \n",
       "6         1.0                          fox                    jumped over   \n",
       "7         1.0                    brown fox                    jumped over   \n",
       "8         1.0                    brown fox                    jumped over   \n",
       "9         1.0                    quick fox                    jumped over   \n",
       "10        1.0                          fox                    jumped over   \n",
       "11        1.0            Christine Lagarde                      discussed   \n",
       "12        1.0            Christine Lagarde                      discussed   \n",
       "13        1.0            Christine Lagarde                      discussed   \n",
       "14        1.0            Christine Lagarde  discussed stimulus efforts in   \n",
       "15        1.0            Christine Lagarde                      discussed   \n",
       "16        1.0            Christine Lagarde                      discussed   \n",
       "17        1.0            Christine Lagarde                      discussed   \n",
       "18        1.0  short-term stimulus efforts                          is in   \n",
       "19        1.0            Christine Lagarde                      discussed   \n",
       "20        1.0            Christine Lagarde                      discussed   \n",
       "21        1.0            Christine Lagarde                      discussed   \n",
       "22        1.0            Christine Lagarde                      discussed   \n",
       "23        1.0             recent interview                        is with   \n",
       "24        1.0                       Martin                            was   \n",
       "25        1.0      Trayvon Benjamin Martin      was African American from   \n",
       "26        1.0      Trayvon Benjamin Martin              was American from   \n",
       "27        1.0      Trayvon Benjamin Martin                            was   \n",
       "28        1.0      Trayvon Benjamin Martin                            was   \n",
       "\n",
       "                                               object  \n",
       "0                                          my pajamas  \n",
       "1                              elephant in my pajamas  \n",
       "2                                            elephant  \n",
       "3                                            lazy dog  \n",
       "4                                                 dog  \n",
       "5                                                 dog  \n",
       "6                                                 dog  \n",
       "7                                            lazy dog  \n",
       "8                                                 dog  \n",
       "9                                            lazy dog  \n",
       "10                                           lazy dog  \n",
       "11  short-term stimulus efforts in interview with ...  \n",
       "12                      stimulus efforts in interview  \n",
       "13               stimulus efforts in recent interview  \n",
       "14                                             France  \n",
       "15  short-term stimulus efforts in recent intervie...  \n",
       "16  stimulus efforts in recent interview with Wall...  \n",
       "17    short-term stimulus efforts in recent interview  \n",
       "18          recent interview with Wall Street Journal  \n",
       "19  stimulus efforts in interview with Wall Street...  \n",
       "20                                   stimulus efforts  \n",
       "21                        short-term stimulus efforts  \n",
       "22           short-term stimulus efforts in interview  \n",
       "23                                Wall Street Journal  \n",
       "24                                            African  \n",
       "25                                            Florida  \n",
       "26                                            Florida  \n",
       "27                                           American  \n",
       "28                                   African American  "
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No buffalos (because there were no verbs), but the rest is somewhat promising. Note, however, that it abandoned the key theme of the sentence about the tragic Trayvon Martin death (\"fatally shot\"), likely because it was buried so deeply within the complex phrase structure. This is obviously a challenge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">How would you extract relevant information about the Trayvon Martin sentence directly from the dependency parse (above)? Code an example here. (For instance, what compound nouns show up with what verb phrases within the sentence?) How could these approaches inform your research project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was African American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    certainty                  subject                       verb  \\\n",
       "24        1.0                   Martin                        was   \n",
       "25        1.0  Trayvon Benjamin Martin  was African American from   \n",
       "26        1.0  Trayvon Benjamin Martin          was American from   \n",
       "27        1.0  Trayvon Benjamin Martin                        was   \n",
       "28        1.0  Trayvon Benjamin Martin                        was   \n",
       "\n",
       "              object  \n",
       "24           African  \n",
       "25           Florida  \n",
       "26           Florida  \n",
       "27          American  \n",
       "28  African American  "
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[24:29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the part of Trayvon Martin sentence from `ieDF` as above, and we have found the subject and object, aka compound nouns, that show up with verb phrases, which are \"Trayvon Benjamin Martin\", \"African American\", and \"was\". However, let's look at the sentence again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.'"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the dependency parser did not extract the full information from that sentence. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [0.9 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 14.614 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [16.6 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0131 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/r0/knnmzsq17t32vsdpgs17k_9m0000gn/T/tmpo5ki1p5h\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was African American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   certainty                  subject                       verb  \\\n",
       "0        1.0                   Martin                        was   \n",
       "1        1.0  Trayvon Benjamin Martin  was African American from   \n",
       "2        1.0  Trayvon Benjamin Martin          was American from   \n",
       "3        1.0  Trayvon Benjamin Martin                        was   \n",
       "4        1.0  Trayvon Benjamin Martin                        was   \n",
       "\n",
       "             object  \n",
       "0           African  \n",
       "1           Florida  \n",
       "2           Florida  \n",
       "3          American  \n",
       "4  African American  "
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF1 = stanford.openIE(text[3])\n",
    "ieDF1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still the same and it seems that the parser stops at the second comma of the sentence. Let's try to break the sentence and see if it can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1 = 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida.'\n",
    "text2 = 'Trayvon Benjamin Martin, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.0 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 13.21 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [15.2 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0101 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/r0/knnmzsq17t32vsdpgs17k_9m0000gn/T/tmpq0k0dbmu\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was American from</td>\n",
       "      <td>Miami Gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was African American from</td>\n",
       "      <td>Miami Gardens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was African American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   certainty                  subject                       verb  \\\n",
       "0        1.0  Trayvon Benjamin Martin          was American from   \n",
       "1        1.0  Trayvon Benjamin Martin  was African American from   \n",
       "2        1.0  Trayvon Benjamin Martin                        was   \n",
       "3        1.0  Trayvon Benjamin Martin                        was   \n",
       "4        1.0  Trayvon Benjamin Martin          was American from   \n",
       "5        1.0  Trayvon Benjamin Martin  was African American from   \n",
       "6        1.0                   Martin                        was   \n",
       "\n",
       "             object  \n",
       "0     Miami Gardens  \n",
       "1     Miami Gardens  \n",
       "2  African American  \n",
       "3          American  \n",
       "4           Florida  \n",
       "5           Florida  \n",
       "6           African  "
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF2 = stanford.openIE(text1)\n",
    "ieDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.0 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 14.09 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [16.0 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0172 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/r0/knnmzsq17t32vsdpgs17k_9m0000gn/T/tmpk7dvaxt5\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - No extractions in: /var/folders/r0/knnmzsq17t32vsdpgs17k_9m0000gn/T/tmpk7dvaxt5\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [certainty, subject, verb, object]\n",
       "Index: []"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF3 = stanford.openIE(text2)\n",
    "ieDF3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not perform better even if we break the sentence. It fails on `text2` maybe because it has too many parenthetical phrases. It informs us that it is possible that the dependency parser we use ignores some part of the sentences due to the complexity of them. Therefore, we should carefully choose the parser and examine the performance of it. It might be helpful to compare the results among different versions of parsers and try to break the sentences before being parsed. And we should always be cautious about the machine work just the same as we are about human work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also look for subject, object, target triples in one of the reddit stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.0 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 13.428 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [15.0 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0092 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/r0/knnmzsq17t32vsdpgs17k_9m0000gn/T/tmpdtopvbhc\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ieDF = stanford.openIE(redditTopScores['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll get</td>\n",
       "      <td>calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>we</td>\n",
       "      <td>Quite often 'll get</td>\n",
       "      <td>calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>we</td>\n",
       "      <td>often 'll get</td>\n",
       "      <td>calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.831036</td>\n",
       "      <td>we</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct to TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>straight analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct from wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct from wall to TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>straight analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct to TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>we</td>\n",
       "      <td>would supply analog cable to</td>\n",
       "      <td>homes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.831036</td>\n",
       "      <td>we</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct from wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.774359</td>\n",
       "      <td>analog cable</td>\n",
       "      <td>coax</td>\n",
       "      <td>direct from wall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   certainty                subject                          verb  \\\n",
       "0   1.000000                     we                       'll get   \n",
       "1   1.000000                     we           Quite often 'll get   \n",
       "2   1.000000                     we                 often 'll get   \n",
       "3   0.831036                     we                          coax   \n",
       "4   0.774359  straight analog cable                          coax   \n",
       "5   0.774359           analog cable                          coax   \n",
       "6   0.774359  straight analog cable                          coax   \n",
       "7   1.000000                     we  would supply analog cable to   \n",
       "8   0.831036                     we                          coax   \n",
       "9   0.774359           analog cable                          coax   \n",
       "\n",
       "                   object  \n",
       "0                   calls  \n",
       "1                   calls  \n",
       "2                   calls  \n",
       "3            direct to TV  \n",
       "4        direct from wall  \n",
       "5  direct from wall to TV  \n",
       "6            direct to TV  \n",
       "7                   homes  \n",
       "8        direct from wall  \n",
       "9        direct from wall  "
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ieDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's almost 200 triples in only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(redditTopScores['sentences'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentences and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(s) for s in redditTopScores['sentences'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find at the most common subject in this story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I                        48\n",
       "it                       42\n",
       "he                       19\n",
       "He                       18\n",
       "we                       11\n",
       "old man                   8\n",
       "man                       8\n",
       "call                      4\n",
       "letter                    4\n",
       "analog cable              4\n",
       "straight analog cable     4\n",
       "our booking calendar      4\n",
       "my supervisor             3\n",
       "TV                        2\n",
       "they                      2\n",
       "his TV set                2\n",
       "you                       2\n",
       "people                    1\n",
       "repeat offenders          1\n",
       "our digital equipment     1\n",
       "handling                  1\n",
       "our equipment             1\n",
       "me                        1\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I is followed by various male pronouns and compound nouns (e.g., \"old man\"). 'I' occures most often with the following verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "could come                        8\n",
       "even brought                      5\n",
       "brought                           5\n",
       "had                               4\n",
       "was                               4\n",
       "speak for                         3\n",
       "complaint in                      1\n",
       "have                              1\n",
       "had cable within                  1\n",
       "think occasionally about          1\n",
       "'ve dealt with                    1\n",
       "took                              1\n",
       "still think occasionally about    1\n",
       "get to                            1\n",
       "think about                       1\n",
       "instantly felt                    1\n",
       "still think about                 1\n",
       "speak with                        1\n",
       "get                               1\n",
       "eventually had                    1\n",
       "anyway get                        1\n",
       "felt                              1\n",
       "ask                               1\n",
       "do                                1\n",
       "So anyway get                     1\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the following objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr. Smith                                             4\n",
       "call                                                  3\n",
       "him                                                   3\n",
       "simplified remote                                     2\n",
       "simplified remote for his set top box                 2\n",
       "remote                                                2\n",
       "bad                                                   2\n",
       "this                                                  2\n",
       "remote for his set top box                            2\n",
       "get                                                   2\n",
       "willing                                               2\n",
       "speak with her for bit                                1\n",
       "speak                                                 1\n",
       "book                                                  1\n",
       "cable running                                         1\n",
       "how useless                                           1\n",
       "speak with her                                        1\n",
       "experience                                            1\n",
       "speak for bit about account for Mr. Smith             1\n",
       "bit about account for Mr. Smith                       1\n",
       "bit                                                   1\n",
       "it                                                    1\n",
       "residence                                             1\n",
       "her                                                   1\n",
       "speak for bit about account                           1\n",
       "speak for bit                                         1\n",
       "cable                                                 1\n",
       "useless                                               1\n",
       "cable running again                                   1\n",
       "speak with her for bit about account for Mr. Smith    1\n",
       "bit about account                                     1\n",
       "30 seconds                                            1\n",
       "speak with her for bit about account                  1\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'I']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run the corenlp server. When you run this server (with the command below), you can click on the browswer link provided to experiment with it. Note that when we run the server, executing the command below, it interrupts the current jupyter process and you will not be able to run code here again (processes will \"hang\" and never finish) until you interrup the process by clicking \"Kernel\" and then \"Interrupt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server on http://localhost:16432 , please wait a few seconds\n"
     ]
    }
   ],
   "source": [
    "stanford.startCoreServer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 5*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform open information extraction on a modest subset of texts relevant to your final project. Analyze the relative attachment of several subjects relative to verbs and objects and visa versa. Describe how you would select among these statements to create a database of high-value statements for your project and then do it by extracting relevant statements into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform  open information extraction on the first plot summary in my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.1 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 14.377 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [16.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0117 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/r0/knnmzsq17t32vsdpgs17k_9m0000gn/T/tmp0y2xqkby\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>sacrifice</td>\n",
       "      <td>is in</td>\n",
       "      <td>ancient ethnic group from south of Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>We</td>\n",
       "      <td>see</td>\n",
       "      <td>killing of other species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>We</td>\n",
       "      <td>see</td>\n",
       "      <td>killing of species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>We</td>\n",
       "      <td>see</td>\n",
       "      <td>killing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>are</td>\n",
       "      <td>executor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>victim of</td>\n",
       "      <td>themselves</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   certainty    subject       verb                                    object\n",
       "0        1.0  sacrifice      is in  ancient ethnic group from south of Italy\n",
       "1        1.0         We        see                  killing of other species\n",
       "2        1.0         We        see                        killing of species\n",
       "3        1.0         We        see                                   killing\n",
       "4        1.0   Everyone        are                                  executor\n",
       "5        1.0   Everyone  victim of                                themselves"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_ieDF = stanford.openIE(plots['plot'][0])\n",
    "plot_ieDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the original text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sacrifice of pig in some ancient ethnic group from the south of Italy, to represent the brutality of human beings rooted in every aspect of our contemporary society. We see one of the primitive and archaic human behaviour that has driven his struggle for life, the killing of other species. Everyone at the same time are the executor and the victim of themselves.'"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots['plot'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 triples in 3 sentences and 69 words.\n"
     ]
    }
   ],
   "source": [
    "print('There are', len(plot_ieDF), 'triples in', len(plots['sentences'][0]), 'sentences and'\\\n",
    "      , sum([len(s) for s in plots['sentences'][0]]), 'words.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common subjects in this plot summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "We           3\n",
       "Everyone     2\n",
       "sacrifice    1\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_ieDF['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common verbs in this plot summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "see          3\n",
       "are          1\n",
       "victim of    1\n",
       "is in        1\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_ieDF['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common objects in this plot summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "executor                                    1\n",
       "killing                                     1\n",
       "ancient ethnic group from south of Italy    1\n",
       "killing of other species                    1\n",
       "killing of species                          1\n",
       "themselves                                  1\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_ieDF['object'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We\" occures most often with the following verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "see    3\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_ieDF[plot_ieDF['subject'] == 'We']['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We\" occures most often with the following objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "killing of other species    1\n",
       "killing                     1\n",
       "killing of species          1\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_ieDF[plot_ieDF['subject'] == 'We']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently there are way too little information been extracted by the open information extraction and many of the information found are repetitive in one or two parts of the triples. It seems that the parser only extracted the very basic and main ideas of a sentence and sacrificed the details. Though it is not a complete extraction of information, it is somehow useful if we only want the most basic information, for example, if we just want information about \"who do what\" with each component being consist of one word, we can make use of the open information extraction as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "      <th>subject_len</th>\n",
       "      <th>verb_len</th>\n",
       "      <th>object_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>sacrifice</td>\n",
       "      <td>is in</td>\n",
       "      <td>ancient ethnic group from south of Italy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>We</td>\n",
       "      <td>see</td>\n",
       "      <td>killing of other species</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>We</td>\n",
       "      <td>see</td>\n",
       "      <td>killing of species</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>We</td>\n",
       "      <td>see</td>\n",
       "      <td>killing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>are</td>\n",
       "      <td>executor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>victim of</td>\n",
       "      <td>themselves</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   certainty    subject       verb                                    object  \\\n",
       "0        1.0  sacrifice      is in  ancient ethnic group from south of Italy   \n",
       "1        1.0         We        see                  killing of other species   \n",
       "2        1.0         We        see                        killing of species   \n",
       "3        1.0         We        see                                   killing   \n",
       "4        1.0   Everyone        are                                  executor   \n",
       "5        1.0   Everyone  victim of                                themselves   \n",
       "\n",
       "   subject_len  verb_len  object_len  \n",
       "0            1         2           7  \n",
       "1            1         1           4  \n",
       "2            1         1           3  \n",
       "3            1         1           1  \n",
       "4            1         1           1  \n",
       "5            1         2           1  "
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_ieDF['subject_len'] = plot_ieDF['subject'].str.split().str.len()\n",
    "plot_ieDF['verb_len'] = plot_ieDF['verb'].str.split().str.len()\n",
    "plot_ieDF['object_len'] = plot_ieDF['object'].str.split().str.len()\n",
    "plot_ieDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "      <th>subject_len</th>\n",
       "      <th>verb_len</th>\n",
       "      <th>object_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>We</td>\n",
       "      <td>see</td>\n",
       "      <td>killing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>are</td>\n",
       "      <td>executor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   certainty   subject verb    object  subject_len  verb_len  object_len\n",
       "3        1.0        We  see   killing            1         1           1\n",
       "4        1.0  Everyone  are  executor            1         1           1"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_statement = plot_ieDF.loc[(plot_ieDF['subject_len'] == 1) & (plot_ieDF['verb_len'] == 1) & (plot_ieDF['object_len'] == 1)]\n",
    "main_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
