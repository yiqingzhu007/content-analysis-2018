{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Classification\n",
    "\n",
    "This week, we shift from gathering human textual classifications through crowdsourcing, to using machine learning models and algorithms that train on those human classifications and extend them to documents far too numerous to read. If you recall, *clustering* allows us to stably partition text data (e.g., documents, turns of conversation) according to all patterns of covariation among available text features. *Classification*, by contrast, partitions text data according to only those features and their variation that enable us to mimic and extrapolate human annotations.\n",
    "\n",
    "In this notebook, we will show how to use a variety of classification methods, including Na√Øve Bayes, Logistic regression, K-nearest neighbor, decision trees and random forests, support vector machines and even a simple neural network, the perceptron. We will also demonstrate ensemble techniques that can link several such methods into a single, more accurate, classification pipeline. We will finally learn to use conventions and metrics to evaluate classifier performance on out-of-sample data. \n",
    "\n",
    "For this notebook we will be using the following packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For ML\n",
    "import sklearn\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "import sklearn.neural_network\n",
    "import sklearn.decomposition\n",
    "\n",
    "import nltk #For tokenizing and normalizing\n",
    "import numpy as np #arrays\n",
    "import matplotlib.pyplot as plt #Plots\n",
    "import matplotlib.colors # For nice colours\n",
    "import seaborn #Makes plots look nice, also heatmaps\n",
    "import scipy as sp #for interp\n",
    "\n",
    "#These are from the standard library\n",
    "import collections\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import glob\n",
    "import pandas\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Simulated Examples\n",
    "\n",
    "Here we create a sandbox for you to explore different types of classified data and how different statistical classifiers perform on each type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating example data\n",
    "\n",
    "We start by loading one of the \"cartoon\" or simplified data sets and then dividing it into training and testing sets. To maximize our ability to visualize, each dataset involves two classes, colored yellow and blue, arrayed along two two dimensions (`x` and `y`). \n",
    "\n",
    "The four data patterns include: \n",
    "+ `random` in which the two classes are randomly distributed across both dimensions\n",
    "+ `andSplit` in which the two classes are linearly split along one of two dimensions (e.g., men like Adidas)\n",
    "+ `xorSplit` in which the two classes are split, oppositely, along each dimension (e.g., old ladies and young men like Nikes)\n",
    "+ `targetSplit` in which one class is nested within the other in two dimensions (e.g., middle aged, middle income people like vintage Mustangs)\n",
    "+ `multiBlobs` in which 5 classes are placed as bivariate Gaussians at random locations\n",
    "\n",
    "`noise` is a variable [0-1] that ranges from no noise in the prescribed pattern [0] to complete noise/randomness [1].\n",
    "\n",
    "Uncomment (remove the # in front of) each dataset, one at a time, and then run the cell and subsequent cells to examine how each machine learning approach captures each pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = .2\n",
    "\n",
    "#dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.random())\n",
    "#dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.andSplit(noise))\n",
    "#dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.xorSplit(noise)) #Please try this one\n",
    "dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.targetSplit(noise))\n",
    "#dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.multiBlobs(noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily visualize the rendered datasets because they are generated in two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotter(dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Machine Learning algorithm\n",
    "\n",
    "We can now pick a model, there are many more options in `scikit-learn`. These are just a few examples, which array along the machine learning \"tribes\" described in Pedro Domingos _The Master Algorithm_.\n",
    "\n",
    "Uncomment (remove the # in front of) each algorithm one at a time, then run the cell and subsequent cells to evaluate how it learns to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bayes\n",
    "#clf = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "#Analogizes\n",
    "#clf = sklearn.svm.SVC(kernel = 'linear', probability = True) #slow, set probability = False to speed up\n",
    "#clf = sklearn.svm.SVC(kernel = 'poly', degree = 3, probability = True) #slower\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')# k, 'distance' or 'uniform'\n",
    "\n",
    "#Classical Regression\n",
    "#clf = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "#Symbolists\n",
    "#clf = sklearn.tree.DecisionTreeClassifier()\n",
    "#clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "#Connectionists\n",
    "#clf = sklearn.neural_network.MLPClassifier()\n",
    "\n",
    "#Ensemble\n",
    "#clf = sklearn.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model by giving it our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm evaluation\n",
    "\n",
    "We can look at few measurements of each classifier's performance by using the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf, dfTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lets us look at which classes do better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf, dfTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The greater the area under the curve the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotMultiROC(clf, dfTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the regions the classifer identifies as one class or the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf, dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we do the same for real data\n",
    "\n",
    "Available data sets include:\n",
    "+ Reddit threads \"classified\" by thread topic\n",
    "+ 20 newsgroups \"classified\" by group topic\n",
    "+ Senate press releases \"classified\" by Senator (2 senators)\n",
    "+ Senate press releases \"classified\" by Senator (5 senators)\n",
    "+ Emails classified as Spam or Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.loadReddit())\n",
    "#dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.loadNewsGroups())\n",
    "#dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.loadSenateSmall())\n",
    "#dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.loadSenateLarge())\n",
    "#dfTrain, dfTest = lucem_illud.trainTestSplit(lucem_illud.loadSpam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bayes\n",
    "clf = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "#Analogizes\n",
    "#clf = sklearn.svm.SVC(kernel = 'linear', probability = True) #slow, set probability = False to speed up, but lose ROC\n",
    "#clf = sklearn.svm.SVC(kernel = 'poly', degree = 3, probability = True) #slower\n",
    "#clf = sklearn.neighbors.KNeighborsClassifier(5, weights='distance')# k, 'distance' or 'uniform'\n",
    "\n",
    "#Classical Regression\n",
    "#clf = sklearn.linear_model.LogisticRegression()\n",
    "\n",
    "#Symbolists\n",
    "#clf = sklearn.tree.DecisionTreeClassifier()\n",
    "#clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "#Connectionists\n",
    "#clf = sklearn.neural_network.MLPClassifier()\n",
    "\n",
    "#Ensemble\n",
    "#clf = sklearn.ensemble.GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(np.stack(dfTrain['vect'], axis=0), dfTrain['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf, dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf, dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotMultiROC(clf, dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf, dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">Go back through all of the cells above and generate 10 distinct artificial datasets and classify them with all of the available methods. Add a cell immediately below and describe which classifier(s) worked best with which artificially constructed data source and why. Then go through all of the empirical datasets (i.e., Newsgroups, Senate Small, Senate Large, Email Spam) and classify them with all available methods. Add a second cell immediately below and describe which classifier(s) worked best with which data set and why.\n",
    "\n",
    "<span style=\"color:red\">***Stretch*** (but also required) Wander through the SKLearn documentation available [here](http://scikit-learn.org/stable/), particularly perusing the classifiers. In cells following, identify and implement a new classifier that we have not yet used (e.g., AdaBoost, CART) on one artificial dataset and one real dataset (used above). Then, in the next cell describe the classifier, detail how it compares with the approaches above, and why it performed better or worse than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinton / Obama Press Releases\n",
    "\n",
    "We often will not have nicely prepared data, so we will work though the proccess of cleaning and structuring in more detail here:\n",
    "\n",
    "While the Clinton and Obama Senatorial Press Releases are not hand-coded, we can imagine that we have been given a stack of such press releases, but lost the metadata associated with which senatorial office issued which. If we label a few of them, how well can our classifier do at recovering the rest? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ObamaClintonReleases = pandas.read_csv('../data/ObamaClintonReleases.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn the 'targetSenator' column into a binary category variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ObamaClintonReleases['category'] = [s == 'Obama' for s in ObamaClintonReleases['targetSenator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ObamaClintonReleases['tokenized_text'] = ObamaClintonReleases['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "ObamaClintonReleases['normalized_text'] = ObamaClintonReleases['tokenized_text'].apply(lambda x: lucem_illud.normalizeTokens(x, stopwordLst = lucem_illud.stop_words_basic, stemmer = lucem_illud.stemmer_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into training data and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_data_df, test_data_df = lucem_illud.trainTestSplit(ObamaClintonReleases, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(train_data_df))\n",
    "print(len(test_data_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try with a logistic regression, which may be familiar to you from statistical methods classes. First, we must turn the training dataset into a tf-idf matrix (`lucem_illud.generateVecs()` will help with this but for now we are doing it the long way):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects = TFVectorizer.fit_transform(train_data_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use the CountVectorizer instead, which simply produces a matrix of word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1368, 11473)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFVects.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save this in the dataframe to make things easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_df['vect'] = [np.array(v).flatten() for v in TFVects.todense()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a regression, we cannot have more variables than cases. So, we need to first do a dimension reduction. First, we will approah this with PCA. You have previously seen this in week 3. Here we are not concerned about visualization, but rather classification and so all principal components are calculated. Watch out: we have to use `stack` not `sum` for combining the vectors. We note that you could also use topic loading and embedding dimensions as featured variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA()\n",
    "reduced_data = pca.fit_transform(np.stack(train_data_df['vect'], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store the PCA space vectors in the dataframe too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_df['pca'] = [r for r in reduced_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization in 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAJOCAYAAACJNWIjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3X9wXPV97//XZ1eWVjK2i7ETMMEy\nGNvYGEziTKoYSjtxgpJ7SaadVjQxhNaobgkwIc2Pb7+jb+ZOv50bf29uMr2XYiiNo/BtLjgNatJm\n8L2J2pLvhMZcJcUEE2NjE4FlinFiQWKMpJW0ez7fP/asfHZ1zv7S2bO/no8ZRujs2dXReiW99vN5\nf94fY60VAAAAohGr9QUAAAC0EsIXAABAhAhfAAAAESJ8AQAARIjwBQAAECHCFwAAQIQIXwCqwhjz\nfmPMiVpfRy0ZY/qNMY+HfS6Axkb4AhqUMeYtz3+OMWbK8/mtEV1DjzHme8aYs8aYN4wxPzLG3B7F\n1w6bMeYPPM/flPucZj//VSWPaa0dtNZ+OOxzy2WM+S1jzIjn3+mHxpjrSrhfwhhjjTHvqMZ1Aa2K\n8AU0KGvtBdn/JJ2U9GHPsUfzzzfGtIX59Y0xN0j6F0lPSLpC0kWS7pH0H8L8OlGx1v6t5/n8sKST\nnufz1/LPD/v5rBZjzEWSviPpS5IulPQOSV+QNFPL6wJaGeELaFLGmP9sjPmmMeYbxphzkm4zxjxi\njPlzzzk5U4PGmHcYY/7BGHPGGPOyMebuAl/iy5IGrbVfsta+bjP+zVr70YDr+bwx5iVjzDljzPPG\nmI94bltvjHnSHZkZN8bsc4/HjDF/ZYz5hXvbc8aYTe5tCWPMXxpjXjHG/NwY86AxJuHe9jZjzP8y\nxvzKHel5cgFPpfd7OG2M+awx5nlJb7rH/pP7XJ0zxhw2xvxHz/l3GmP+xXO91hjzx8aYUWPML40x\n/63Cc9vc5+V19/ZPGmNSAZe9UdKUtfZb1lrHWjtprf2utfaI5/H+xBhzzH2u/qcx5lL3puzzdswd\nAfztEJ5GoOURvoDm9juS9klaJumbhU40xsQk7Zf0b5IulfQBSZ8zxmz3OXeJpPdI+vsyruW4pOvd\na/mCpH3GmLe7t31B0v/U+ZGZB9zjH5LUI2mde9tHJb3h3vYlSZdLuta9fY2k/8u97XOSXpK0UtLF\nkj5fxnUW8/vKPDcXuZ8fk7TN/b6+KOnvjDErCtz/g5LeKeldknYaY36rgnPvkfSbkjYr8+/wewUe\n46ikTmPMoDGm1xiTM4pnjPl9SZ9SZrTv7ZJ+IukR9+Yb3Y8b3BHAfyzwdQCUiPAFNLcfWmsfd0c8\npoqc+15JS621u621M9ban0kaVCbw5FsuyUh6rdQLsdY+Zq19zb2WfZJOSHq3e/OsMuHpEmtt0lp7\nwHN8qaSr3Mc4Yq097QbFXZI+Za39pbX2TUn/j+daZyWtkrTa/V5CGfly/Tdr7ans82mt/abn+/of\nkl6VtLXA/Xdba9+01r6szMhSodqroHNvkfSX7td9XdJ/DXoA9/brJS2S9LCkM8aYb3sC4p2S/rO1\n9ri1dlbS/y3pBk8wBhAywhfQ3F4p49xuSavdqbpfuUXm/4cyI0f53pBkJV1S6oMbY/7QGHPI89hX\nScoGgM8oEw6eNsb81BjzB5Jkrf0nSQ9J+mtJPzfGPOSOul0sqUOS9/H2S3qb+3j/RdKYpCfcabnP\nlfE8FJPznJrMKsXnPNdxpef78nPa8/+Tki6o4NxVeddR8N/ZWnvYWnu7tXaVMgFurTIjh1Lm3/0h\nz/WfkZRSZgQSQBUQvoDmZvM+n5DU5fncG6xekfSitfbXPP8t8VuBZ609J+nHkn63lIswxlyhTID6\nhKSL3AL2F5QZPZM7gvNH1tpLJN0t6SvGmMvd2/67tfZdykyxbZL0aUk/V6ZgfIPnWpdZa5e593nT\nWvun1to1kn5b0p8ZY36zlGstwdxzaoxZL+l+SX8sabn7ff0s+31V0WvKDUeXlXpHa+3zkv6HMs+n\nlPl3/8O8f/dOa+1BzX/9AAgB4QtoLc9K+o/GmAuNMZdI+qTntv8tacYY8xm34DtujLnGGBM0hfY5\nSX9kjPm0MWa5JBlj3pktls9zgTJ/yM9kTjO75E4luve7xVPk/Sv33LQx5j3uf23KBMcZSY61Ni3p\nq5L+uzFmpcl4hzHmJvfxPmyMWWuMMZLOSkpLctzbHjHGfLXcJy7ABe7jnpEUM8bcqczIV7U9JulP\njTEXm8xqxs8Gnej+G34q+/waY9YoU7c24p7ykKTPG2M2uLdfaIz5XUmy1k4r8/xdUa1vBGhFhC+g\ntfy/yhRgj0n6nqS/y95grU0p0ybiPcrUY41L+htlaq7msdb+q6T3S+qVdMIY84Yyo1v/y+fc55QZ\nIfqxMqM2GyT9yHPKr0v6N2PMhKRvS7rbWntS0q8pU3f2K/eaXpP0l+59PuN+Hz9WJiD8kzKF93If\n//uS3pJ0QNJ97vVKmVGibE3Zglhrn1EmvDztXtvl7v9X2x5JT0k6osz3v1/SdMC5b0q6Qeef3x+6\n9/k/Jcla+w338b5tjHlTmYD+Ac/9/5OkIXda8iMCsGDGWkaVAbQGk2lF8Yyka92w2RSMMb8j6b9Y\nazfU+loAFMfIF4CW4a6k3NTowcsYs8QYc5M7NbxamVYa/1Dr6wJQGka+AKDBGGOWSfr/JK1XZmr1\ncUl/aq19q6YXBqAkhC8AAIAIMe0IAAAQIcIXAABAhAhfAAAAESJ8AQAARIjwBQAAECHCFwAAQITa\nan0BAACgMR08ePBtbW1tX1Vmo/ZWGNBxJB1OpVJ/tHXr1l9U+iCELwAAUJG2travXnzxxRtXrlz5\ny1gs1vSNQx3HMWfOnNl0+vTpr0qqeK/TVkipAACgOjavXLnyzVYIXpIUi8XsypUrzyoz0lf544R0\nPQAAoPXEWiV4Zbnf74LyE+ELAAAgQoQvAABQNV1dXe8s9dxkMmnuuOOOy1avXr25u7t78/bt29eO\njo4ukqRjx461r1u37urqXWl0CF8AAKAufPKTn7z0rbfeir300kuHx8bGDn/kIx/51W//9m9f6ThO\nrS8tVIQvAABQdWNjY4ve/e53b7jqqqs2rVu37urvfe97F3hvP3fuXOyxxx5b8dBDD73S1pZpxnDv\nvfe+3t7e7jz++ONLJCmVSukjH/nI5VdcccXVH/zgB684d+5cTJI++9nPXrJ58+aN69atu/pjH/tY\ndzasvec979nQ399/2ebNmzdeccUVV//gBz/ouummm9Z2d3dv/uQnP7kq+7Xf//73r7366qs3Xnnl\nlVd/+ctfXlHt54LwBQAAqu5rX/va8u3bt5994YUXjhw9evT5X//1X5/03n7kyJGOSy65ZGb58uU5\nw1zXXXfd5E9/+tNOSTpx4kTinnvu+cVLL730/JIlS5wvfelLKyXpc5/73C8OHz589MUXX3x+amoq\n9nd/93fLsvdvb293Dh8+fHTnzp1n+vr6rty7d+/JF1544flvfvObK06fPh2XpEcfffTE888/f/TZ\nZ5898jd/8zdvzx6vFsIXAACoup6enolvfOMbKz796U+v+vGPf9x54YUXlj2XePHFF8/cdNNNE5L0\n8Y9//PWnnnrqAkn67ne/u+Taa6+9av369ZueeuqpJYcPH+7M3ud3fud3fiVJW7Zsmbryyiunuru7\nZzs7O+1ll102/dJLL7VL0he/+MW3b9iwYdPWrVs3nj59etHzzz+fCOe79kf4AgAAVfehD33orSef\nfPLYpZdeOnPHHXdcvmfPnou8t2/cuHH6tddea//lL3+Zk00OHTrUdc0110xJkjEm5zGNMZqcnDSf\n+cxnur/97W+PHj9+/Mhtt902nkwm5x4jkUhYSYrFYuro6JhrixGLxZRKpcz+/fuX/OAHP1jy9NNP\nv3Ds2LEjGzdunJqamqpqPiJ8AQCAqjt+/Hj7O97xjtnPfOYz47fffvuZZ555pst7+9KlS53f+73f\nG//EJz5xWSqVkiTt2bPnomQyGfvwhz98TpJee+219n/5l39ZLEmPPvro8m3btr01OTkZk6SLL744\ndfbs2djjjz9+YTnX9atf/Sq+bNmy9JIlS5yf/OQniUOHDi0O5RsugO2FAABA1Q0PDy/5q7/6q4vb\n2tpsV1dX+tFHH305/5z777//1TvvvPMdl19++eZYLKa1a9cm//Ef//FnsVhmrGjNmjXJ+++//21/\n/Md/3LVu3brkZz/72TNLlixxbr311jMbN268euXKlaktW7ZMlHNdv/u7v3v2K1/5ysorrrji6iuu\nuCJZ7v0rYaxtqca0AAAgJIcOHTqxZcuW8VpfR9QOHTq0YsuWLWsqvT/TjgAAABEifAEAAESI8AUA\nABAhwhcAAECECF8AAAARInwBAABEiD5fJRoacXZI2i1ptaSTkgb6emL7antVAAC0rtOnT8d/67d+\na4MkjY+PL4rFYnb58uUpSXr22WePZrvb1xvCVwnc4LVXUrYbb7ekvUMjjghgAADUxsUXX5x+4YUX\njkjSpz/96VUXXHBB+i/+4i9+7j3HcRxZaxWPV3Wv7LIw7Via3TofvLK63OMAAKAEo6ed5Y8fdK4Z\nGnG2Pn7QuWb0tLO8Gl/n8OHDHWvXrr36Ix/5yOXr1q27enR0tH3JkiXXZW//yle+cuHv//7vd0vS\nK6+80nbTTTet3bx588Zrrrlm4xNPPMH2QnVidZnHAQCAx+hpZ/mzY+p2bGbgJzmr9mfH1C05Wntx\n7I2wv97LL7+cePjhh1++8cYbJ2dnZwPPu/POO1f/2Z/92ent27dPHDt2rP3mm29e9+KLLz4f9vV4\nEb5Kc1KZqUa/4wAAoIgjr+rSbPDKcqxiR17VpWsvVujh67LLLpu+8cYbJ4udd+DAgaWjo6OJ7Odn\nz56Nv/XWW+aCCy6oWr0Y4as0A8qt+ZKkSfc4AAAoIjmr9nKOL1RnZ6eT/f/sxtxzXzOZnDtgrY28\nOJ+arxK4RfW7JI1Jsu7HXRTbAwBQmsQizZRzPEzxeFxLly5N//SnP+1Ip9P6zne+82vZ266//vo3\nv/jFL67Mfv7UU091Vvt6GPkqkRu0CFsAAFRg06V61VvzJUkxI2fTpXo1iq//53/+5//+oQ99aP1F\nF100e+21107OzMwYSfrqV7968o477li9fv36Fel02mzbtu3ctm3bqlpWZKytyxYYAACgzh06dOjE\nli1bxks9f/S0s/zIq7o0Oav2xCLNbLpUr1aj2L7aDh06tGLLli1rKr0/I18AACASay+OvVGN4vpG\nQ/gqE53uAQDAQhC+8iSHB+eFq0Rv/z6JTvcAAGDhWO3o4QavvcqEKuN+3Osel+h0DwAAFojwlatY\nuKLTPQAAWBDCV65i4Spo6Smd7gEAQEkIX7mKhasBZTrbe9HpHgCAGonH41uvuuqqTdn/jh07Ftgx\n/9ixY+3r1q27Osrr80PBfa6C2wj19cT2DY04EqsdAQCoCx0dHc4LL7xwpNbXUQ7Cl0eit39fcnhQ\nCljtKNHpHgCASqVOHl2eeuknl2p6ql0dnTNtV7zz1bbVG0Pv+3Xs2LH2HTt2XD41NRWTpPvuu+/k\nBz7wgQnvOU8//XRi586dl8/OzhrHcfStb31r9Jprrpl+8MEHl//1X//122dnZ8273vWuia9//etj\nbW3hxiXCVx43aBGuAAAIUerk0eWpYz/qlpPOlDxNT7Wnjv2oW5IWEsCmp6djV1111SZJuuyyy6b/\n+Z//eXTVqlWpf/3Xfz3e1dVlf/rTn3Z87GMfu+Lw4cNHvfe7//77V951110//8QnPvFGMpk0qVRK\nzzzzTOLv//7vlz/99NMvdHR02Ntuu231Qw89dNE999zz+gK+9XkIXyrc2wsAACxc6qWfXDoXvLKc\ndCz10k8uXUj48pt2nJmZMf39/d1HjhzpjMViGhsb68i/33vf+96JL3/5y5f8+7//e/tHP/rRX15z\nzTXT3/ve95YcPny4a8uWLRslKZlMxt72trelKr22IC0fvjy9vXIapyaHB0UAAwAgJNNT/oXwQccX\n4Atf+MLb3/a2t81+61vfetlxHHV2dm7NP+fOO+984zd+4zcm/uEf/mHZzTffvO7+++8fs9aavr6+\n1x944IGqbvbNakcapwIAUH0dnTNlHV+As2fPxi+55JLZeDyuBx988KJ0Oj3vnCNHjrRv3Lhx+vOf\n//wvent7f/Xss892fvCDH3xz//79F7766qttkvTzn/88fvz48dDDIeGLxqkAAFRd2xXvfFWxuJNz\nMBZ32q54Z+ijTJ/61Kd+8Y1vfOOiDRs2bHrhhRcSnZ2dTv45jzzyyPL169dffdVVV206evRo55/8\nyZ+8vnXr1uTnP//5V7dv375+/fr1m973vvetf+WVVxaFfX3GWhv2YzaU5PDgCWWmGvONJXr710R7\nNQAANI5Dhw6d2LJly3ip50e12rHaDh06tGLLli1rKr1/y9d8qUhvLwAAEI621RvfaMSwFbaWn3Z0\ni+p3SRqTZN2Puyi2BwAA1cDIl+jtBQBAhRzHcUwsFmuZGibHcYykeTVk5Wj5kS8AAFCxw2fOnFnm\nBpKm5ziOOXPmzDJJhxfyOIx8AQCAiqRSqT86ffr0V0+fPr1ZrTGg40g6nEql/mghD9Lyqx0BAACi\n1AopFQAAoG4w7VimoRFn3j6QfT0xivUBAEBJmHYsgxu8/HqC7SKAAQCAUjDtWB72gQQAAAvCtGMJ\nPFONftsQSewDCQAASkT4KiJgqjHfyYguBwAANDimHYvzm2r0Yh9IAABQMsJXcYWmFMdEsT0AACgD\n047FnZR/rddYX09sTcTXAgAAGhwjX8UNKDO16MVUIwAAqAjhqwh3SnGXMlOMVkw1AgCABaDJKgAA\nQIQY+QIAAIgQ4QsAACBChC8AAIAIEb4AAAAiRPgCAACIEOELAAAgQoQvAACACLG90AINjTg7lNl8\ne7UyWxEN0IAVAAAEocnqArjBa6+kLs/hSdEBHwAABGDacWF2Kzd4yf18dw2uBQAANADC18KsLvM4\nAABocYSvhTlZ5nEAANDiCF8LM6BMjZfXpHscAABgHsLXArhF9bskjUmy7keK7QEAQCBWO4aIthMA\nAKAYwldIaDsBAABKwbRjeGg7AQAAiiJ8hYe2EwAAoCi2FwrPSUndkrRqZlQbkwfVaSeUNF1Ocnhy\nR6K3n6lHAADAyFeIBiRNrpoZ1ZapA+qyEzKSOu1kXNLe5PDgjhpfHwAAqAOEr5Bk205sSj6dblM6\n/2ZqvwAAgCTCV6j6emL7Ou1k0HNK7RcAACB8VQFbDgEAgECEr/Cx5RAAAAhE+AqZu6px3pZDrHYE\nAAASHe4BAAAixcgXAABAhAhfAAAAEaLDfUjcJqq7lWkpcVLSAHVeAAAgHzVfIXCD117lbqw9KQrt\nAQBAHqYdw7FbucFLoqs9AADwQfgKR1D3erraAwCAHISvcNDVHgAAlISC+3AMyL/ma2BoxJlXiO9u\nwg0AAFoQBfch8Vvt+PiynVJAIT4BDACA1kT4qqKhEeeEpG6fm8b6emJror0aAABQD6j5qi4K8QEA\nQA7CV3VRiA8AAHIQvqprQJkaL69J9zgAAGhBhK8qcovqd0kak2TdjxTbAwDQwii4BwAAiBAjXwAA\nABGiyWqEaLgKAACYdoyIG7xouAoAQItj2jE6u5UbvOR+vrsG1wIAAGqE8BUdGq4CAADCV4RouAoA\nAAhfEaLhKgAAIHxFhYarAABAYrUjAABApBj5AgAAiBDhCwAAIEKELwAAgAgRvgAAACJE+AIAAIgQ\n4QsAACBChC8AAIAIEb4AAAAiRPgCAACIEOELAAAgQoQvAACACBG+AAAAItRW6wtAsKERZ4ek3ZJW\nSzopaaCvJ7avtlcFAAAWwlhra30N8OEGr72SujyHJyXtIoABANC4mHasX7uVG7zkfr67BtcCAABC\nQviqX6vLPA4AABoA4at+nQy6wZ2SBAAADYjwVWeGRpwdQyPOCQWPcBkx9QgAQMNitWMdCSiy98PU\nIwAADYqRr/riV2TvJ3BKEgAA1DfCV30pZURrUtJAtS8EAABUB+GrThQpok9LspLGRJ8vAAAaGjVf\n9WO3MsX0+ayk2wlcAAA0B8JX/Vi9amZUG5MH1WknNGUW62hiq061rxXBCwCA5kH4qhOXTR9/fXNy\nZEWb0pKkLjuhLVMHFLfp16Wranx1AAAgLNR81YnNyR8pG7yy2pTW5uSPanRFAACgGghfdaJNqYvK\nOQ4AABoT4at+BPXuoqcXAABNhPBVPwaU6eHlRU8vAACaDOGrTiR6+/dJ2qVML6+5nl7ucQAA0CQI\nX3XEDVoDykw1rpa0Ozk8WKj5KgAAaDDGWlvra4DLDVr5G2tPihEwAACaBiNf9cVvY+0u9zgAAGgC\nhK/6ErSxdikbbgMAgAZA+KovtJsAAKDJEb7qC+0mAABocoSvOkK7CQAAmh+rHQEAACLEyBcAAECE\nCF8AAAARInwBAABEiPAFAAAQIcIXAABAhNpqfQEo39CIs0OZLYdWK9OAdaCvJ0Y7CgAAGgCtJhqM\nG7z8Nt9+WNLNIpABAFDXCF8NZmjEOSGp2+cmK8l4Pp+UtIsABgBAfaHmq/EEbbJt8j7vUmZqEgAA\n1BHCV+MpZ5PtoKAGAABqhPDVePw23w6aOy4nqAEAgAgQvhqMW8OVv/n2g5ofyCaVCWoAAKCOUHDf\nJGg/AQBAYyB8AQAARIgmq3WIUSwAAJoXI191pkAT1ZJ6dhHcAACobxTc15/dyg1eUok9uzzBrVuZ\nvl/dkva6xwEAQB0gfNWfoN5cpfTsqji4AQCAaBC+6k9Qb65SenYtJLgBAIAIEL7qj18T1VJ7di0k\nuAEAgAiw2rHO9PXE9g2NOFJlRfMDl07/7GtXTT/T0WknNGUW64WOd02/2nElzVYBAKgTrHZsIsnh\nwR2OzMMx2fbsMUdmJia7M9Hbz4pHAADqANOOzWW3N3hJkvs5BfcAANQJwldzoeAeAIA6R/hqLhTc\nAwBQ5whfzWUhKyUBAEAECF9NxC2q3yVpTJJ1P+6i2B4AgPrBascmxP6OAADUL8JXk1noxtwAAKC6\nCF9NZmjEOaHMhtp+xsQoGAAANUXNV/Mp1FaiW9Jed3QMAADUAOGr+RRrK9El6esEMAAAaoPw1Xz8\n2k3ki4sRMAAAaoLw1WTceq5su4lCusS2QwAARI6C+ybmt/Jx1cyoNiYPqtNOaMosVpeduJU+YAAA\nRIfw1SSSw4Pzenslevv3uQHs65Liq2ZGtWXqgNqU9t51UjRiBQAgMkw7NgE3eO1VZjWjcT/uTQ4P\n7nCnIW+XNLkxeTA/eElMPwIAECnCV3PYrdymqnI/v086XwfWaSeC7l+oPQUAAAgR4as5BIWnFe6o\nmPp6YvtMcBF+sfYUAAAgJISv5lAoPHmnFP3aUEy6xwEAQAQIX82hUHiaGxVzi+qzbSis+5FiewAA\nIsRqxyaRHB48I2mFz01jid7+NRFfDgAACMDIV/O4V0wpAgBQ9whfTYIpRQAAGgPTjgAAABFi5AsA\nACBChC8AAIAIEb4AAAAiRPgCAACIEOELAAAgQoQvAACACLXV+gIQLXej7d3KbDt0UtIAvcAAAIgO\nfb5aiBu89krq8hyeFM1YAQCIDNOOrWW3coOX3M931+BaAABoSYSv1rLa76CVuodGnB1RXwwAAK2I\n8NVaTvodnDKLJWkvAQwAgOojfLWWAWVqvOakFNfRxFaJ6UcAACJB+GohblH9rkmzWFbSpFmsQ53X\n61T72uwpvtOSAAAgPKx2bEFDI84JSd0+N4319cTWRHs1AAC0Fvp8NZAQe3QNyL/lxMCCLxIAABTE\nyFeDCLtHl1tcnxPk+npi9PoCAKDKCF8NIjk8eEIBU4WJ3v410V4NAACoFAX3jSOoGJ4ieQAAGgjh\nq3H49ugqcBwAANQhwlfjmNejSxTJAwDQcKj5aiClrnYMcVUkAAAIGeGryYS9KhIAAISLacfms1u5\nwUti6yAAAOoG4av5sCoSAIA6RvhqPqyKBACgjrG9UPOpytZBFPEDABAOCu6bUNhBiSJ+AADCQ/hC\nUWxtBABAeJh2hC/vxts3S8b4n0YRPwAAZaLgHvO4wWuvMqNdZsosDjqVIn4AAMpE+IKfnF5hRxNb\nlVI8/xy2NgIAoAKEL/jJmU481b5Whzqv12RmBMxKGhPF9gAAVITwBT/zphNPta/V8Y7rxt3bVkva\n7a6CBAAAZSB8wc+AMtOKcy6d/tn0tcmnlsqtA3M/7iWAAQBQHsIX5unrie2TtEuZ6UUraeza5P8+\nF5NtzzuVPSMBACgTfb5QkuTwoKPMiFc+m+jtJ8QDAFAi+nwhUF6nfEeav+RRtJsAAKAshC/48tlS\nyC940W4CAIAyMV2EIDm9vjzSot0EAAAVY+QLQYK2DopR4wUAQOX4I4ogQbVc1HgBALAAhC8Emdfr\nS9R4AQCwYIQv+HJruXJ6fYkaLwAAFow+XwAAABFi5AsAACBCrHZsAXnNUk9KGmD6EACA2mDascn5\nNEuVMoXz1G8BAFADTDs2P79mqWyIDQBAjRC+ml9Qs9Sg4wAAoIqo+Wp+JyV1BxwvamjEmVcv1tcT\nY7oSAIAKEb6a34D8a76KNkt1g5f3vt2S9g6NONlTCGUAAJSJgvsWUOlqx6ER54T8R83GJS2V1O45\nNiNpZ19PbB+jZQAABCN8IdDQiONIMmXcZVzSvQpYXUkAAwCAaUcUFlQvJklaNTOqjcmD6rQTmjKL\ndTSxdcWp9rWFVlcSvgAALY/VjigkaHNtrZoZ1ZapA+qyEzKSuuyEtkwd0KqZ0aBVlN1DI84Jd0oS\nAICWRfhCIHeacN7m2pLGNyd/pDalc85vU1qbkk878x7ovGzBPgEMANCyqPlC2Y59/8k9q2dfvNuv\nGMxK2r9s56TmTz16jfX1xNZU5eIAAKhzjHyhbN2zL94cVIVvZbQu+ewPlRklC0KDVwBAy2LkCyXJ\na1dRcAVkWnEbV/q2x5ft3C3/gn1GvgAALYuRLxTl2Zy7WyW0nogrbZQJakEF+0UbvAIA0KwIXyiF\nX/uIYlYHFezT7wsA0Mro84UurJ/FAAAgAElEQVRS+NZoZSesA4bCTkpzKyYJWwAAuBj5Qil8N+E2\n0tjJReseSCueXzjI1CIAAAEIXyhFYO3WhvfdeE9c6duUN7VYyt6RAAC0IlY7oiSVbs4NAAByEb4A\nAAAixLQjAABAhAhfAAAAEaLVBCpCDRgAAJWh5gtl83S89zZenRSrHAEAKIppR1TCr+N9l3scAAAU\nQPhCJXw73hc4DgAAXIQvVMK3432B4wAAwEX4QiUCO97X4FoAAGgoFNyjIuWudhwacead7266DQBA\nSyF8oerc4OW7OpIABgAIUyO82WfaEVFgdSQAoOo8b/a7JRn34173eN0gfCEKrI4EAEShId7sE74Q\nhdcDjpt6ezcCAJhvaMTZMTTinBgacRz3Y73+7m6IN/uEL9RaXb0bAQDkapSpPFdDtEIifCEKFxW4\nra7ejQAA5mmIqTxXQ7RCInwhCoXecdTVuxEAwDwNMZUnSe6qxl2SxiRZ92Pdraxvq/UFoCUMSPqa\npI684zOqs3cjAIB5Tioz1eh3vO64QauuwlY+Rr5Qde4Pwh2Sxj2HxyXtrLd3IwCAeRpiKq+R0GQV\nAAAU1AiNSxsJ4Quh44cUAIBghC+EKuythAhyAIBmQ/hCqIZGnBPyL8wc6+uJrfGcVzRUsSckgGbF\nG8vWRvhCqIZGHEeZJnz5bF9PLOaeU1KoKjXIAUAj4Y1lsGwoXTUzunpT8mknYSdjxg2nid7+pnlu\naDWBgpLDg/PenRX5AShlSXKhhn3ex26Y3jIAUIZSfwfWVFSjc9m/M1Zavd0s1um2d5jVsz9Tm9Jx\n95RuSXuTw4NqlgBGqwkEcn8g5m0p4R4PErgkeWjE2TM04qTkH86k+aEqaE/IuuwtAwAlqvs3llFt\nKeT9O2Mk02UnzOWzx9SmdP6p9dpRvyKMfKGQst+dffjsw0qpbTKuVNeUWazjHdeNv9Kx/l5J2yTd\nXewLDo04O/p6YvvcH/ClPqdMi94yABpb6E1L/Uap3JsqHbmKanRu3tfxq1tx1U04XSjCFwop691Z\n9h1Mm1JdktRlJ3Rd8kDXhelfbHuu64aiwUuZn7nsD/ZuSe0+55xr9ZoIAA1vQP41XxW9sfSpIetW\nZlcRo/O/R7MjV9m7FQtlVR2d85S0BM2E+GmaWQ+mHVFIubvD+75TWpk6dVcZX3N13sd8hTbpBoC6\nV4X9B/1+93Zo/hvYLkn3qbTpxHJ//5csr6TFl89SwKbqqM/IFwop992Zb2DqtBMFRpHnyb4ta6i9\nxACgHCHvP1jOaNQKn2N+04mhjs7l8QuLc9KK27FFV+qS1CusdkTrSfT270sOD0qlr3b0DUxTZnE5\nXzY7GlvNH3wAaCZBb1bLkRPg3NpbqTqrHQuFxbG40gOb3ndD0wQtP4QvFOQGrVJ/COYFprTi9mhi\nazkjXyelqv/gA0Az8XuzGmRc/qNfJwNaS6wJ6yK9X0sBPRwTvf3V+Hp1hyarCFV+X7CxRev2P9d1\nw06V9kvBSrqNgAUA5ckLTo6kuM9p45Lulf+swsOS8n9XV6Xxq6fma97XaqapxUIIX6i6En8pSJ4u\n+ACAyhTroB/QlmJu5eGqmVFtTB5Up51Q0nSlO+3k7WGHogoaeDcVwhdCVewHyv2hf0T+rVzYNggA\nQlBud/rs1nCrZka1ZepAfpPTlhqVigLhC6EpdSh5aMTZI+ku5QYw9jUDgBrJ7qW7/c3H1GUn/E5p\nmXqsKDDFgzAV6og8p68ndo+k2xRejxsAwMIMSJrs9A9eUhN1l68HrHZEmEruiBxyjxsAQImCpiSH\nRhwlTdfXO+2kX10uPRZDxMgXwlS1jsgAgIUL2DD7kaERZ09fT2xfp528XZkyEC96LIaM8IUwDajK\nP7RDI86OoRHnxNCI47gf87fEAAAE8ysPMZLuGhpxdrj1ufO2PqLYPlwU3CNU1Vw+7Aath5W7X9mM\npJ3UiwFoNeWuaHTv48h/tbnEivPIMPKFUCV6+/e5K2Jucw89khwePOGGsoW6T/M3im13jwNAywiY\nPvTbIDtfoTIQiuojQvhC6PJ2rJ/7pRBCAPPbEqPQcQBoViWtLvcxoMx0oh/qcyNC+EI1VPpLAQBQ\nmpJXl3u505IPan4Ao6g+QrSaQDVU9EuhBEEbwo4v8HEBoNEEbU4dOHqVVyP2unv4IpVYL4bwMPKF\naqhWy4l7JU3nHZt2jwNAKylrdblPjdgKZWYkbuvria0heEWL8IVqqErLCfeXwx3KXQJ9B780ALQa\n9/fevJYQBX4fUg5SR2g1gapo9R3rAVRfJa0WWlWBFhO2ryfGQEzECF8AgIbjmUbzjuZMin1ifWU3\nzva5id5eNUDaBQA0IqbRylP1HUhQOlY7AgAaUbVWVUtqvinN7MbZaqLvqZEx7QgAaDjVnEZjShPV\nxsgXGkqzvRsFULEB+QekMKbRCk1pVvT7hkVI8GLkCw2Dd6MAvKr1ZiyMlYHea7ts+vjr1yafWhqT\n9e5NOylpFwGsNTHyhUYS+rtRAI3LDVrV+Nkvu3u8V/4bxfXTz66Izd9Okd9dLYzVjmgkVS2wBQDX\nQlcG5rxR7LQTQefxu6tFEb7QSKq1bREAzKmge3y+nFA1ZRYHncfvrhZF+EIjoU8NgEaQE6qOJrYq\npXj+OfzuamGELzSMEN6NAkBRPptQd0va6x4vRc4bxVPta/VcYtt0Sm3j8vzuoti+dbHaEQ2JlhMA\nqiWMHmL8jkIhhC80HPeX2sOSvMu2ZyTt5JcbgFIFBSQ2oUa18SJCI7pPucFL7uf31eBaADSgIlOL\nLO5BVRG+0IhWlHkcAPIV6hvI4h5UFU1WAQANIeQtegL7BrIJNaqN8IVGNC7/Ua7xqC8EQDTc4OXd\nXqw7rfgjx77/5LYN77vxngoesmAX+yp2zweYdkRD+qY0b6+OaUn31uBaAERj3jRhXGmzMnXqrjJa\nQHgxtYiaYeQLdS9vRdLrkpZo/kqkmaivC0CkfKcJO+2EUQV7JDK1iFqi1QTqWv4GtUVMiqarQFNK\nDg+ekM804aRZrCeW3hJ5Cwj6eGEhmHZEvfNbkRQku1IJQPMZSCueM1qQUlxHE1uliFtAhNABHy2O\naUfURBmrloJWJAUp93wADSDR27/v2Pef3LYydequTjthpsxiHU1s1an2tbWo0yrUpoLRLxRF+ELk\n/FYtSdqbHB6UTwALWpEUhCaIQJPa8L4b7xkacZ5SSNN9C5g6DGxTUcl1oPUQvlAL5bxrHND8mq8Z\nZVY3Lsk7d/KGc985lhx+IyUpLikt6aFEb38ly9AB1KGwWkD41JNmpw5VQgAr2KYCKIaaL9RCye8a\n3V+CuySNKdNeYkyZPRyXSrrVe/yGc9/54YXOGzcpE7zkfrw7OTy4J+TrB9D4Cr0JLIY2FVgQVjsi\nckGrliSNJXr71yzgcbMjXvnSid5+RnmBErTKKr6Fbp7dKs8TqoM/SKgFv6nEMN41+gWvQscBeCxw\nKq7RLGjqkA74WAimHRE5t6g+fypx1wL2aMtKl3J8aMTZMTTinBgacRz3I8vDgYyFTMU1GqYOUTOM\nfKEm3KCVE7ZC2DT3IUl3BxyX1HLv7IFyVXUVXz1N1dHhHrVEzRfqgk/7CcntWF9OAHOL6+9UwGrH\noRHnhALqzfp6YmvKv3KgcRQLP9X8+QjYrYJdKdCSGPlCvQilaaEbtAq1lqA/D1pSiaO+odZj5oU9\nR/PrLytqTBrCKDlQU9R8oV5EFYqCimnpz4NmV7SeK6C1S0UjUz5b8AQtfCnrZ9wzSp6ztY97HGgI\njHyhXkTVtLBaKy2BelfSG5ygVXwV1GuVui9ruT/jbO2DhsfIF+pFJCuPwnxnD1RLlVbkVjzqW+FG\n0qWMaJX8M54cHtxRoEdgqV8PqAuMfKEuJHr79yWHB6UQ6ziC3qnTnwf1yn3N3idphedwWCtyFzLq\nW8loU9BodlqZN/4lry4MWJDj9/WAhsBqRzQlVlah0QS8Zr0KrjgspQg9+4Zk1czo6k3Jp52EnYyZ\nEt7oVNINPsyfwSIjXnOPS9E9GgXTjmhWrdQsEs2hWI1U4LRaqUXofT2xfR8++/DA1qknpzrtZNyU\nXrBe9pRlyFP8haYUw2rSDESGaUc0K1pKoNEUe20WmlYrZ1qwkinEiqYsQ5ziD5rCXNB+sECtMPKF\nZkVLCTSaQq/NYkGn5DcbtoI3JnWwUIWtgNBUGPlCs6KlBBqN32tWksYl3Vsk6JTUqmVoxNmx3SxW\nl50IeoxAtVyoUo0FOUAtEb7QlNi3DY1mga/ZUt9s7D6a2Gq2TB1Qm2e/+ZTienXRFfs3LOQbqDK/\n/WCBRsVqRwBoAiWudnQkmVUzo9qYPKhOO6Eps1hHE1t1qn0tq4GBiBC+AKBFFNg4O4sN5oEIMO2I\nhuSzYW9ZTRuBFhVUV5bFamAgAox8oeEUaUbJ1AmaRilTieVyf36+Lv+Nrhn5AiJAqwk0okLNKGmk\niqZQauPUcrlvTG4XrRuAmmHaEY2o2NTI6mqMGAARq6QZaklYDQzUFtOOaDjFioYvmz4+fl3yQJd8\n9pQjgKFRJIcHA/dTTPT2hzZrkRwe3CPpTmWmIdOSHkr09t8T1uMDmI+RLzSiQkXDk5uTP5LPbV0p\ntd03NOLcJ2mF53gpDSyBWiipcepCuMHrbs+huKS7k8ODIoAB1UPNFxqOz1YnaXm2PGlT6iK/+8WV\nWqHc4CX384fdImSg5pLDgzuSw4MnlJkOzJ+aCLsu684yjwMIASNfaEjerU7y6rt2S3pL0pL8+8yo\nPejh2hVCHQ1aR16rk9DqpTxF9t6R22wAq0btot+Kx0LHAYSA8IWG5vPHKrAWLCan0EPR3wgl8Wl1\n0i1p79CIoxACmF+RvZE0lujtX7PAx/aTln/QSvscAxASwhcaQoHVi4XaTuRoU0qrZkZ1qn2t382h\n1dGgefi97rRs525JXXlb9HQd77juPumqhYYv3zcBtnpvDh5Sbs2X9ziAKmG1I+pewFTMpDJ1X4/I\nf0WYr0mzWE8svSX/8IyknX6jFrSsaF1Br7uDnTd2SvLdnLpN6VuDXh+lTFW6tV7zRm8nzWL7xNJb\nbqvGwhBWOwLRI3yh7gX9QVKmwF4Bt/mykvYv2+k9FLjasVDoI4A1v6DX3ZTpSluZeJed8Lub7/Rg\nwK4M83ZjSA4P7kgr/khc6bk3FCnFdajzep1qX0v3eaBJMO2IRhA05bJa0m0qY/TLlLd9StWaXKIh\n+L7uEnay0CrxoNdqSa+lRG//vgNPvviIZzpTRxNbs1Pl1CUCTYLwhUbg2+8opbbXv7vs47uvnnxK\nl88eKyV9lbtMv1DoQ/Pzfd0Z6WRKbYvbMq1L/O7jp+TX0qn2tSdPta+tan8vALVFny80ggHl7UPn\nyMw8l3jvEkndz3dtM8903jivIVKeMZU/XRj0x44/gq1h3uvO/XygTal7g24LeKxyXkuBXzf4UgE0\nEsIX6p4bmLxNVceeS2x789WOKzuy55xqX6spszjoIcbdj48khwdPlLExMX8EW5jf605ugC90W8DD\nlfxa8mkiPKa82rByZRu3JocHnTJ/BgBUAQX3aEhDI868fe9WzYwqfwWapGn3PG+H1ZKL5sNe7cjq\nyeZSTrPVajVmLYaFI0D9IXyhIQVtru1uqj2h83/gFmv+lkJS9ZpWBuKPYO1UI/iUuoKx1gqtFo76\nZwBABgX3aFR+m2tPvtKx/t6e37zKu3Q/qK29bwF0lUcnWD1ZA2F3pPe8RvwCTT3+e7JwBKgzhC80\npL6e2L6hEUcqHpR8V6zJp9C5ytvGSPwRrJoioTm00Hvs+0/u2Z46dVennTB5bSC86u3fs+SfAQDR\nIHyhYXk31y5gQNLD8tR8pRXTs503dJ8acc4ot8FqtUem+CNYBSWE5lBCb3J4cMc7FL8r2wC1y05o\ny9QBScoPYPX27+k7SiwWjgA1w2pHNLzk8OCe5PBgKjk8aN2Pe/JOsQGfrpD0NfePt1T9kSlWT1ZH\nodAshdcyZLe387wktSmtjcmD3kN19+9ZwcpMAFXGyBcamhu0vBsDxyXdnRwelLs/3W5JHco5wWpj\n8mB2tKJD50e2qjoylejt35ccHpRY7Riowpq7YqE5rJEf36/TeX6boTFFtIKxXO5rrO6uC2hVhC/U\nTEhtF+4scPweFf+DKYX/RzoQfwSDlVNz533tvN90OUcS74771F6dlMqqDyzGN5xPmcVWUlU2vQbQ\nnAhfqAmftgvdkva6I1Yl/RFzHyMecHP2eNAfTO+nztCIsyPEP9KoTEk1d/mvnU47GfepvcoJzSXW\nBxYzL5ynFbdn2lY9yGsEQDkIX6iVBRW3e/4AB8l2Wp33BzOluI4mtnrPjSt3hCW0P6TJ4cEdKbXd\nF1dqxZRZrOMd142/0rH+Xv5Y+yq15m7ea6dNaW1KPp0+1b42piqFZr9p47jSAxvedyP/lgDKQpNV\n1ITbf8tvL2yb6O0vuhCkQONIWUlpGcVllVbbeJtS35R0s5VWJ02XPZJ4d8w7RbVqZlQbkwfVaSdk\n3LqdMOqwksODOxyZh2OycystU4rrucS26Vc7rryDAJYrqHGupLG+ntia7CcLfe0AQK3xiwq1stAV\naIErEI2kNln3Y2qFzRTkrzbSyU47+fFT7Wvn3nFktyTqygQv6fz0Zxh73+32Bi8pM0Jz1fQz2SL/\nhjI04uwYGnFODI04jvuxoueowOOUuho01A3Pw/q+AKBUhC/UykLbLpT8h9ac/9At6dHes4/aVTOj\nkqSNyYP5e0FKuW0KFqJQsX+9NeL05Q0mkh5R5jnMPpd7yw0qnqJ67+M8OpTpuSaVtqF0aC07Aq6n\n7O8LAMpBzRdqIoS2C/uV22KiZO2aiWULtPNWPXpVHI48K/H8psayxf711ohznoC9C70K1uj5tY2Q\nf62f5PZck3SHd4rRT8gtO9jyCUDkqPlCQypU81UqK8nKKJbfgzWjok2HAzbPntNINV8FarC8bF9P\nbN4IekBwswoIpB7nJL2hiFabuiN6vvVjft8XAISBkS80qgVP2xlJRtYvESykt5fvyI5VZsTreMd1\n4692XFn3qx3d8FRKuA0awfN7HnyDl3fBw5RZvORoYusSd0FERXtrltk/ji2fAESO8IVG5Si4x1dZ\njCRHRkbWGp8/1mX+MfcNhUayy2/6aKxHUk8YF11FnlGrYgqF1JLCcXbBQ7buzme/xLKmACvoH8e+\nhwAix7A6GlWor10jq/3Ldp5M9Pav8Qle8wqyC6yGDHUlXo0E1WVJ2dna4GL4rJK+X78FDz77JZYz\nyllsn8cc7vWXUuQPAKFh5AuNKmi6qGLb33yse+QH153Ja4JabkF2w46keArkCz2vpW6j4/c8zBO0\n4CHv+OslfL2ssjdHD7uxLgAUw8gX6k5yeHBHcnjwRHJ40HE/+o0yDUhKFXusdFA5fR4jd8oreWDF\nTWcffeTY95/c495U1h9zd9Rs3khKvW+ePTTi7NH5VhJBxkodEfIZUcr/Z5iU9EDSdM3r8yHN2/5p\nSRmtH5ph5BFAk2PkC3WljJqdbSry+nVk9GznDXrX1JMlf30jqUMz5h2zL92VHH7xKZVYkB3SJuE1\n4Qabu1R4JeKMAkbvgr5374iSX9uJvp7YvuTw5FMqvv1TtiltpSNuDTHyCKB10GoCdaVAC4mc1g/J\n4cGUChTcpxTXoc7rdap9rba/+Zi6gvt5FTIu6V75/zGfG83yay/hyMw8l9j25isd6y+ST8uEoDBS\nykWFHfRKbCkx3tcTWxlwLQWfn2K838+kWWyOJrZ6N8jOKrn1QyMHYQCtgfCFulLqvn3J4UHfF262\npUN25GRz8kdqt9NSwIOW4Fb3Y+Af86DAOGkW64mlt8x9KreQO6AH1tzthS4mjLCTr0CvqzmrZkbt\npuTTTsJOxpOmK/2Ltksf2vC+G+8pNSyXcS2Bj1es+SoANAqmHVFvSu27lJbPyJeV0RNLb9GqmVFd\nN/VDxeUs9HoeSvT2L5Vnyitbk6bzYazQNkJZXcpso7Nb0mL5F/Fnby80ClaNjuwFFy+47SBMm9Jx\nSeq0k/FLZ1+6+9j3pe4KCtyLYNoQQNOj4B71ptR9+x7Kv6OV9Erb2nOS7Kbk0+lSg1eRsd8l2YJ/\nN3SdkfSocltP+MorGs/qVmYrnSDF9hYsKexkA+LU8KDzy3/6RurAky86QyNOKmDz6P0q8DQEtYN4\nW+rVOxVygTutHwC0AqYdUXdKrdlJDg/ukXSnMiNgaWVGqe5xbys6lVaGMZXYOiHLW3NW6df0m2Yr\nZZrPb2rS53omlQk5yj/XNdf4/+azD/vPA2dOuNXn/guaBgWAZkf4QlMKY+9HD6sy+opZSSfa1s8e\nXnz9ooV8Tb8C86Car7FF6x5+ruuGmyWtfv+b33Q67eS8Kdm8GjQpEyqlIt/XTW/uU4dbN+c1o3Zn\nae/H4xS4A0B5qPlC08gLAa8r0wcs5zVeys7OPgpOL/qdfFnqpbOHdf2E937ePQxntchKxi7STCy7\nQOBU+1rvOSY5rJQypQFzgSbR278vOTwoz/d5cmzRuv3Pdd2wU24gS/gEL8m3oWlpdVkBb9Dimp2Q\n5nqbEbYAoESEL9S1MqYg80eEVkiaSSlu40qHNf1YsjalLurria3MrmxcNTPa5d3DsF2zmX29dX4/\nwwtTP9fq2Z9566uyISqn11l+2Hkus0JwbiRsyiz2ba3hU4OWrcsqGCzbNeN7PC57QaH7AQD8Eb5Q\ntwo1XHV5Q5nfCsJ2I3tuRh0XtGvahJ3A3FE0R/4LV5zk8OCOvt7+fUMjjjYln/56drWgnzaldfns\nsUKjcoVWNOaMYB1NbM3ZrFrybVzqXcSQP42ZM0AYFOZE13gAqAirHVHPgtoq3Kf5m137riCMy1nS\nEWLwyu6T4xSfvIzL3YC7rye2r9NOFv1ZK/aIVuoOWAWZE4JOta/Voc7rNWW60layU6Yrfajzenuq\nfW1aeSsIA1YXPijPitOjia1Kze/qQfsHAKgQBfeoWyGvWAxF9qeljItKS7pdxTesLmpa7fqnZbfO\na8a6kKatQfI78F87+cP93bMv3iyK6gFgwQhfqBs+9V2LVbgnVkNwZGZeaVs7fWnq5SX5/bLKMW06\n9E9Ld0g+bSgWsl0RACBahC/UhYAWCtPKDDK11+SiQjTprmjMrnacUbtictSmVMmjaFbS/mU7tWpm\nVJuST6cTdjJm8kahCGEAUP8IX4ic3wpGBUzLTatdjmnLBo26moIsR3bPyfx2D+V8Q9kAl19ML3eK\n8fFlO6WQpx8BAOEjfCFSBTaG7pRPFsmO9kiy2998zASsuqt7FfYXy7n/M503amPyYNDKwzE3fLEp\nNQDUOVpNIGpBKxh9N8r29KYyAaM+DaGc4JUf1KykX8Qu1qn2tXrX1JNBd/NtmOo2be1ODk84CiiU\np0M9AESLVhOIWlBX9ZjyNtTO702VbaEwaRYX2wy7oeUHNSNpiT0nKXCzbikTmnJaTqyaGdWWqQPZ\nkbJsS45Hk8ODZ7ybhWt+24692dsBAOEjfCFqQY05T8rtN2WVqW/y25j6VPtaPbH0Fu1ftjPbcqsl\nZGvFivTcGpAnwG5MHgwaJVyh8wEraCRydygXDgCYh/CFqOUEBNekzu9duGb/sp23PrH0lsn84JVn\n3khPM8uOeHkaqDpu8kwrUy+3+8NnH5YyATYt+e7l6JUNWEEjkaXt+wgAKBvhC5Fya4nyO6rv8tYY\n+XRdzx/h8o70TPt8mRlJ50K/+BpxZGaOd1w3Lvf5OtW+9tZOO/lxk3ke4vJMF7oBLCYVnKLMytZ4\n+WmZYAsAUWO1I+peod5V7tTZfTrfjDXbFb9h21JkZdtTHO+4bvyVjvX3ettFJIcHTyhgZWN21WO2\n5qvAAoUxZQKsb3sKiu4BoDoIX2gKAS0sGtqkWawnlt4y96k8/boKbL1kH1+28za5z8WqmVFtTv5I\n7XY6/+S5gFXKakeatwJAeAhfaAoFRoIakpX08qINer5rm/fwXL+uQiNfid7+NWHuzViNvSMBoJXR\n5wvNoqkKxI2k1bM/0y9n3u5d8en9HoOmCwekubo5TzC6UdKN91R4OYVWRBK+AKBMFNyj4TVrT6o2\npfWuqSe1/c3HtGpmVPIUwZeycCFErIgEgBAx8oWG41OjtFhNUGDvx0jqshPaMnVAK1Kv7c+MYGW4\nQSuKkaeT8p/iZEUkAFSA8IWG4lNYH1jntdD9FOtJm9LK1GxVPHU4p4LthApOcQIAykPBPepawCjX\nioJ3al420du/oFKBAhubF5yyZLUjAISH8IW6tZD2Ec006uUxlujtX7OQByi2SnIhjw0AKA0F96hn\nfqvsimrktxMFrj2saT6K5wGgxqj5QuTKmMKqKBBkR7wabfSrwPWmFd5KRornAaDGGPlCpDwNO7vl\n2ZPQPZ5vQYGgUYKXVaabfQGxEFtIBG5sHtLjAwCKIHwhaoUaduYLCgrjVbiumkgprmc6b9QTS28p\ntBF2aKNSEfcHAwD4oOAekRoacQL3JOzric17M+DXFsG9qe73ccyfRrSS0jJqkx230oops1hHE1vn\nOtivmhnVdVMHbFxp793Y5BoAmgw1X4haWTVHQY1Ek8ODkvRoqFcWMqPzBfRWRicWrdfzXdvU1xNb\n6bdf4qn2tZMrUq89XOkejACAxsDIFyIV5ibNyeHBPZLuDvHyqiqluH6aeO+59/7mhqUSvbMAoFUR\nvhC5MENH4wWwtvELev9gZa2vAwBQO4QvNLwCjUPrkZV0m8rb3gcA0ERY7YhmMNBAbyFel0+rDXdh\nAQCgBRC+0PAeX7ZTZ8zb0w0QwKbdj6W22gAANCHCF5rB7h8t/Q/xlxdtkCMjK8mRNKs2WdXVdkNx\nSRcF3Mb2PgDQImg1gWawWpKe79qm57Ut/7axG85959iFzhsfUO2b3rcps1VQ3Oc2tvcBgBbByBea\nQVBwGfvw2YcHLnTeuMoIc+0AAAvZSURBVEGe4GU9/9VATGzvAwAtjfCFZlBov8J52xmZvI8ROym2\n9wGAlkarCTSFoN5hyeHBoO2MqmlW0iKf4zOSdhK0AKC1Eb7Q1BbaAyx/f8YSjUu6V9J9klZ4j1US\nvOiEDwDNhfCFpub2z8rZzqicQDWruGZNQp12Qir9fjbR2x84pe+3WXhQKAtzOyYAQH2g5gtNzQ01\nuySNWUmTZrFeXrRBKd8Fh7mspOc6r7dPLL1lbP+ynbca6Vbl1mqNB9w1cOWiJwyW2mR1Xs2a6AsG\nAA2NkS+0jKERJy33DceqmVFtTB5Up50IHM1KK3Zuce/OpUGP5zeqpkxd15vK9POaN6pVYBp0LNHb\nv8bnmoNq1mxfT4w3TwDQgPjljZbgTt+V/Hq3kuJy7ix0jndUzb3LuPtxhYJHtYKaqQYdDxpFoy8Y\nADQowhdaxdw03aqZUW2ZOqCuAqNe0ly4KijR278v0du/xq3xmpDUkXdK/hRhuWGqUBsNAEADInyh\nVayWMsHrnVP/qjalC548q3an0q9R5HhZYcotqp/XF4xiewBoXNR8oSUMjThnVs2MrtgydaBo8HIk\nWZlzcdkLVGQ1olep9VzlrHYEADQfwheajk9frP2S7tr+5mOmy20ZUYhPK4pJldCFPqAAv6T7AgBa\nB9OOaBpDI86OoRHnjKRHldvK4W5JprOE4CX5Li0sqbWDTwE+WwcBAOZh5AtNIaAZaY7tbz6mUka+\nAhRsnAoAQKnaan0BQEjmmpF6e3hNmcU6mtgqSYrb2aLd7QvcXnFrB7YHAgB48U4ezWJuNaO3jUSX\nndC7pp7Uu6aeVIdmigavM+btaUdmJu+mils7eEbkcjrau8cBAC2IkS80lAKjSCcldW9MHpy3mrHU\nfRyNpOX29V/GZO/N/xqJ3v59FY5gFdoeiNEvAGhB1HyhYRTaZNr9/703n324q9SwVcCY8to/VLrB\nNdsDAQDy8csfdcddtXhiaMRx3I/ZKbrAUaRsM9Kk6SrcxKs0ftsCVbrBNdsDAQByEL5QV4rUSBXs\nIN/XE9vXaSdv1/wO8vOkZeQUfvnnB6ty92TMYnsgAEAOwhfqTaERpqKjSI8v26lnE9dPTprFssoU\n0XtZSdNq16HO30i9smjtA8pMMQbxBqvXA84JOi6J7YEAAPNR84W64lcj5WkdYd3WEeZU+1rvKeOS\n7nX/P6cuy6/txKn2tbOS/jAbgErZFsht3rrC55zxvp7Yyoq+WQBASyJ8oa4MjTgn5AlC2dYR3hWM\njmKaVZvaNeMNVJPKTOf5BSRdPfmU1swek1FOsgsMbcrbFmghhfPs5QgA8GLaEfUmp0bKr3VETM5c\nz64uO6EtUwe0ama0SwWC1+WzxxTTvPS0wpH+1v3/YtsCBU15Oj4LA+Z49nvMqWHLK+YHALQQ+nyh\nrvT1xPYNjTiSO1LUaSeKdo5oU1obkweVNxU5Z83s8cBeXzGpbcZ0PDS8dMcbKty/a0D+2xfF3Y/Z\nhQHKuy99vgAAOZh2RF0rUI+VI1Ncb2RkvVORkqSbzz5ctLP9/mU7vYd8+3flNVl1dD54eY319cTW\neK4/cLqSvSIBoDXxyx/1zq9VwzxGUkw2fypSktyjwabM4vxDvv27+npi+/p6YmvcGq+gn525FZLJ\n4cE9Cm6wT58vAGhRhC/UNbfuyluPVZLsVKQknVi0PvCOaZm5jbfzFOvfVUrz1E8UuD99vgCgRRG+\nUPcSvf37Er39a9xpukJ9uXJ02glJ0vNd2/Tyog1ypLneX1aZecOxRettQK1YsZGpUpqnBv58sdoR\nAFoX4QuNpqRpSOn8dOKqmVFdnPr3ufm/bLuJmKQ1sy+mL53+2XTeXYt2oKd5KgCgUhTco+Hk9c3y\nramykp7pvFGS5vUJy5dS2/h3l318QoVXO1ZynW9KWuJz07lEb//ShT4+AKAxEb7Q0Nyi9rvkCWHZ\nV/SUWay4nVWHZoo9TFVWHroh8W81v6XLuKR7mXoEgNZE+EJDGhpxdlw2ffy+9dPPrnBruxyTmUm0\nygtiRRuFebYRCkPeyNzrki6QlPA51YqO9wDQcqj5QsMZGnF2XDr9s69tTo6s6LIT2RqumPs2Iidr\nlRC8itZ3lcOno/0K+QcviY73ANCS6HCPupe/N+JliesXr59+tiO/jquEoJWVHe6txqiTX0f7Yuh4\nDwAthPCFuuYZScoGmu7NyRHFCxTQ+xiXlFNQX8VpvmL9wcK+HwCgwRC+UBfyR7d0PiDNG0lqU1qO\nu5WQj/wyLyvpImXC120R1FadVAnbIfkwyeHBPYne/nvCviAAQH2h5gs151Mn5a2D8h0RMrJK5W2t\n6MjMSHpQ53tvZYNYlLVVJfch83FnmBcCAKhPhC/UA786qWwdlG+n+bTaxg8nesYnzWJZZXp1xWR3\nJnr773FXLp7U/DIw3z0bw+SzHdKYpAdU2vZIfht1AwCaDNOOqDkrrQ4oll8t6Tbl1nwppbgOJ35d\nr3Ssv7fnN6/ynUYs8phV5Qaw/Ou6R5ob5Xs04K5lFbIBABoTI1+oqaERZ0d2GyAfJ7MjSSm1jVtJ\nk2axDnVer1c61q+QtHdoxJk3jVjsMUO58Aq5388DATc/FOW1AABqg/CFWtt9NLHV5NdvpRW3cvtv\nJXr793132ccn9i/bqSeW3iLPRthB04hFH7OW3KL6B3R+pCst6QGK7QGgNdDhHjU1NOI4ksyqmVFt\nTB5Up53QlFmso4mt9vob18Xyz/N5CNvXE8t5E1HqYwIAUAvUfKHWTkrqPtW+1juilT0+77yA+1f6\nmAAARI5RANSaX2sGvy1/Sj2v3HMBAIgU046oCbdQ3rv5tJRphnpS0kBfT2zeKsa8+wSeV+65AABE\nifCFyLnBKKd9hDIjU7sISACAZse0I2qhUFNVAACaGuELtRDU6JTNpQEATY/VjqiKIjVX5axcBACg\nqTDyhdB5arpyNsr2dKNnNSIAoGURvlANBWu63BGw/M2nKbYHALQEVjsidOV0owcAoNXwhxDVEFS7\nRU0XAKDlUXCPahiQfx8v35ouGqICAFoJ046oCr9A5d7kd4yGqwCAlkH4QiSGRpw9ku5Sbi3YpPvf\nCp+7jPX1xNZEcGkAAESKaUdUTd7ol18Bfpfmr4rMouEqAKApEb5QFQH7N5aD4nwAQFNitSOqxa/X\nV6louAoAaFqEL1RLudOGadFwFQDQAph2RLUE7d8YJEYDVgBAK+CPHaplQJmRrFKZoRHnhGf/RwAA\nmhKtJlA1BbYZKoQeXwCApsbIF6qpkhWLcxtwAwDQjAhfqKZKVyzS4wsA0LQIX6gad+qwknltenwB\nAJoW4QvVVixI5YczenwBAJoa4QvVVmjV47ik25Tp7UWPLwBAS2C1I6quwKbaBC0AQMth5AtV19cT\nu0eMcAEAIIkO96gSt1nqbmVWLp6UNNDXE1tT04sCAKAOMO2I0LnBa69yN9ZmmhEAABG+UAVDI84J\n+e/rmFZmqjs7EkYQAwC0HMIXQpE3zVjKlkKMhAEAWhIF91gwzzRjt0rfy5FthAAALYnwhTDsVm59\nV6nYRggA0HIIXwhDpSGKbYQAAC2H8IUwVBKi2EYIANCSCF8Iw4AyYaoYK5qsAgBaHKsdEQqfpqrL\nJS3xOXWMZqsAgFZG+EJVDI04jvxXPtq+nhgjrgCAlsUfQVRLUB0YRfYAgJZG+EK1+NWBUWQPAGh5\nhC9UhVtMv0uZ4nqK7AEAcFHzBQAAECFGvgAAACJE+AIAAIgQ4QsAACBChC8AAIAIEb4AAAAiRPgC\nAACIEOELAAAgQoQvAACACP3/7daxAAAAAMAgf+tZ7CqK5AsAYCRfAAAj+QIAGMkXAMBIvgAARvIF\nADCSLwCAkXwBAIzkCwBgJF8AACP5AgAYyRcAwEi+AABG8gUAMJIvAICRfAEAjOQLAGAkXwAAI/kC\nABjJFwDASL4AAEbyBQAwki8AgJF8AQCM5AsAYCRfAAAj+QIAGMkXAMBIvgAARvIFADCSLwCAkXwB\nAIzkCwBgJF8AACP5AgAYyRcAwEi+AABG8gUAMJIvAIBRCWVqPWXktGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ef49320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "ax.axis('off')\n",
    "pallet = seaborn.color_palette(palette='coolwarm', n_colors = 2)\n",
    "\n",
    "#Plot Obama\n",
    "a = np.stack(train_data_df[train_data_df['category']]['pca'])\n",
    "ax.scatter(a[:,0], a[:, 1], c = pallet[0], label = \"True\")\n",
    "\n",
    "#Plot not Obama\n",
    "a = np.stack(train_data_df[train_data_df['category'].eq(False)]['pca'])\n",
    "ax.scatter(a[:,0], a[:, 1], c = pallet[1], label = \"False\")\n",
    "    \n",
    "ax.legend(loc = 'upper right', title = 'Is Obama')\n",
    "plt.title('True Classes, Training Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA cannot distinguish Obama very well. Let's perform a screeplot to see how many Principal Components we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAFNCAYAAADPZwa0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ef7ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(train_data_df)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize = (16, 5), sharey=True)\n",
    "\n",
    "eigen_vals = np.arange(n) + 1\n",
    "ax1.plot(eigen_vals, pca.explained_variance_ratio_, 'ro-', linewidth=1)\n",
    "ax1.set_title('Scree Plot (Full)')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "eigen_vals = np.arange(50) + 1\n",
    "ax2.plot(eigen_vals, pca.explained_variance_ratio_[:50], 'ro-', linewidth=1)\n",
    "ax2.set_title('Scree Plot (First 50 Principal Components)')\n",
    "ax2.set_xlabel('Principal Component')\n",
    "ax2.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "\n",
    "eigen_vals = np.arange(20) + 1\n",
    "ax3.plot(eigen_vals, pca.explained_variance_ratio_[:20], 'ro-', linewidth=2)\n",
    "ax3.set_title('Scree Plot (First 50 Principal Components)')\n",
    "ax3.set_xlabel('Principal Component')\n",
    "ax3.set_ylabel('Proportion of Explained Variance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose the first 10 pricipal components as our covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_df['pca_reduced_10'] = train_data_df['pca'].apply(lambda x: x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit a logistic regression to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression()\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_10'], axis=0), train_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the logistic regression performs on the training dataset from which we develop the model. Unfortunately, the mean accuracy is only about 64%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6710526315789473"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.score(np.stack(train_data_df['pca_reduced_10'], axis=0), train_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does it perform on the testing dataset, which we \"held out\" and did not use for model training? We need to repeat all the steps on the testing data, but without retraining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6656891495601173"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create vectors\n",
    "TFVects_test = TFVectorizer.transform(test_data_df['text'])\n",
    "test_data_df['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#PCA\n",
    "reduced_data_test = pca.transform(np.stack(test_data_df['vect'], axis=0))\n",
    "test_data_df['pca'] = [r for r in reduced_data_test]\n",
    "test_data_df['pca_reduced_10'] = test_data_df['pca'].apply(lambda x: x[:10])\n",
    "\n",
    "#Test\n",
    "logistic.score(np.stack(test_data_df['pca_reduced_10'], axis=0), test_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly poorer. How about using more dimensions (40)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.7404970760233918\n",
      "Testing:\n",
      "0.6979472140762464\n"
     ]
    }
   ],
   "source": [
    "train_data_df['pca_reduced_40'] = train_data_df['pca'].apply(lambda x: x[:40])\n",
    "test_data_df['pca_reduced_40'] = test_data_df['pca'].apply(lambda x: x[:40])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_40'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_40'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_40'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or still more (100)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.8289473684210527\n",
      "Testing:\n",
      "0.7624633431085044\n"
     ]
    }
   ],
   "source": [
    "train_data_df['pca_reduced_100'] = train_data_df['pca'].apply(lambda x: x[:100])\n",
    "test_data_df['pca_reduced_100'] = test_data_df['pca'].apply(lambda x: x[:100])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_100'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_100'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_100'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even more (200)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.8786549707602339\n",
      "Testing:\n",
      "0.782991202346041\n"
     ]
    }
   ],
   "source": [
    "train_data_df['pca_reduced_200'] = train_data_df['pca'].apply(lambda x: x[:200])\n",
    "test_data_df['pca_reduced_200'] = test_data_df['pca'].apply(lambda x: x[:200])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_200'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_200'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_200'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is becoming ridiculous (400)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.9093567251461988\n",
      "Testing:\n",
      "0.8240469208211144\n"
     ]
    }
   ],
   "source": [
    "train_data_df['pca_reduced_400'] = train_data_df['pca'].apply(lambda x: x[:400])\n",
    "test_data_df['pca_reduced_400'] = test_data_df['pca'].apply(lambda x: x[:400])\n",
    "\n",
    "logistic.fit(np.stack(train_data_df['pca_reduced_400'], axis=0), train_data_df['category'])\n",
    "\n",
    "print(\"Training:\")\n",
    "print(logistic.score(np.stack(train_data_df['pca_reduced_400'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(logistic.score(np.stack(test_data_df['pca_reduced_400'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of covariates would overfit our data, and it seems that using a logistic regression, our prediction accuracy is at best about 65%. We can, however, try a logistic regression that uses the TF-IDF scores for each word, but with an L1 regularization or L1-norm loss function, which is also known as least absolute deviations (LAD), least absolute errors (LAE) or L1 penalty. It minimizes the sum of the absolute differences (S) between the target value ($Y_i$) and the estimated values ($f(x_i)$) and prunes all insignificant variables (i.e., word TF-IDF scores):\n",
    "\n",
    "$S=\\sum^n_{i=1}|y_i=f(x_i)|$\n",
    "\n",
    "The result is a model retaining only the most individually significant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8165204678362573\n"
     ]
    }
   ],
   "source": [
    "logistic_l1= sklearn.linear_model.LogisticRegression(penalty='l1')\n",
    "logistic_l1.fit(np.stack(train_data_df['vect'], axis=0), train_data_df['category'])\n",
    "print(logistic_l1.score(np.stack(train_data_df['vect'], axis=0), train_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using training data, and then test it on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7653958944281525\n"
     ]
    }
   ],
   "source": [
    "print(logistic_l1.score(np.stack(test_data_df['vect'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "81% accuracy seems like the best we can get by using a logistic regression.\n",
    "\n",
    "Now let's try with Naive Bayes. Classically, it is trained with word counts, but TF-IDF vectors are also quite good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveBayes = sklearn.naive_bayes.BernoulliNB()\n",
    "naiveBayes.fit(np.stack(train_data_df['vect'], axis=0), train_data_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "0.9576023391812866\n",
      "Testing:\n",
      "0.8621700879765396\n"
     ]
    }
   ],
   "source": [
    "print(\"Training:\")\n",
    "print(naiveBayes.score(np.stack(train_data_df['vect'], axis=0), train_data_df['category']))\n",
    "print(\"Testing:\")\n",
    "print(naiveBayes.score(np.stack(test_data_df['vect'], axis=0), test_data_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit better than the logit, but that's just looking at the accuracy. What about other measures? Let's first save the predictions in the dataframe to save use rerunning the model every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_df['nb_predict'] = naiveBayes.predict(np.stack(test_data_df['vect'], axis=0))\n",
    "test_data_df['nb_predict_prob_true'] = naiveBayes.predict_proba(np.stack(test_data_df['vect'], axis=0))[:,0] #other is prop false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194444444444444"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_score(test_data_df['nb_predict'], test_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8489208633093526"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.recall_score(test_data_df['nb_predict'], test_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8339222614840989"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.f1_score(test_data_df['nb_predict'], test_data_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how well our posterior distribution looks relative to the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103219cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.grid(False)\n",
    "ax.set_frame_on(False)\n",
    "test_data_df[test_data_df['category'].eq(True)]['nb_predict_prob_true'].hist(alpha = 0.5, ax = ax, bins = 10, label = 'True', color = 'red')\n",
    "test_data_df[test_data_df['category'].eq(False)]['nb_predict_prob_true'].hist(alpha = 0.5, ax = ax, bins = 10, label = 'False', color = 'blue')\n",
    "ax.set_xlim((0,1.1))\n",
    "ax.legend(title = \"Is Obama\")\n",
    "ax.set_xlabel('posterior')\n",
    "ax.set_ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification is suprisingly accurate. We can even look at what words are most influential with a bit of simple math:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clinton</th>\n",
       "      <th>Clinton_log_prob</th>\n",
       "      <th>Obama</th>\n",
       "      <th>Obama_log_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dick</td>\n",
       "      <td>-1.786482</td>\n",
       "      <td>signature</td>\n",
       "      <td>-2.179983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amy</td>\n",
       "      <td>-1.851723</td>\n",
       "      <td>welcomed</td>\n",
       "      <td>-2.260025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brundage</td>\n",
       "      <td>-1.933640</td>\n",
       "      <td>awarded</td>\n",
       "      <td>-2.308816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>monday</td>\n",
       "      <td>-1.933640</td>\n",
       "      <td>fy</td>\n",
       "      <td>-2.334133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicago</td>\n",
       "      <td>-1.996554</td>\n",
       "      <td>urging</td>\n",
       "      <td>-2.360109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>temporary</td>\n",
       "      <td>-2.181476</td>\n",
       "      <td>class</td>\n",
       "      <td>-2.400383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>political</td>\n",
       "      <td>-2.229485</td>\n",
       "      <td>urban</td>\n",
       "      <td>-2.400383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quickly</td>\n",
       "      <td>-2.279916</td>\n",
       "      <td>urged</td>\n",
       "      <td>-2.428162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reform</td>\n",
       "      <td>-2.279916</td>\n",
       "      <td>encourage</td>\n",
       "      <td>-2.456736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>location</td>\n",
       "      <td>-2.297308</td>\n",
       "      <td>point</td>\n",
       "      <td>-2.456736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cases</td>\n",
       "      <td>-2.351375</td>\n",
       "      <td>bills</td>\n",
       "      <td>-2.471335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>practices</td>\n",
       "      <td>-2.351375</td>\n",
       "      <td>environment</td>\n",
       "      <td>-2.471335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>reported</td>\n",
       "      <td>-2.351375</td>\n",
       "      <td>floor</td>\n",
       "      <td>-2.471335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>va</td>\n",
       "      <td>-2.351375</td>\n",
       "      <td>ground</td>\n",
       "      <td>-2.471335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>writing</td>\n",
       "      <td>-2.351375</td>\n",
       "      <td>read</td>\n",
       "      <td>-2.486150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Clinton  Clinton_log_prob        Obama  Obama_log_prob\n",
       "0        dick         -1.786482    signature       -2.179983\n",
       "1         amy         -1.851723     welcomed       -2.260025\n",
       "2    brundage         -1.933640      awarded       -2.308816\n",
       "3      monday         -1.933640           fy       -2.334133\n",
       "4     chicago         -1.996554       urging       -2.360109\n",
       "5   temporary         -2.181476        class       -2.400383\n",
       "6   political         -2.229485        urban       -2.400383\n",
       "7     quickly         -2.279916        urged       -2.428162\n",
       "8      reform         -2.279916    encourage       -2.456736\n",
       "9    location         -2.297308        point       -2.456736\n",
       "10      cases         -2.351375        bills       -2.471335\n",
       "11  practices         -2.351375  environment       -2.471335\n",
       "12   reported         -2.351375        floor       -2.471335\n",
       "13         va         -2.351375       ground       -2.471335\n",
       "14    writing         -2.351375         read       -2.486150"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top indices\n",
    "trueVals, falseVals = naiveBayes.feature_log_prob_\n",
    "\n",
    "words_dict = {\n",
    "    'Obama' : [],\n",
    "    'Obama_log_prob' : [],\n",
    "    'Clinton' : [],\n",
    "    'Clinton_log_prob' : [],\n",
    "}\n",
    "\n",
    "for i, prob in sorted(enumerate(trueVals), key = lambda x:x[1], reverse=True)[:15]:\n",
    "    words_dict['Obama'].append(TFVectorizer.get_feature_names()[i])\n",
    "    words_dict['Obama_log_prob'].append(prob)\n",
    "\n",
    "for i, prob in sorted(enumerate(falseVals), key = lambda x:x[1], reverse=True)[:15]:\n",
    "    words_dict['Clinton'].append(TFVectorizer.get_feature_names()[i])\n",
    "    words_dict['Clinton_log_prob'].append(prob)\n",
    "    \n",
    "pandas.DataFrame(words_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to classify our text into one of *many* classes? The multinomial Naive Bayes generating model assumes that document features (e.g., words) are generated by draws from a multinomial distribution (recall this gives the probability to observe a particular pattern of counts across features). \n",
    "\n",
    "Let's use again the dataset we used in week 3, the 20 newsgroup dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newsgroups = sklearn.datasets.fetch_20newsgroups(data_home = '../data') #Free data to play with: documents from a newsgroup corpus.\n",
    "newsgroups.target_names #Possible categories, i.e., the newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick specific categories, and pull the relevant training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_categories = ['talk.religion.misc', 'soc.religion.christian', 'sci.space', 'comp.graphics'] #Can change these of course\n",
    "\n",
    "newsgroupsDF = pandas.DataFrame(columns = ['text', 'category', 'source_file'])\n",
    "for category in target_categories:\n",
    "    print(\"Loading data for: {}\".format(category))\n",
    "    ng = sklearn.datasets.fetch_20newsgroups(categories = [category], remove=['headers', 'footers', 'quotes'], data_home = '../data')\n",
    "    newsgroupsDF = newsgroupsDF.append(pandas.DataFrame({'text' : ng.data, 'category' : [category] * len(ng.data), 'source_file' : ng.filenames}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to tokenize, and make a training and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroupsDF['tokenized_text'] = newsgroupsDF['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "newsgroupsDF['normalized_text'] = newsgroupsDF['tokenized_text'].apply(lambda x: lucem_illud.normalizeTokens(x, stopwordLst = lucem_illud.stop_words_basic, stemmer = lucem_illud.stemmer_basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_ng_df, test_ng_df = lucem_illud.trainTestSplit(newsgroupsDF, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(train_ng_df))\n",
    "print(len(test_ng_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract features from the text. We can use built-in feature extraction to do so. We will use a tf-idf vectorizer, which converts the document into a vector of words with tf-idf weights (term-frequency inverse-document frequency). This gives high weight to words that show up a lot in a given document, but rarely across documents in the corpus (more distinctive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFVectorizer_ng = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects_ng = TFVectorizer_ng.fit_transform(train_ng_df['text'])\n",
    "train_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_ng.todense()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MultinomialNB_ng = sklearn.naive_bayes.MultinomialNB()\n",
    "MultinomialNB_ng.fit(np.stack(train_ng_df['vect'], axis = 0), train_ng_df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and save predictions to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ng_df['nb_predict'] = MultinomialNB_ng.predict(np.stack(train_ng_df['vect'], axis=0))\n",
    "print(\"Training score:\")\n",
    "print(MultinomialNB_ng.score(np.stack(train_ng_df['vect'], axis=0), train_ng_df['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ng_df[['category', 'nb_predict']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good, lets examine the testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create vectors\n",
    "TFVects_test = TFVectorizer_ng.transform(test_ng_df['text'])\n",
    "test_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#Add to df\n",
    "test_ng_df['nb_predict'] = MultinomialNB_ng.predict(np.stack(test_ng_df['vect'], axis=0))\n",
    "\n",
    "#Test\n",
    "print(\"Testing score:\")\n",
    "print(MultinomialNB_ng.score(np.stack(test_ng_df['vect'], axis=0), test_ng_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use a confusion matrix, like we used last week for evaluating human coders relative to one another. Now we are evaluating our classifier relative to human coding. We'll just use the one in `lucem_illud`, which requres a classifier and a dataframe with `'vect'` and `'category'` columns, like we have in the examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the precision, recall, and F-measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.precision_score(test_ng_df['nb_predict'], test_ng_df['category'], average = 'weighted')) #precision\n",
    "print(sklearn.metrics.recall_score(test_ng_df['nb_predict'], test_ng_df['category'], average = 'weighted')) #recall\n",
    "print(sklearn.metrics.f1_score(test_ng_df['nb_predict'], test_ng_df['category'], average = 'weighted')) #F-1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate these per catagory. This has the same requiments as `plotConfusionMatrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.metrics.evaluateClassifier(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the ROC curves. This has the same requiments as `plotConfusionMatrix`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotMultiROC(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the PCA space visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(MultinomialNB_ng, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also give the model a new string, not present in our data, and use the *predict* method to see if it can assign it to a category. Using our model to extend its classifications to new, uncoded data might be the primary purpose of a social science application. The words do have to be in the vocabulary, so don't be too creative :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_category(s, model, tfidf): #We just define a simple function here\n",
    "    a = np.zeros((1, len(tfidf.vocabulary_)))\n",
    "    for w in nltk.word_tokenize(s):\n",
    "        try:\n",
    "            a[:,tfidf.vocabulary_[lucem_illud.stemmer_basic.stem(w.lower())]] = 1\n",
    "        except KeyError:\n",
    "            print(\"Warning: '{}' not in vocabulary\".format(w))\n",
    "    return model.predict(a)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_category('rockets are cool', MultinomialNB_ng, TFVectorizer_ng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform Logistic and Na√Øve Bayes classification (binary or multinomial) using training, testing and extrapolation (uncoded) data from texts and hand-classifications associated with your final project (e.g., these could be crowd-sourced codes gathered through Amazon Mechanical Turk last week). Visualize the confusion matrix for training and testing sets. Calculate precision, recall, the F-measure, and AUC, then perform an ROC visualization. How do these classifiers perform? Exrapolate codes from these models to all uncoded data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees can be used to predict both categorical/class labels (i.e., classification) and continuous labels (i.e., regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blobs_df = lucem_illud.multiBlobs(noise=.2, centers=[(0,0), (0,5), (5,0), (-5,0), (0,-5)])\n",
    "df_exampleTree_train, df_exampleTree_test = lucem_illud.trainTestSplit(blobs_df)\n",
    "lucem_illud.plotter(df_exampleTree_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import our Decision Tree classifier from sklearn.tree (familiar syntax) and fit it using the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_tree = sklearn.tree.DecisionTreeClassifier(max_depth=4,random_state=0)\n",
    "clf_tree.fit(np.stack(df_exampleTree_train['vect'], axis =0), df_exampleTree_train['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what's going on visually with the classification: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf_tree, df_exampleTree_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf_tree, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(df_exampleTree_test['category'],clf_tree.predict(np.stack(df_exampleTree_test['vect'], axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we trim the tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depthvec = []\n",
    "scorevec = []\n",
    "for i in range(1,20):\n",
    "    tree2 = sklearn.tree.DecisionTreeClassifier(max_depth=i,random_state=0)\n",
    "    tree2.fit(np.stack(df_exampleTree_train['vect'], axis =0), df_exampleTree_train['category'])\n",
    "    score = sklearn.metrics.accuracy_score(df_exampleTree_test['category'], tree2.predict(np.stack(df_exampleTree_test['vect'], axis = 0)))\n",
    "    depthvec.append(i)\n",
    "    scorevec.append(score)\n",
    "plt.scatter(depthvec,scorevec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select different layers of the decision tree or \"prune\" it. At approximately four layers down in the decision tree, the shape is somewhat odd, suggesting that our model is overfitting beyond those four layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining multiple overfitting estimators turns out to be a key idea in machine learning. This is called **bagging** and is a type of **ensemble** method. The idea is to make many randomized estimators--each can overfit, as decision trees are wont to do--but then to combine them, ultimately producing a better classification. A **random forest** is produced by bagging decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = sklearn.tree.DecisionTreeClassifier(max_depth=10) #Create an instance of our decision tree classifier.\n",
    "\n",
    "bag = sklearn.ensemble.BaggingClassifier(tree, n_estimators=100, max_samples=0.8, random_state=1) #Each tree uses up to 80% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag.fit(np.stack(df_exampleTree_train['vect'], axis =0), df_exampleTree_train['category']) #Fit the bagged classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(bag, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(bag, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(bag, df_exampleTree_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform decision tree and random forest classification (binary, multinomial or continuous) using training, testing and extrapolation (uncoded) data from texts and hand-classifications associated with your final project. As with ***Exercise 2***, these could be crowd-sourced codes gathered through Amazon Mechanical Turk last week. Visualize the classification of data points. Calculate relevant metrics (e.g., precision, recall, the F-measure, and AUC). Now build an ensemble classifier by bagging trees into a random forest. Visualize the result. How do these classifiers perform? What does ensemble learning do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Nearest neighbors classifier takes a simpler premise than those before: Find the closest labeled datapoint in set and \"borrow\" its label.\n",
    "\n",
    "Let's use newsgroup data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newsgroupsDF[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a testing and training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_ng_df, test_ng_df = lucem_illud.trainTestSplit(newsgroupsDF, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize our k-nearest neighbors classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "weights=\"uniform\"\n",
    "clf_knearest = sklearn.neighbors.KNeighborsClassifier(n_neighbors, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to classify using the TF-IDF vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TFVectorizer_ng = sklearn.feature_extraction.text.TfidfVectorizer(max_df=100, min_df=2, stop_words='english', norm='l2')\n",
    "TFVects_ng = TFVectorizer_ng.fit_transform(train_ng_df['text'])\n",
    "train_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_ng.todense()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_knearest.fit(np.stack(train_ng_df['vect'], axis = 0), train_ng_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf_knearest, train_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lets look at the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create vectors\n",
    "TFVects_test = TFVectorizer_ng.transform(test_ng_df['text'])\n",
    "test_ng_df['vect'] = [np.array(v).flatten() for v in TFVects_test.todense()]\n",
    "\n",
    "#Add to df\n",
    "test_ng_df['nb_predict'] = clf_knearest.predict(np.stack(test_ng_df['vect'], axis=0))\n",
    "\n",
    "#Test\n",
    "print(\"Testing score:\")\n",
    "print(clf_knearest.score(np.stack(test_ng_df['vect'], axis=0), test_ng_df['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's produce another confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf_knearest, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can produce the PCA space visual if you want, altough it can take a very long time, so we'll leave it optionally commented out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lucem_illud.plotregions(clf_knearest, test_ng_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform and visualize k-nearest neighbor classification using training, testing and extrapolation (uncoded) data from texts and hand-classifications associated with your final project. Visualize the classification of data points and calculate relevant metrics (e.g., precision, recall, the F-measure, and AUC). Articulate how the *k*-nearest neighbor approach relates to *k*-means clustering explored in ***week 3***?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVMs\n",
    "\n",
    "Now we will examine Support Vector Machines, an approach that creates the partition that preserves the \"maximum margin\" between classes.\n",
    "\n",
    "We will use a few sub forums from reddit--which tend to share text rather than memes--namely `talesfromtechsupport`, `badroommates`, `weeabootales` and `relationships`. The top 100 text posts from each have been saved to `data/reddit.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditDf = pandas.read_csv('../data/reddit.csv', index_col = 0)\n",
    "\n",
    "#Drop a couple missing values\n",
    "\n",
    "redditDf = redditDf.dropna()\n",
    "\n",
    "#Set category\n",
    "\n",
    "redditDf['category'] = redditDf['subreddit']\n",
    "\n",
    "#tokenize and normalize\n",
    "redditDf['tokenized_text'] = redditDf['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "redditDf['normalized_text'] = redditDf['tokenized_text'].apply(lambda x: lucem_illud.normalizeTokens(x, stopwordLst = lucem_illud.stop_words_basic, stemmer = lucem_illud.stemmer_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will tf.idf the data to make our vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redditTFVectorizer = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, min_df=3, stop_words='english', norm='l2')\n",
    "redditTFVects = redditTFVectorizer.fit_transform([' '.join(l) for l in redditDf['normalized_text']])\n",
    "redditDf['vect'] = [np.array(v).flatten() for v in redditTFVects.todense()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilize the model and make a train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdBackFraction = .2\n",
    "train_redditDf, test_redditDf = lucem_illud.trainTestSplit(redditDf, holdBackFraction=holdBackFraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_svm = sklearn.svm.SVC(kernel='linear', probability = False)\n",
    "#probability = True is slower but  lets you call predict_proba()\n",
    "clf_svm.fit(np.stack(train_redditDf['vect'], axis=0), train_redditDf['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and consider the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf_svm, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf_svm, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf_svm, test_redditDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets\n",
    "\n",
    "We include an example of a simple neural network, the Multi-layer Perceptron (MLP) that learns a function $f(\\cdot): R^m \\rightarrow R^o$ by training on a dataset, where $m$ is the number of dimensions for input and $o$ is the number of dimensions for output. Given a set of features $X = {x_1, x_2, ..., x_m}$ and a target $y$, it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers. The following figure shows a one hidden layer MLP with scalar output. ![title](../data/multilayerperceptron_network.png) The leftmost layer, known as the input layer, consists of a set of \"neurons\" $\\{x_i | x_1, x_2, ..., x_m\\}$ representing the input features (e.g., weighted words). Each neuron in the hidden layer transforms the values from the previous layer with a weighted linear summation $w_1x_1 + w_2x_2 + ... + w_mx_m$, followed by a non-linear activation function $g(\\cdot):R \\rightarrow R$ - like the logistic or hyperbolic tan function. The output layer receives the values from the last hidden layer and transforms them into output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_nn = sklearn.neural_network.MLPClassifier()\n",
    "clf_nn.fit(np.stack(train_redditDf['vect'], axis=0), train_redditDf['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.evaluateClassifier(clf_nn, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotConfusionMatrix(clf_nn, test_redditDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lucem_illud.plotregions(clf_nn, test_redditDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 5*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform a neural network classification and calculate relevant metrics (e.g., precision, recall, the F-measure, and AUC). How does this classify relevant to *k*-nearest neighbor, Naive Bayes, logistic and decision-tree approaches?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
